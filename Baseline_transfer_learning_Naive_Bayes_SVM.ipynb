{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W266 Transfer learning Project by Arunima Kayath, Anamika Sinha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import time\n",
    "# Install a few python packages using pip\n",
    "from common import utils\n",
    "utils.require_package('nltk')\n",
    "utils.require_package(\"wget\")      # for fetching dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_curve, auc\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/reachanamikasinha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys, time\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "# Numerical manipulation libraries.\n",
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Helper libraries\n",
    "from common import utils, vocabulary\n",
    "#import segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to read the amazon review data files\n",
    "def parse(path):\n",
    "  print('start parse')\n",
    "  start_parse = time.time()\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "  end_parse = time.time()\n",
    "  print('end parse with time for parse',end_parse - start_parse)\n",
    "\n",
    "def getDF(path):\n",
    "  print('start getDF')\n",
    "  start = time.time()\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  print('end getDF')\n",
    "  end = time.time()\n",
    "  print('time taken to load data = ',end-start)\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "#df = getDF('reviews_Toys_and_Games.json.gz') #old def function corresponding to the step bt step vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 70.29379439353943\n",
      "end getDF\n",
      "time taken to load data =  70.29404664039612\n",
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 107.64730548858643\n",
      "end getDF\n",
      "time taken to load data =  107.64770483970642\n"
     ]
    }
   ],
   "source": [
    "df_vid = getDF('reviews_Video_Games.json.gz')\n",
    "df_toys = getDF('reviews_Toys_and_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 61.853924036026\n",
      "end getDF\n",
      "time taken to load data =  61.854384899139404\n"
     ]
    }
   ],
   "source": [
    "df_aut = getDF('reviews_Automotive.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 208.65658712387085\n",
      "end getDF\n",
      "time taken to load data =  208.65727996826172\n"
     ]
    }
   ],
   "source": [
    "df_hnk = getDF('reviews_Home_and_Kitchen.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for modeling. \n",
    "Train,dev,test split.\n",
    "Create similar sized data subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy reviews train, dev and test set dataframe shape: (1351662, 9) (450554, 9) (450555, 9)\n",
      "Video games reviews train, dev and test set dataframe shape: (794851, 9) (264951, 9) (264951, 9)\n",
      "Auto reviews train, dev and test set dataframe shape: (824260, 9) (274754, 9) (274754, 9)\n",
      "Home and Kitchen reviews train, dev and test set dataframe shape: (2552355, 9) (850785, 9) (850786, 9)\n"
     ]
    }
   ],
   "source": [
    "#Create train,dev,test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_toys,devtest = train_test_split(df_toys, test_size=0.4, random_state=42)\n",
    "dev_toys,test_toys = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Toy reviews train, dev and test set dataframe shape:',train_toys.shape,dev_toys.shape,test_toys.shape)\n",
    "\n",
    "#For Video games reviews\n",
    "train_vid,devtest = train_test_split(df_vid, test_size=0.4, random_state=42)\n",
    "dev_vid,test_vid = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "print('Video games reviews train, dev and test set dataframe shape:',train_vid.shape,dev_vid.shape,test_vid.shape)\n",
    "\n",
    "#For Auto reviews\n",
    "train_aut,devtest = train_test_split(df_aut, test_size=0.4, random_state=42)\n",
    "dev_aut,test_aut = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "print('Auto reviews train, dev and test set dataframe shape:',train_aut.shape,dev_aut.shape,test_aut.shape)\n",
    "\n",
    "#For Home and Kitchen reviews\n",
    "train_hnk,devtest = train_test_split(df_hnk, test_size=0.4, random_state=42)\n",
    "dev_hnk,test_hnk = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "print('Home and Kitchen reviews train, dev and test set dataframe shape:',train_hnk.shape,dev_hnk.shape,test_hnk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create a smaller sized train and dev data set. Enables testing accuracy for different sizes.\n",
    "#Also binarizes the labels. Ratings of 1,2 and to 0; Ratings of 4,5 to 1.\n",
    "\n",
    "def set_df_size(size,data_train,data_dev):\n",
    "    size_train = size\n",
    "    len_max_train = data_train[data_train.overall!=3].shape[0] #max possible length of train data set taking out the 3 ratings.\n",
    "    #print(\"Number of reviews with ratings != 3 in train set\",len_max_train)\n",
    "    temp_size_train = min(len_max_train,size_train)\n",
    "\n",
    "    len_max_dev = data_dev[data_dev.overall!=3].shape[0]\n",
    "    #print(\"Number of reviews with ratings != 3 in dev set\",len_max_dev)\n",
    "    temp_size_dev = min(len_max_dev,int(0.3*temp_size_train)) #making the dev set about 0.3 times the train set.\n",
    "\n",
    "    temp_train_data = data_train[data_train.overall != 3][:temp_size_train]\n",
    "    #print('Size of train data',temp_train_data.shape)\n",
    "    #print(temp_train_data.groupby('overall').count())\n",
    "    #print(temp_train_toys[:5])\n",
    "\n",
    "    temp_dev_data = data_dev[data_dev.overall!=3][:temp_size_dev]\n",
    "    #print('Size of dev data',temp_dev_data.shape)\n",
    "    #print(temp_dev_data.groupby('overall').count())\n",
    "    #print(temp_dev_data[:2])\n",
    "    \n",
    "    #Binarize ratings\n",
    "    temp_train_y = np.zeros(temp_size_train)\n",
    "    temp_train_y[temp_train_data.overall > 3] = 1\n",
    "    temp_dev_y = np.zeros(temp_size_dev)\n",
    "    temp_dev_y[temp_dev_data.overall>3] = 1\n",
    "    #print('binarized y shape',temp_train_y.shape,temp_dev_y.shape)\n",
    "    #print(temp_dev_y[:20],data_dev.overall[:20])\n",
    "    return temp_train_data,temp_dev_data,temp_train_y,temp_dev_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Straight go to Cell 13 if you want to run on different sample sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toys reviews\n",
      "\n",
      "Number of reviews with ratings != 3 in train set 1235443\n",
      "Number of reviews with ratings != 3 in dev set 411860\n",
      "Size of train data (100000, 9)\n",
      "Size of dev data (30000, 9)\n",
      "binarized y shape (100000,) (30000,)\n",
      "\n",
      " Video games reviews\n",
      "\n",
      "Number of reviews with ratings != 3 in train set 720397\n",
      "Number of reviews with ratings != 3 in dev set 240040\n",
      "Size of train data (100000, 9)\n",
      "Size of dev data (30000, 9)\n",
      "binarized y shape (100000,) (30000,)\n",
      "\n",
      " Auto reviews\n",
      "\n",
      "Number of reviews with ratings != 3 in train set 761859\n",
      "Number of reviews with ratings != 3 in dev set 254068\n",
      "Size of train data (100000, 9)\n",
      "Size of dev data (30000, 9)\n",
      "binarized y shape (100000,) (30000,)\n",
      "\n",
      " Home and Kitchen reviews\n",
      "\n",
      "Number of reviews with ratings != 3 in train set 2345113\n",
      "Number of reviews with ratings != 3 in dev set 781758\n",
      "Size of train data (100000, 9)\n",
      "Size of dev data (30000, 9)\n",
      "binarized y shape (100000,) (30000,)\n"
     ]
    }
   ],
   "source": [
    "#Create smaller dataframes of desired size = size_train for each dataset, and binarize the ratings.\n",
    "list_df = ['toys','vid','aut','hnk'] #list of keys that refer to each dataframe. Adding a new dataframe would require updating this list\n",
    "size_train = 100000 #Set size of train set here. This is a hyperparameter.\n",
    "\n",
    "dict_train_df = {} #Dict to store train input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_dev_df = {} #Dict to store dev input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_train_y = {} #Dict to store binarized train data label for each domain\n",
    "dict_dev_y = {} #Dict to store binarized dev data label for each domain\n",
    "key = list_df[0]\n",
    "print('Toys reviews\\n')\n",
    "dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_toys,dev_toys)\n",
    "print('\\n Video games reviews\\n')\n",
    "key = list_df[1]\n",
    "dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_vid,dev_vid)\n",
    "print('\\n Auto reviews\\n')\n",
    "key = list_df[2]\n",
    "dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_aut,dev_aut)\n",
    "print('\\n Home and Kitchen reviews\\n')\n",
    "key = list_df[3]\n",
    "dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_hnk,dev_hnk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Baseline.\n",
    "Note : First the reviews are converted to word id sparse vectors using CountVectorizer. Then we apply the Naive Bayes model to this.   \n",
    "The vocabulary,words ids (using CountVectorizer) and the Naive Bayes model is created using the source domain, and then applied to the target domain.    \n",
    "There is an argument for creating the vocabulary, word ids using both domains since that only uses the unlabeled data, and then fit the Naive Bayes model using only the source domain.   \n",
    "We may try that in the future. Would love input on whether it is worth trying that.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number words in training corpus for toys 63968\n",
      "toys dataset id shapes (100000, 63968) (30000, 63968)\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.34%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.75      0.74      4465\n",
      "        1.0       0.96      0.95      0.95     25535\n",
      "\n",
      "avg / total       0.92      0.92      0.92     30000\n",
      "\n",
      "Number words in training corpus for vid 99366\n",
      "vid dataset id shapes (100000, 99366) (30000, 99366)\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 89.32%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.70      0.71      5642\n",
      "        1.0       0.93      0.94      0.93     24358\n",
      "\n",
      "avg / total       0.89      0.89      0.89     30000\n",
      "\n",
      "Number words in training corpus for aut 59113\n",
      "aut dataset id shapes (100000, 59113) (30000, 59113)\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 92.05%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.62      0.69      4329\n",
      "        1.0       0.94      0.97      0.95     25671\n",
      "\n",
      "avg / total       0.92      0.92      0.92     30000\n",
      "\n",
      "Number words in training corpus for hnk 57556\n",
      "hnk dataset id shapes (100000, 57556) (30000, 57556)\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.59%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.71      0.74      5087\n",
      "        1.0       0.94      0.96      0.95     24913\n",
      "\n",
      "avg / total       0.91      0.92      0.91     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting reviews to sparse matrix of word ids with count vectorizer, and using Naive Bayes to make the prediction.\n",
    "#This section also creates the count_vectorizer and Naive Bayes models for each domain to be used to test transfer learning\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "dict_vectorizers = {} #Dict to store the count_vectorizer model developed on each domain\n",
    "dict_train_ids = {} #Dict to store train data reviews as sparse matrix of word ids\n",
    "dict_dev_ids = {} #Dict to store dev data reviews as sparse matrix of word ids\n",
    "dict_nb = {} #Dict to store naive bayes model developed on each domain. Assumes input features are developed using the corresponding count_vectorizer\n",
    "dict_dev_ypred = {} #Dict to store dev predictions\n",
    "for key in list_df:\n",
    "    \n",
    "    #Converting ratings to tokenized word id counts as a sparse matrix using count_vectorizer\n",
    "    dict_vectorizers[key] = CountVectorizer()\n",
    "    dict_train_ids[key] = dict_vectorizers[key].fit_transform(dict_train_df[key].reviewText)\n",
    "    dict_dev_ids[key] = dict_vectorizers[key].transform(dict_dev_df[key].reviewText)\n",
    "    print(\"Number words in training corpus for\",key,len(dict_vectorizers[key].get_feature_names()))\n",
    "    print(key,'dataset id shapes',dict_train_ids[key].shape, dict_dev_ids[key].shape)\n",
    "    \n",
    "    #Building a Naive Bayes model to predict the ratings\n",
    "    dict_nb[key] = MultinomialNB()\n",
    "    dict_nb[key].fit(dict_train_ids[key],dict_train_y[key])\n",
    "    dict_dev_ypred[key] = dict_nb[key].predict(dict_dev_ids[key])\n",
    "    acc = accuracy_score(dict_dev_y[key], dict_dev_ypred[key])\n",
    "    print(\"Accuracy on\",key,\"dev set for binary prediction with toys naive bayes model: {:.02%}\".format(acc))\n",
    "    print('Corresponding classification report\\n',classification_report(dict_dev_y[key], dict_dev_ypred[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next two cells are Naive bayes transfer learning  in baseline version without count vectorizer min_df=5, max_df=0.8, stop_words='english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 92.3% 91.4% 91.2% 91.3%\n",
      "vid  87.0% 89.3% 87.8% 87.3%\n",
      "aut  75.6% 79.1% 92.1% 84.0%\n",
      "hnk  84.9% 85.8% 91.1% 91.6%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Accuracy of transfer learning\n",
    "\n",
    "# dict_transfer_ids = {} #Dictionary to store the dev vector ids for dataframe A(df) using the count_vectorizer of dataframe B(vect)\n",
    "# transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "# for vectKey in list_df:\n",
    "#     dict_transfer_ids[vectKey] = {}\n",
    "#     #print('vectKey',vectKey)\n",
    "#     for dfKey in list_df:\n",
    "#         #print('dfKey',dfKey)\n",
    "#         dict_transfer_ids[vectKey][dfKey] = dict_vectorizers[vectKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "#         #print(dfKey,'dataset using ',vectKey,' count vectorizer, id shapes',dict_transfer_ids[vectKey][dfKey].shape)\n",
    "#         dict_dev_ypred = dict_nb[vectKey].predict(dict_transfer_ids[vectKey][dfKey])\n",
    "#         acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "#         #print(\"Accuracy on \",dfKey,\" dev set for binary prediction with \", vectKey,\" naive bayes model: {:.02%}\".format(acc))\n",
    "#         transfer_results[vectKey][dfKey] = acc\n",
    "\n",
    "# print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "# print(\"Accuracy of rating predictions\")\n",
    "# print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "# print(transfer_results.to_string(float_format = '{:.01%}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer loss on rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid  aut  hnk\n",
      "toys  0.0%  0.9% 1.1% 1.0%\n",
      "vid   2.3%  0.0% 1.5% 2.1%\n",
      "aut  16.4% 12.9% 0.0% 8.0%\n",
      "hnk   6.7%  5.8% 0.5% 0.0%\n"
     ]
    }
   ],
   "source": [
    "# #Calculating and displaying as transfer loss\n",
    "# transfer_loss = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store loss in accuracy on transfer. Col = Model, row = dataframe\n",
    "# for A in list_df:\n",
    "#     for B in list_df:\n",
    "#         transfer_loss[A][B] = transfer_results[B][B] - transfer_results[A][B]\n",
    "# print(\"Transfer loss on rating predictions\")\n",
    "# print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "# print(transfer_loss.to_string(float_format = '{:.01%}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here if you want to run different sample sizes. Below code is for error analysis  with different sample sizes. It does not have min_df=5, max_df=0.8, stop_words='english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = ['toys','vid','aut','hnk'] #list of keys that refer to each dataframe. Adding a new dataframe would require updating this list\n",
    "dict_train_df = {} #Dict to store train input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_dev_df = {} #Dict to store dev input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_train_y = {} #Dict to store binarized train data label for each domain\n",
    "dict_dev_y = {} #Dict to store binarized dev data label for each domain\n",
    "#print(len(dict_train_df))\n",
    "\n",
    "def create_sized_data(size = 100000):\n",
    "    size_train = size #Set size of train set here. This is a hyperparameter.\n",
    "    key = list_df[0]\n",
    "    #print('Toys reviews\\n')\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_toys,dev_toys)\n",
    "    #print('\\n Video games reviews\\n')\n",
    "    key = list_df[1]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_vid,dev_vid)\n",
    "    #print('\\n Auto reviews\\n')\n",
    "    key = list_df[2]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_aut,dev_aut)\n",
    "    #print('\\n Home and Kitchen reviews\\n')\n",
    "    key = list_df[3]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_hnk,dev_hnk)\n",
    "    \n",
    "create_sized_data()\n",
    "#print(len(dict_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting reviews to sparse matrix of word ids with count vectorizer, and using Naive Bayes to make the prediction.\n",
    "#This section also creates the count_vectorizer and Naive Bayes models for each domain to be used to test transfer learning\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "dict_vectorizers = {} #Dict to store the count_vectorizer model developed on each domain\n",
    "dict_train_ids = {} #Dict to store train data reviews as sparse matrix of word ids\n",
    "dict_dev_ids = {} #Dict to store dev data reviews as sparse matrix of word ids\n",
    "dict_nb = {} #Dict to store naive bayes model developed on each domain. Assumes input features are developed using the corresponding count_vectorizer\n",
    "dict_dev_ypred = {} #Dict to store dev predictions\n",
    "dict_dev_ypred_proba = {} ##Dict to store dev predictions probablities\n",
    "def create_base_NB_models():\n",
    "    for key in list_df:\n",
    "\n",
    "        #Converting ratings to tokenized word id counts as a sparse matrix using count_vectorizer\n",
    "        dict_vectorizers[key] = CountVectorizer()\n",
    "        dict_train_ids[key] = dict_vectorizers[key].fit_transform(dict_train_df[key].reviewText)\n",
    "        dict_dev_ids[key] = dict_vectorizers[key].transform(dict_dev_df[key].reviewText)\n",
    "        #print(\"Number words in training corpus for\",key,len(dict_vectorizers[key].get_feature_names()))\n",
    "        #print(key,'dataset id shapes',dict_train_ids[key].shape, dict_dev_ids[key].shape)\n",
    "\n",
    "        #Building a Naive Bayes model to predict the ratings\n",
    "        dict_nb[key] = MultinomialNB()\n",
    "        dict_nb[key].fit(dict_train_ids[key],dict_train_y[key])\n",
    "        dict_dev_ypred[key] = dict_nb[key].predict(dict_dev_ids[key])\n",
    "        acc = accuracy_score(dict_dev_y[key], dict_dev_ypred[key])\n",
    "        #print(\"Accuracy on\",key,\"dev set for binary prediction with toys naive bayes model: {:.02%}\".format(acc))\n",
    "\n",
    "def print_base_NB_details():\n",
    "    for key in list_df:\n",
    "      print('Classification report for',key,'\\n',classification_report(dict_dev_y[key], dict_dev_ypred[key]))  \n",
    "        \n",
    "#create_base_NB_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sample_size', 'Target_Domain', 'toys', 'vid', 'aut', 'hnk']\n",
      "['Sample_size', 'Target_Domain', 'toys', 'vid', 'aut', 'hnk']\n",
      "['Sample_size', 'Target_Domain', 'Class', 'toys', 'vid', 'aut', 'hnk']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "#Define Sample size and create dataframes to store  transfer metrics results\n",
    "\n",
    "#Sample_size = [500000, 100000]\n",
    "Sample_size = [50000, 100000]\n",
    "num_classes = [0,1]\n",
    "list_df = ['toys','vid','aut','hnk']\n",
    "list_auc_df = deepcopy(list_df)\n",
    "list_auc_df.insert(0,\"Sample_size\")\n",
    "list_auc_df.insert(1,\"Target_Domain\")\n",
    "\n",
    "\n",
    "list_acc_df = deepcopy(list_df)\n",
    "list_acc_df.insert(0,\"Sample_size\")\n",
    "list_acc_df.insert(1,\"Target_Domain\")\n",
    "\n",
    "\n",
    "list_f1_df = deepcopy(list_df)\n",
    "list_f1_df.insert(0,\"Sample_size\")\n",
    "list_f1_df.insert(1,\"Target_Domain\")\n",
    "list_f1_df.insert(2,\"Class\")\n",
    "\n",
    "print(list_auc_df )\n",
    "print(list_acc_df )\n",
    "print(list_f1_df )\n",
    "    \n",
    "len_auc_df = len(Sample_size)*len(list_df)\n",
    "index_auc_df = list(range(1, len_auc_df+1))\n",
    "print(index_auc_df)\n",
    "    \n",
    "len_acc_df = len(Sample_size)*len(list_df)\n",
    "index_acc_df = list(range(1, len_acc_df+1))\n",
    "print(index_acc_df)\n",
    "\n",
    "len_f1_df = len(Sample_size)*len(list_df)*len(num_classes)\n",
    "index_f1_df = list(range(1, len_f1_df+1))\n",
    "print(index_f1_df)\n",
    "\n",
    "transfer_auc_results = pd.DataFrame(index=index_auc_df,columns=list_auc_df) #Dataframe to store auc on transfer. Col = Model, row = dataframe\n",
    "transfer_acc_results = pd.DataFrame(index=index_acc_df,columns=list_acc_df) #Dataframe to store accuracy on transfer. \n",
    "transfer_f1_results = pd.DataFrame(index=index_f1_df,columns=list_f1_df) #Dataframe to store accuracy on transfer. \n",
    "#print(transfer_auc_results)\n",
    "#print(transfer_f1_results)\n",
    "\n",
    "transfer_auc_loss = pd.DataFrame(index=index_auc_df,columns=list_auc_df) #Dataframe to store auc on transfer. Col = Model, row = dataframe\n",
    "transfer_acc_loss = pd.DataFrame(index=index_acc_df,columns=list_acc_df) #Dataframe to store acc on transfer. \n",
    "transfer_f1_loss = pd.DataFrame(index=index_f1_df,columns=list_f1_df) #Dataframe to store f1 on transfer. \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transfer learning error analysis using AUC, Accuracy and f1 metrics\n",
    "\n",
    "dict_transfer_ids = {} #Dictionary to store the dev vector ids for dataframe A(df) using the count_vectorizer of dataframe B(vect)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def estimate_transfer_accuracy(size=5000):\n",
    "    \n",
    "#     for n in range(1,len(list_df)+1):\n",
    "#         transfer_auc_results.set_value(index_auc_df[n], list_auc_df[0], size)\n",
    "    \n",
    "    for vectKey in list_df:\n",
    "        \n",
    "        dict_transfer_ids[vectKey] = {}\n",
    "        #dict_transfer_results[vectKey] = {}\n",
    "        \n",
    "\n",
    "        n = Sample_size.index(size)*len(list_df)\n",
    "        j = Sample_size.index(size)*len(list_df)*len(num_classes)\n",
    "                \n",
    "        #print('vectKey',vectKey)\n",
    "        for dfKey in list_df:\n",
    "        #print('dfKey',dfKey)\n",
    "        \n",
    "            \n",
    "            dict_transfer_ids[vectKey][dfKey] = dict_vectorizers[vectKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "            #print(dfKey,'dataset using ',vectKey,' count vectorizer, id shapes',dict_transfer_ids[vectKey][dfKey].shape)\n",
    "            dict_dev_ypred = dict_nb[vectKey].predict(dict_transfer_ids[vectKey][dfKey])\n",
    "            dict_dev_ypred_proba = dict_nb[vectKey].predict_proba(dict_transfer_ids[vectKey][dfKey])\n",
    "            \n",
    "            ##AUC Calculations\n",
    "            #false_pos_rate, true_pos_rate, _ = roc_curve(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "            \n",
    "            #roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "            \n",
    "            false_pos_rate, true_pos_rate, _ = roc_curve(dict_dev_y[dfKey], dict_dev_ypred_proba[:,1])\n",
    "            roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "            \n",
    "            transfer_auc_results.set_value(index_auc_df[n], list_auc_df[0], size)\n",
    "            transfer_auc_results.set_value(index_auc_df[n], list_auc_df[1], dfKey)\n",
    "            transfer_auc_results.set_value(index_auc_df[n], vectKey, roc_auc)\n",
    "            \n",
    "            \n",
    "            ##Accuracy calculations\n",
    "            acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "            \n",
    "            transfer_acc_results.set_value(index_auc_df[n], list_auc_df[0], size)\n",
    "            transfer_acc_results.set_value(index_auc_df[n], list_auc_df[1], dfKey)\n",
    "            transfer_acc_results.set_value(index_auc_df[n], vectKey, acc)\n",
    "            \n",
    "            ##f1 score calcullations\n",
    "            f1_val_pos = (f1_score(dict_dev_y[dfKey], dict_dev_ypred,  average=None))[1]#pos class\n",
    "        \n",
    "            f1_val_neg = (f1_score(dict_dev_y[dfKey], dict_dev_ypred,  average=None))[0]#neg class\n",
    "            transfer_f1_results.set_value(index_f1_df[j], list_f1_df[0], size)\n",
    "            transfer_f1_results.set_value(index_f1_df[j], list_f1_df[1], dfKey)\n",
    "            transfer_f1_results.set_value(index_f1_df[j], list_f1_df[2], \"1\")\n",
    "            transfer_f1_results.set_value(index_f1_df[j], vectKey, f1_val_pos)\n",
    "            j +=1\n",
    "            transfer_f1_results.set_value(index_f1_df[j], list_f1_df[0], size)\n",
    "            transfer_f1_results.set_value(index_f1_df[j], list_f1_df[1], dfKey)\n",
    "            transfer_f1_results.set_value(index_f1_df[j], list_f1_df[2], \"0\")\n",
    "            transfer_f1_results.set_value(index_f1_df[j], vectKey, f1_val_neg)\n",
    "            j +=1\n",
    "            #print(n)\n",
    "            n += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating and displaying as transfer loss with Naive Bayes\n",
    "\n",
    "def estimate_transfer_loss(size=5000):\n",
    "   \n",
    "    for vectKey in list_df:\n",
    "        \n",
    "        \n",
    "\n",
    "        x = Sample_size.index(size)*len(list_df)\n",
    "        y = Sample_size.index(size)*len(list_df)*len(num_classes)\n",
    "                \n",
    "        #print('vectKey',vectKey)\n",
    "        for dfKey in list_df:\n",
    "        #print('dfKey',dfKey)\n",
    "        \n",
    "            \n",
    "\n",
    "            #AUC loss calculation\n",
    "            pos_source = transfer_auc_results.columns.get_loc(dfKey)\n",
    "            pos_target = transfer_auc_results.columns.get_loc(vectKey)\n",
    "            transfer_loss = transfer_auc_results.iloc[index_auc_df[x]-1,pos_source] - transfer_auc_results.iloc[index_auc_df[x]-1,pos_target]\n",
    "\n",
    "            transfer_auc_loss.set_value(index_auc_df[x], list_auc_df[0], size)\n",
    "            transfer_auc_loss.set_value(index_auc_df[x], list_auc_df[1], dfKey)\n",
    "            transfer_auc_loss.set_value(index_auc_df[x], vectKey, transfer_loss)\n",
    "            \n",
    "            \n",
    "            #ACC loss calculation\n",
    "            pos_source = transfer_acc_results.columns.get_loc(dfKey)\n",
    "            pos_target = transfer_acc_results.columns.get_loc(vectKey)\n",
    "            transfer_loss = transfer_acc_results.iloc[index_acc_df[x]-1,pos_source] - transfer_acc_results.iloc[index_acc_df[x]-1,pos_target]\n",
    "\n",
    "            transfer_acc_loss.set_value(index_acc_df[x], list_acc_df[0], size)\n",
    "            transfer_acc_loss.set_value(index_acc_df[x], list_acc_df[1], dfKey)\n",
    "            transfer_acc_loss.set_value(index_acc_df[x], vectKey, transfer_loss)\n",
    "            x += 1\n",
    "            \n",
    "            #f1 loss calculation\n",
    "            pos_source = transfer_f1_results.columns.get_loc(dfKey)\n",
    "            pos_target = transfer_f1_results.columns.get_loc(vectKey)\n",
    "            transfer_loss = transfer_f1_results.iloc[index_f1_df[y]-1,pos_source] - transfer_f1_results.iloc[index_f1_df[y]-1,pos_target]\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], list_f1_df[0], size)\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], list_f1_df[1], dfKey)\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], list_f1_df[2], \"1\")\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], vectKey, transfer_loss)\n",
    "            y +=1\n",
    "            transfer_loss = transfer_f1_results.iloc[index_f1_df[y]-1,pos_source] - transfer_f1_results.iloc[index_f1_df[y]-1,pos_target]\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], list_f1_df[0], size)\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], list_f1_df[1], dfKey)\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], list_f1_df[2], \"0\")\n",
    "            transfer_f1_loss.set_value(index_f1_df[y], vectKey, transfer_loss)\n",
    "            y +=1\n",
    "            \n",
    "            #print(y)\n",
    "          \n",
    "\n",
    "# estimate_transfer_loss(5000)\n",
    "# print(transfer_auc_results.to_string(float_format = '{:.01%}'.format))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train data_set size = 50000\n",
      "\n",
      " Train data_set size = 100000\n",
      " \n",
      " \n",
      " \n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Area Under Curve values of rating predictions\n",
      "Columns = source domain, Rows = target domain\n",
      "\n",
      "  Sample_size Target_Domain  toys   vid   aut   hnk\n",
      "1       50000          toys 93.3% 90.9% 90.4% 91.0%\n",
      "2       50000           vid 85.4% 88.4% 86.0% 86.3%\n",
      "3       50000           aut 88.1% 85.4% 92.2% 88.9%\n",
      "4       50000           hnk 91.9% 90.0% 91.7% 93.1%\n",
      "5      100000          toys 93.9% 91.8% 91.4% 91.8%\n",
      "6      100000           vid 86.4% 89.3% 87.2% 86.9%\n",
      "7      100000           aut 87.7% 85.6% 92.8% 89.0%\n",
      "8      100000           hnk 91.9% 90.3% 92.8% 93.7%\n",
      " \n",
      " \n",
      "  Sample_size Target_Domain toys  vid  aut  hnk\n",
      "1       50000          toys 0.0% 2.4% 2.9% 2.4%\n",
      "2       50000           vid 3.0% 0.0% 2.4% 2.1%\n",
      "3       50000           aut 4.1% 6.9% 0.0% 3.3%\n",
      "4       50000           hnk 1.2% 3.1% 1.4% 0.0%\n",
      "5      100000          toys 0.0% 2.1% 2.6% 2.2%\n",
      "6      100000           vid 2.8% 0.0% 2.1% 2.4%\n",
      "7      100000           aut 5.1% 7.2% 0.0% 3.8%\n",
      "8      100000           hnk 1.9% 3.4% 0.9% 0.0%\n",
      " \n",
      " \n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy values of rating predictions\n",
      "Columns = source domain, Rows = target domain\n",
      "\n",
      "  Sample_size Target_Domain  toys   vid   aut   hnk\n",
      "1       50000          toys 92.1% 91.2% 90.7% 91.0%\n",
      "2       50000           vid 87.3% 89.2% 87.5% 86.9%\n",
      "3       50000           aut 78.1% 80.1% 91.8% 84.6%\n",
      "4       50000           hnk 85.9% 86.4% 90.8% 91.4%\n",
      "5      100000          toys 92.3% 91.4% 91.2% 91.3%\n",
      "6      100000           vid 87.0% 89.3% 87.8% 87.3%\n",
      "7      100000           aut 75.6% 79.1% 92.1% 84.0%\n",
      "8      100000           hnk 84.9% 85.8% 91.1% 91.6%\n",
      " \n",
      " \n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy values of rating predictions\n",
      "Columns = source domain, Rows = target domain\n",
      "\n",
      "  Sample_size Target_Domain  toys   vid  aut  hnk\n",
      "1       50000          toys  0.0%  0.9% 1.4% 1.0%\n",
      "2       50000           vid  1.9%  0.0% 1.8% 2.3%\n",
      "3       50000           aut 13.7% 11.6% 0.0% 7.2%\n",
      "4       50000           hnk  5.5%  5.0% 0.6% 0.0%\n",
      "5      100000          toys  0.0%  0.9% 1.1% 1.0%\n",
      "6      100000           vid  2.3%  0.0% 1.5% 2.1%\n",
      "7      100000           aut 16.4% 12.9% 0.0% 8.0%\n",
      "8      100000           hnk  6.7%  5.8% 0.5% 0.0%\n",
      " \n",
      " \n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "f1 values of rating predictions\n",
      "Columns = source domain, Rows = target domain\n",
      "\n",
      "   Sample_size Target_Domain Class  toys   vid   aut   hnk\n",
      "1        50000          toys     1 95.4% 94.9% 94.6% 94.8%\n",
      "2        50000          toys     0 72.5% 67.0% 63.5% 66.9%\n",
      "3        50000           vid     1 92.3% 93.4% 92.5% 92.0%\n",
      "4        50000           vid     0 64.4% 69.8% 61.1% 62.8%\n",
      "5        50000           aut     1 85.7% 87.4% 95.3% 90.5%\n",
      "6        50000           aut     0 53.3% 52.8% 67.0% 59.4%\n",
      "7        50000           hnk     1 91.1% 91.6% 94.6% 94.9%\n",
      "8        50000           hnk     0 66.7% 64.9% 68.5% 72.7%\n",
      "9       100000          toys     1 95.5% 95.0% 94.9% 95.0%\n",
      "10      100000          toys     0 74.4% 68.7% 66.9% 68.4%\n",
      "11      100000           vid     1 92.0% 93.4% 92.7% 92.3%\n",
      "12      100000           vid     0 65.9% 71.1% 63.4% 64.0%\n",
      "13      100000           aut     1 83.8% 86.7% 95.4% 90.1%\n",
      "14      100000           aut     0 51.2% 51.8% 69.2% 58.6%\n",
      "15      100000           hnk     1 90.3% 91.1% 94.8% 95.0%\n",
      "16      100000           hnk     0 65.7% 64.8% 70.6% 74.1%\n",
      " \n",
      " \n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "f1 transfer loss of rating predictions\n",
      "Columns = source domain, Rows = target domain\n",
      "\n",
      "   Sample_size Target_Domain Class  toys   vid  aut   hnk\n",
      "1        50000          toys     1  0.0%  0.4% 0.7%  0.6%\n",
      "2        50000          toys     0  0.0%  5.5% 9.0%  5.6%\n",
      "3        50000           vid     1  1.1%  0.0% 0.9%  1.4%\n",
      "4        50000           vid     0  5.4%  0.0% 8.6%  7.0%\n",
      "5        50000           aut     1  9.6%  7.9% 0.0%  4.8%\n",
      "6        50000           aut     0 13.7% 14.2% 0.0%  7.6%\n",
      "7        50000           hnk     1  3.8%  3.4% 0.3%  0.0%\n",
      "8        50000           hnk     0  6.0%  7.8% 4.2%  0.0%\n",
      "9       100000          toys     1  0.0%  0.5% 0.6%  0.5%\n",
      "10      100000          toys     0  0.0%  5.7% 7.5%  6.1%\n",
      "11      100000           vid     1  1.5%  0.0% 0.8%  1.2%\n",
      "12      100000           vid     0  5.2%  0.0% 7.7%  7.1%\n",
      "13      100000           aut     1 11.7%  8.7% 0.0%  5.3%\n",
      "14      100000           aut     0 18.0% 17.3% 0.0% 10.6%\n",
      "15      100000           hnk     1  4.7%  3.9% 0.2%  0.0%\n",
      "16      100000           hnk     0  8.4%  9.3% 3.5%  0.0%\n"
     ]
    }
   ],
   "source": [
    "for size in Sample_size:\n",
    "    print(\"\\n Train data_set size =\",size)\n",
    "    create_sized_data(size = size)\n",
    "    create_base_NB_models()\n",
    "    estimate_transfer_accuracy(size)\n",
    "    #print(transfer_auc_results.to_string(float_format = '{:.01%}'.format))\n",
    "    estimate_transfer_loss(size)\n",
    "    \n",
    "print(\" \")        \n",
    "print(\" \")        \n",
    "print(\" \")   \n",
    "print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "print(\"Area Under Curve values of rating predictions\")\n",
    "print(\"Columns = source domain, Rows = target domain\\n\")\n",
    "print(transfer_auc_results.to_string(float_format = '{:.01%}'.format))\n",
    "print(\" \")        \n",
    "print(\" \")        \n",
    "print(transfer_auc_loss.to_string(float_format = '{:.01%}'.format))\n",
    "print(\" \")        \n",
    "print(\" \") \n",
    "print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "print(\"Accuracy values of rating predictions\")\n",
    "print(\"Columns = source domain, Rows = target domain\\n\")\n",
    "print(transfer_acc_results.to_string(float_format = '{:.01%}'.format))\n",
    "print(\" \")        \n",
    "print(\" \") \n",
    "print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "print(\"Accuracy values of rating predictions\")\n",
    "print(\"Columns = source domain, Rows = target domain\\n\")\n",
    "print(transfer_acc_loss.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "\n",
    "print(\" \")        \n",
    "print(\" \")  \n",
    "print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "print(\"f1 values of rating predictions\")\n",
    "print(\"Columns = source domain, Rows = target domain\\n\")\n",
    "print(transfer_f1_results.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "print(\" \")        \n",
    "print(\" \")  \n",
    "print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "print(\"f1 transfer loss of rating predictions\")\n",
    "print(\"Columns = source domain, Rows = target domain\\n\")\n",
    "print(transfer_f1_loss.to_string(float_format = '{:.01%}'.format))\n",
    "        \n",
    "    #estimate_transfer_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Baseline\n",
    "Similar approach to Naive Bayes, except we used SVM with linear kernel here. One more important distiction - we found that the SVM with full vocabulary was taking too long to run. Hence we added min_df = 5, and max_df = 0.8, and stop words = English as parameters to CountVectorizer to reduce the number of vocabulary words being considered to the most relevant and hence reduce the SVM dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number words in training corpus for toys 17651\n",
      "toys dataset id shapes (100000, 17651) (30000, 17651)\n",
      "toys  Training done\n",
      "toys  Prediction done\n",
      "Accuracy on toys dev set for binary prediction with  toys SVM model: 93.79%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.71      0.77      4465\n",
      "        1.0       0.95      0.98      0.96     25535\n",
      "\n",
      "avg / total       0.94      0.94      0.94     30000\n",
      "\n",
      "Time for  toys :  2078.7969567775726\n",
      "Number words in training corpus for vid 25014\n",
      "vid dataset id shapes (100000, 25014) (30000, 25014)\n",
      "vid  Training done\n",
      "vid  Prediction done\n",
      "Accuracy on vid dev set for binary prediction with  vid SVM model: 91.63%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.69      0.76      5642\n",
      "        1.0       0.93      0.97      0.95     24358\n",
      "\n",
      "avg / total       0.91      0.92      0.91     30000\n",
      "\n",
      "Time for  vid :  3430.8760755062103\n",
      "Number words in training corpus for aut 15599\n",
      "aut dataset id shapes (100000, 15599) (30000, 15599)\n",
      "aut  Training done\n",
      "aut  Prediction done\n",
      "Accuracy on aut dev set for binary prediction with  aut SVM model: 92.49%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.62      0.70      4329\n",
      "        1.0       0.94      0.98      0.96     25671\n",
      "\n",
      "avg / total       0.92      0.92      0.92     30000\n",
      "\n",
      "Time for  aut :  2356.9667625427246\n",
      "Number words in training corpus for hnk 16440\n",
      "hnk dataset id shapes (100000, 16440) (30000, 16440)\n",
      "hnk  Training done\n",
      "hnk  Prediction done\n",
      "Accuracy on hnk dev set for binary prediction with  hnk SVM model: 92.71%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.70      0.76      5087\n",
      "        1.0       0.94      0.97      0.96     24913\n",
      "\n",
      "avg / total       0.92      0.93      0.92     30000\n",
      "\n",
      "Time for  hnk :  2235.634292125702\n"
     ]
    }
   ],
   "source": [
    "# We use the tfid to give less weigthage to words occuring more frequently. At the same time, to get \n",
    "#rid of prepositions which are not helping with context, we use stop words.\n",
    "from sklearn import svm\n",
    "\n",
    "dict_vectorizers = {} #Dict to store the count_vectorizer model developed on each domain\n",
    "dict_train_ids = {} #Dict to store train data reviews as sparse matrix of word ids\n",
    "dict_dev_ids = {} #Dict to store dev data reviews as sparse matrix of word ids\n",
    "dict_svm = {} #Dict to store svm model developed on each domain. Assumes input features are developed using the corresponding count_vectorizer\n",
    "dict_dev_ypred = {} #Dict to store dev predictions\n",
    "for key in list_df:\n",
    "    \n",
    "    #Converting ratings to tokenized word id counts as a sparse matrix using count_vectorizer\n",
    "    dict_vectorizers[key] = TfidfVectorizer(min_df=5, max_df=0.8, stop_words='english')\n",
    "    dict_train_ids[key] = dict_vectorizers[key].fit_transform(dict_train_df[key].reviewText)\n",
    "    dict_dev_ids[key] = dict_vectorizers[key].transform(dict_dev_df[key].reviewText)\n",
    "    print(\"Number words in training corpus for\",key,len(dict_vectorizers[key].get_feature_names()))\n",
    "    print(key,'dataset id shapes',dict_train_ids[key].shape, dict_dev_ids[key].shape)\n",
    "    \n",
    "    start =time.time()\n",
    "    #Building an SVM model to predict the ratings\n",
    "    dict_svm[key] = svm.SVC(kernel='linear')\n",
    "    dict_svm[key].fit(dict_train_ids[key],dict_train_y[key])\n",
    "    print(key, \" Training done\")\n",
    "    \n",
    "    dict_dev_ypred[key] = dict_svm[key].predict(dict_dev_ids[key])\n",
    "    print(key, \" Prediction done\")\n",
    "    \n",
    "    acc = accuracy_score(dict_dev_y[key], dict_dev_ypred[key])\n",
    "    print(\"Accuracy on\",key,\"dev set for binary prediction with \", key, \"SVM model: {:.02%}\".format(acc))\n",
    "    print('Corresponding classification report\\n',classification_report(dict_dev_y[key], dict_dev_ypred[key]))\n",
    "    stop = time.time()\n",
    "    print(\"Time for \", key, ': ',stop-start)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectiveness of transfer learning with SVM:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 93.8% 92.3% 92.4% 92.7%\n",
      "vid  89.5% 91.6% 86.9% 88.0%\n",
      "aut  90.3% 90.1% 92.5% 91.0%\n",
      "hnk  91.4% 90.8% 91.6% 92.7%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of transfer learning with svm\n",
    "\n",
    "dict_transfer_ids = {} #Dictionary to store the dev vector ids for dataframe A(df) using the count_vectorizer of dataframe B(vect)\n",
    "transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "for vectKey in list_df:\n",
    "    dict_transfer_ids[vectKey] = {}\n",
    "    #print('vectKey',vectKey)\n",
    "    for dfKey in list_df:\n",
    "        #print('dfKey',dfKey)\n",
    "        dict_transfer_ids[vectKey][dfKey] = dict_vectorizers[vectKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "        #print(dfKey,'dataset using ',vectKey,' count vectorizer, id shapes',dict_transfer_ids[vectKey][dfKey].shape)\n",
    "        dict_dev_ypred = dict_svm[vectKey].predict(dict_transfer_ids[vectKey][dfKey])\n",
    "        acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "        #print(\"Accuracy on \",dfKey,\" dev set for binary prediction with \", vectKey,\" naive bayes model: {:.02%}\".format(acc))\n",
    "        transfer_results[vectKey][dfKey] = acc\n",
    "\n",
    "print(\"Effectiveness of transfer learning with SVM:\")\n",
    "print(\"Accuracy of rating predictions\")\n",
    "print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "print(transfer_results.to_string(float_format = '{:.01%}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer loss on rating predictions with SVM\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "     toys  vid  aut  hnk\n",
      "toys 0.0% 1.5% 1.4% 1.1%\n",
      "vid  2.1% 0.0% 4.8% 3.6%\n",
      "aut  2.2% 2.4% 0.0% 1.5%\n",
      "hnk  1.3% 1.9% 1.1% 0.0%\n"
     ]
    }
   ],
   "source": [
    "#Calculating and displaying as transfer loss with svm\n",
    "transfer_loss = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store loss in accuracy on transfer. Col = Model, row = dataframe\n",
    "for A in list_df:\n",
    "    for B in list_df:\n",
    "        transfer_loss[A][B] = transfer_results[B][B] - transfer_results[A][B]\n",
    "print(\"Transfer loss on rating predictions with SVM\")\n",
    "print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "print(transfer_loss.to_string(float_format = '{:.01%}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Baseline updated for CountVectorizer parameters to make them similar to SVM.\n",
    "\n",
    "ie set min_df = 5, max_df = 0.8, stop_words = english in CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number words in training corpus for toys 17651\n",
      "toys dataset id shapes (100000, 17651) (30000, 17651)\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.59%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.76      0.73      4465\n",
      "        1.0       0.96      0.94      0.95     25535\n",
      "\n",
      "avg / total       0.92      0.92      0.92     30000\n",
      "\n",
      "Number words in training corpus for vid 25014\n",
      "vid dataset id shapes (100000, 25014) (30000, 25014)\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.54%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.73      0.70      5642\n",
      "        1.0       0.94      0.92      0.93     24358\n",
      "\n",
      "avg / total       0.89      0.89      0.89     30000\n",
      "\n",
      "Number words in training corpus for aut 15599\n",
      "aut dataset id shapes (100000, 15599) (30000, 15599)\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.12%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.67      0.68      4329\n",
      "        1.0       0.94      0.95      0.95     25671\n",
      "\n",
      "avg / total       0.91      0.91      0.91     30000\n",
      "\n",
      "Number words in training corpus for hnk 16440\n",
      "hnk dataset id shapes (100000, 16440) (30000, 16440)\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 90.78%\n",
      "Corresponding classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.72      0.72      5087\n",
      "        1.0       0.94      0.95      0.94     24913\n",
      "\n",
      "avg / total       0.91      0.91      0.91     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting reviews to sparse matrix of word ids with count vectorizer, and using Naive Bayes to make the prediction.\n",
    "#This section also creates the count_vectorizer and Naive Bayes models for each domain to be used to test transfer learning\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "dict_vectorizers = {} #Dict to store the count_vectorizer model developed on each domain\n",
    "dict_train_ids = {} #Dict to store train data reviews as sparse matrix of word ids\n",
    "dict_dev_ids = {} #Dict to store dev data reviews as sparse matrix of word ids\n",
    "dict_nb = {} #Dict to store naive bayes model developed on each domain. Assumes input features are developed using the corresponding count_vectorizer\n",
    "dict_dev_ypred = {} #Dict to store dev predictions\n",
    "for key in list_df:\n",
    "    \n",
    "    #Converting ratings to tokenized word id counts as a sparse matrix using count_vectorizer\n",
    "    dict_vectorizers[key] = CountVectorizer(min_df=5, max_df=0.8, stop_words='english')\n",
    "    dict_train_ids[key] = dict_vectorizers[key].fit_transform(dict_train_df[key].reviewText)\n",
    "    dict_dev_ids[key] = dict_vectorizers[key].transform(dict_dev_df[key].reviewText)\n",
    "    print(\"Number words in training corpus for\",key,len(dict_vectorizers[key].get_feature_names()))\n",
    "    print(key,'dataset id shapes',dict_train_ids[key].shape, dict_dev_ids[key].shape)\n",
    "    \n",
    "    #Building a Naive Bayes model to predict the ratings\n",
    "    dict_nb[key] = MultinomialNB()\n",
    "    dict_nb[key].fit(dict_train_ids[key],dict_train_y[key])\n",
    "    dict_dev_ypred[key] = dict_nb[key].predict(dict_dev_ids[key])\n",
    "    acc = accuracy_score(dict_dev_y[key], dict_dev_ypred[key])\n",
    "    print(\"Accuracy on\",key,\"dev set for binary prediction with toys naive bayes model: {:.02%}\".format(acc))\n",
    "    print('Corresponding classification report\\n',classification_report(dict_dev_y[key], dict_dev_ypred[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 91.6% 91.0% 90.8% 91.3%\n",
      "vid  86.0% 88.5% 88.1% 87.2%\n",
      "aut  74.1% 78.5% 91.1% 82.6%\n",
      "hnk  83.9% 85.5% 90.8% 90.8%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of transfer learning with Naive Bayes\n",
    "\n",
    "dict_transfer_ids = {} #Dictionary to store the dev vector ids for dataframe A(df) using the count_vectorizer of dataframe B(vect)\n",
    "transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "for vectKey in list_df:\n",
    "    dict_transfer_ids[vectKey] = {}\n",
    "    #print('vectKey',vectKey)\n",
    "    for dfKey in list_df:\n",
    "        #print('dfKey',dfKey)\n",
    "        dict_transfer_ids[vectKey][dfKey] = dict_vectorizers[vectKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "        #print(dfKey,'dataset using ',vectKey,' count vectorizer, id shapes',dict_transfer_ids[vectKey][dfKey].shape)\n",
    "        dict_dev_ypred = dict_nb[vectKey].predict(dict_transfer_ids[vectKey][dfKey])\n",
    "        acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "        #print(\"Accuracy on \",dfKey,\" dev set for binary prediction with \", vectKey,\" naive bayes model: {:.02%}\".format(acc))\n",
    "        transfer_results[vectKey][dfKey] = acc\n",
    "\n",
    "print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "print(\"Accuracy of rating predictions\")\n",
    "print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "print(transfer_results.to_string(float_format = '{:.01%}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer loss on rating predictions with Naive Bayes\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut  hnk\n",
      "toys  0.0%  0.6%  0.8% 0.3%\n",
      "vid   2.5%  0.0%  0.5% 1.3%\n",
      "aut  17.0% 12.7%  0.0% 8.5%\n",
      "hnk   6.9%  5.3% -0.0% 0.0%\n"
     ]
    }
   ],
   "source": [
    "#Calculating and displaying as transfer loss with svm\n",
    "transfer_loss = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store loss in accuracy on transfer. Col = Model, row = dataframe\n",
    "for A in list_df:\n",
    "    for B in list_df:\n",
    "        transfer_loss[A][B] = transfer_results[B][B] - transfer_results[A][B]\n",
    "print(\"Transfer loss on rating predictions with Naive Bayes\")\n",
    "print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "print(transfer_loss.to_string(float_format = '{:.01%}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating similarity / difference between domains\n",
    "\n",
    "This section calculates similarity / distance based on two possible metrics: JS Divergence, Cosine Similarity.\n",
    "In order to calculate this, we first created a word id index for all 4 datasets' reviews combined. Then we calculated the distribution of each domain on this integrated word id index to estimate the divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function to calculate JS Divergence using two discrete distributions.\n",
    "from scipy.stats import entropy\n",
    "from scipy import spatial\n",
    "#from scipy.sparse.linalg import norm\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def JSD(P, Q):\n",
    "   _P = P / norm(P, ord=1)\n",
    "   _Q = Q / norm(Q, ord=1)\n",
    "   _M = 0.5 * (_P + _Q)\n",
    "   return 0.5 * (entropy(_P, _M) + entropy(_Q, _M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 9)\n",
      "Number words in training corpus for hnk 41262\n",
      "toys (100000, 41262)\n",
      "vid (100000, 41262)\n",
      "aut (100000, 41262)\n",
      "hnk (100000, 41262)\n"
     ]
    }
   ],
   "source": [
    "#Create a vocabulary on the reviewText of all dataframes for the sake of comparing their distributions on the same baseline.\n",
    "all_df_reviews = pd.DataFrame(columns = dict_train_df[list_df[0]].columns)\n",
    "for key in list_df:\n",
    "    #print(dict_train_df[key].shape)\n",
    "    all_df_reviews = pd.concat([dict_train_df[key],all_df_reviews])\n",
    "print(all_df_reviews.shape)\n",
    "#print(type(all_df_reviews))\n",
    "#print(all_df_reviews.columns)\n",
    "\n",
    "all_vectorizer = CountVectorizer(min_df=5, max_df=0.8, stop_words='english')\n",
    "all_ids = all_vectorizer.fit_transform(all_df_reviews.reviewText)\n",
    "print(\"Number words in training corpus for\",key,len(all_vectorizer.get_feature_names()))\n",
    "\n",
    "#Create a word if distribution of each df on the integrated vocabulary ids.\n",
    "dict_allVocab_ids = {}\n",
    "for key in list_df:\n",
    "    dict_allVocab_ids[key] = all_vectorizer.transform(dict_train_df[key].reviewText)\n",
    "    print(key,dict_allVocab_ids[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Divergence\n",
      "                  toys               vid               aut               hnk\n",
      "toys             [0.0]  [0.121900206869]  [0.149253766723]  [0.129181255531]\n",
      "vid   [0.121900206869]             [0.0]  [0.197747372379]  [0.200978538535]\n",
      "aut   [0.149253766723]  [0.197747372379]             [0.0]  [0.118183647432]\n",
      "hnk   [0.129181255531]  [0.200978538535]  [0.118183647432]             [0.0]\n",
      "\n",
      "Cosine Distance\n",
      "          toys       vid          aut          hnk\n",
      "toys         0  0.345511     0.287423     0.236629\n",
      "vid   0.345511         0     0.547328     0.526993\n",
      "aut   0.287423  0.547328  2.22045e-16     0.144065\n",
      "hnk   0.236629  0.526993     0.144065 -2.22045e-16\n"
     ]
    }
   ],
   "source": [
    "JSD_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "cosine_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "for key1 in list_df:\n",
    "   for key2 in list_df:\n",
    "       dict_train_ids_1 = dict_allVocab_ids[key1].sum(axis=0).T\n",
    "       dict_train_ids_2 = dict_allVocab_ids[key2].sum(axis=0).T\n",
    "       #print(dict_allVocab_ids[key1].shape,dict_train_ids_1.shape,dict_train_ids_2.shape)\n",
    "       JSD_results[key1][key2] = JSD(dict_train_ids_1,dict_train_ids_2)\n",
    "       cosine_results[key1][key2] = spatial.distance.cosine(dict_train_ids_1,dict_train_ids_2)\n",
    "       \n",
    "print('JS Divergence')\n",
    "print(JSD_results)\n",
    "print('\\nCosine Distance')\n",
    "print(cosine_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.287422911472\n"
     ]
    }
   ],
   "source": [
    "cosine_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "from scipy import spatial\n",
    "dict_train_ids_1 = dict_allVocab_ids['toys'].sum(axis=0).T\n",
    "dict_train_ids_2 = dict_allVocab_ids['aut'].sum(axis=0).T\n",
    "result = spatial.distance.cosine(dict_train_ids_1,dict_train_ids_2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected results from past test runs\n",
    "\n",
    "#### Impact of sample size on accuracy (analysis done with Naive Bayes model, on toys dataset)\n",
    "\n",
    "Toys data set only, with bottoms up word id creation using process similar to assignment 2.\n",
    "Impact of changing size of train data set with Naive Bayes.\n",
    "\n",
    "With number in train set = 10000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 88.74%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 67.16%\n",
    "    Vocab Size : 38696\n",
    "    \n",
    "With number in train set = 50000 (excl 3 ratings)   \n",
    "    Accuracy on dev set for binary prediction: 91.33%   \n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 69.33% \n",
    "    Vocab Size : ~ ..\n",
    "    \n",
    "With number in train set = 100000 (excl 3 ratings)\n",
    "    Accuracy on dev set for binary prediction: 91.56%   \n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.42%\n",
    "    Vocab Size : 105304\n",
    "\n",
    "With number in train set = 500000, dev set = 150000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 91.73%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.95%\n",
    "    vocab size 307822\n",
    "    \n",
    "With number in train set = 1200000, dev set = 360000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 91.92%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 71.24%\n",
    "    vocab size 674074 (not repeated with correction for vocab)\n",
    "    \n",
    "#### Conclusion: There isn't a material increase in accuracy with Naive Bayes after 100000 data points in the train set.\n",
    "    \n",
    "### Output from trying different pre-processing with the toys review set.\n",
    " \n",
    " Accuracy on dev set for binary prediction: 91.69%\n",
    "classification report naive bayes binary classification \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.70      0.77      0.74     22472\n",
    "        1.0       0.96      0.94      0.95    127528\n",
    "\n",
    "avg / total       0.92      0.92      0.92    150000\n",
    "\n",
    "Accuracy on dev set for binary prediction with count vectorizer (no min, max df,stop words set): 91.92%\n",
    "classification report naive bayes binary classification with count vectorizer \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.71      0.79      0.75     22472\n",
    "        1.0       0.96      0.94      0.95    127528\n",
    "\n",
    "avg / total       0.92      0.92      0.92    150000\n",
    "\n",
    "Accuracy on dev set for binary prediction with tfidf (no min, max df,stop words set): 90.13%\n",
    "classification report naive bayes binary classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.90      0.38      0.54     22472\n",
    "        1.0       0.90      0.99      0.94    127528\n",
    "\n",
    "avg / total       0.90      0.90      0.88    150000\n",
    "\n",
    "Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.91%\n",
    "classification report naive bayes multinomial classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          1       0.60      0.74      0.66     13975\n",
    "          2       0.32      0.05      0.09      8497\n",
    "          4       0.42      0.34      0.37     29733\n",
    "          5       0.80      0.87      0.83     97795\n",
    "\n",
    "avg / total       0.68      0.71      0.68    150000\n",
    "\n",
    "#### Conclusion: CountVectorizer pre-prcocessing gives the best results with Naive Bayes.\n",
    "#### Also note that the accuracy for 4 level (1,2,4,5) prediction is much worse than for binary prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Past test runs Detailed Results for transfer learning from toys to video games\n",
    "number words in training corpus for toys: 63984    \n",
    "toys dataset id shapes (100000, 63984) (30000, 63984)    \n",
    "number words in training corpus for video games: 98899    \n",
    "videos dataset id shapes (100000, 98899) (30000, 98899)    \n",
    "number words in training corpus for automobiles: 59468    \n",
    "automobile dataset id shapes (100000, 59468) (30000, 59468)    \n",
    "number words in training corpus for home and kitchen: 57884    \n",
    "home and kitchen dataset id shapes (100000, 57884) (30000, 57884)    \n",
    "\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.23%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.74      0.74      0.74      4503\n",
    "        1.0       0.95      0.95      0.95     25497\n",
    "\n",
    "avg / total       0.92      0.92      0.92     30000\n",
    "\n",
    "Accuracy on video games dev set for binary prediction with video games naive bayes model: 89.16%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.72      0.71      0.71      5725\n",
    "        1.0       0.93      0.93      0.93     24275\n",
    "\n",
    "avg / total       0.89      0.89      0.89     30000\n",
    "\n",
    "Accuracy on autos dev set for binary prediction with autos naive bayes model: 91.93%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.78      0.61      0.69      4323\n",
    "        1.0       0.94      0.97      0.95     25677\n",
    "\n",
    "avg / total       0.91      0.92      0.92     30000\n",
    "\n",
    "Accuracy on home and kitchen dev set for binary prediction with home and kitchen naive bayes model: 91.37%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.76      0.71      0.73      5072\n",
    "        1.0       0.94      0.96      0.95     24928\n",
    "\n",
    "avg / total       0.91      0.91      0.91     30000\n",
    "\n",
    "### Transfer learning:\n",
    "\n",
    "Accuracy on video games dev set for binary prediction with toys naive bayes model: 86.99%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.66      0.65      0.66      5725\n",
    "        1.0       0.92      0.92      0.92     24275\n",
    "\n",
    "avg / total       0.87      0.87      0.87     30000\n",
    "\n",
    "Accuracy on automobiles dev set for binary prediction with toys naive bayes model: 76.06%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.36      0.88      0.51      4323\n",
    "        1.0       0.97      0.74      0.84     25677\n",
    "\n",
    "avg / total       0.88      0.76      0.79     30000\n",
    "\n",
    "Accuracy on home and kitchen dev set for binary prediction with toys naive bayes model: 85.78%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.55      0.85      0.67      5072\n",
    "        1.0       0.97      0.86      0.91     24928\n",
    "\n",
    "avg / total       0.90      0.86      0.87     30000\n",
    "\n",
    "Accuracy on toys dev set for binary prediction with video games naive bayes model: 91.53%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.76      0.63      0.69      4503\n",
    "        1.0       0.94      0.97      0.95     25497\n",
    "\n",
    "avg / total       0.91      0.92      0.91     30000\n",
    "\n",
    "Accuracy on automobiles dev set for binary prediction with video games naive bayes model: 80.50%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.41      0.77      0.53      4323\n",
    "        1.0       0.96      0.81      0.88     25677\n",
    "\n",
    "avg / total       0.88      0.81      0.83     30000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
