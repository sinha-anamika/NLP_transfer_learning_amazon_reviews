{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnnlm' from '/home/reachanamikasinha/project/rnnlm.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# NumPy and SciPy for matrix ops\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# NLTK for NLP utils\n",
    "import nltk\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import vocabulary, tf_embed_viz, glove_helper\n",
    "from w266_common import utils; reload(utils)\n",
    "import rnnlm; reload(rnnlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.100d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 100))\n"
     ]
    }
   ],
   "source": [
    "#Using pretrained GLove embeddings\n",
    "hands = glove_helper.Hands(ndim=100)  # 50, 100, 200, 300 dim are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400003, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.412991046905518\n"
     ]
    }
   ],
   "source": [
    "#Reading back from the pickle file\n",
    "start =time.time()\n",
    "df_hnk = pd.read_pickle('./home_df.pkl')\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#working_df = df_hnk\n",
    "working_df = df_hnk[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Subset the data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(working_df['reviewText'], \n",
    "                                                    #working_df['overall'],\n",
    "                                                    working_df['polarity'],\n",
    "                                                    test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2369885    This unit lasted 2 summers.  At the end of the...\n",
      "2371835    Nothing to write home about.  If you just want...\n",
      "3781582    THIS IS MY SECOND PURCHASE OF THIS COSMETIC BA...\n",
      "3422088    So I've recently purchased the 'ProPur Big' sy...\n",
      "3139971    Unfortunately the dish drain is too flat, most...\n",
      "Name: reviewText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/reachanamikasinha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "x_train_tokens_list length 800\n",
      "Vocabulary size: 4,372\n",
      "Total words  45945\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing steps\n",
    "\n",
    "#Changing to nltk punkt tokenizer as the periods are not getting removed\n",
    "print(X_train.shape[0])\n",
    "\n",
    "train_cnt = collections.Counter()\n",
    "x_train_tokens_list = []\n",
    "start = time.time()\n",
    "for i in range(X_train.shape[0]):\n",
    "\n",
    "    x_train_tokens = word_tokenize(X_train.iloc[i])\n",
    "    \n",
    "    \n",
    "\n",
    "    #2. changing to lowercase and replacing numbers(are we losing any context by \n",
    "    #replacing all numbers in the review test? Are we losing any context here)\n",
    "    x_tokens_canonical = utils.canonicalize_words(x_train_tokens)\n",
    "    \n",
    "    x_train_tokens_list.append(x_tokens_canonical)\n",
    "    \n",
    "\n",
    "    #3. Build vocabulary\n",
    "    for items in x_tokens_canonical:\n",
    "            train_cnt[items] += 1\n",
    "            \n",
    "vocab = vocabulary.Vocabulary(train_cnt, size=None)  # size=None means unlimited\n",
    "total_words = sum(train_cnt.values())\n",
    "print(\"x_train_tokens_list length\", len(x_train_tokens_list))\n",
    "print(\"Vocabulary size: {:,}\".format(vocab.size))\n",
    "#print(\"Vocabulary dict: \", vocab.word_to_id)\n",
    "print(\"Total words \",total_words )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "x_test_tokens_list length 200\n",
      "Total words  12199\n",
      "Average number of words per review:  60.995\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing steps for dev set\n",
    "\n",
    "#Changing to nltk punkt tokenizer as the periods are not getting removed\n",
    "print(X_test.shape[0])\n",
    "\n",
    "test_cnt = collections.Counter()\n",
    "x_test_tokens_list = []\n",
    "start = time.time()\n",
    "for i in range(X_test.shape[0]):\n",
    "\n",
    "    x_test_tokens = word_tokenize(X_test.iloc[i])\n",
    "    \n",
    "    \n",
    "\n",
    "    #2. changing to lowercase and replacing numbers(are we losing any context by \n",
    "    #replacing all numbers in the review test? Are we losing any context here)\n",
    "    x_tokens_canonical = utils.canonicalize_words(x_test_tokens)\n",
    "    \n",
    "    x_test_tokens_list.append(x_tokens_canonical)\n",
    "    \n",
    "\n",
    "    #3. Build vocabulary\n",
    "    for items in x_tokens_canonical:\n",
    "            test_cnt[items] += 1\n",
    "            \n",
    "\n",
    "total_words = sum(test_cnt.values())\n",
    "print(\"x_test_tokens_list length\", len(x_test_tokens_list))\n",
    "\n",
    "print(\"Total words \",total_words )\n",
    "print('Average number of words per review: ', total_words/X_test.shape[0])\n",
    "#Average number of words per review helps us figure out the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saw', 'this', 'book', 'in', 'my', 'local', 'library', '.', 'borrowed', 'it', 'and', 'simply', 'loved', 'it', '.', 'could', \"n't\", 'wait', 'to', 'get', 'my', 'own', 'copy', '.', 'just', 'love', 'all', 'the', 'beautiful', 'pictures', 'in', 'here', '.', 'finally', 'got', 'it', 'from', 'amazon', 'and', 'it', \"'s\", 'mine', '!', '!', 'no', 'need', 'to', 'borrow', 'from', 'the', 'library', 'anymore', '.']\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tokens_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting all reviews to ids \n",
    "train_id_list = []\n",
    "for item in x_train_tokens_list:\n",
    "    train_id_list.append(vocab.words_to_ids(item))\n",
    "    \n",
    "test_id_list = []\n",
    "for item in x_test_tokens_list:\n",
    "    test_id_list.append(vocab.words_to_ids(item))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saw', 'this', 'book', 'in', 'my', 'local', 'library', '.', 'borrowed', 'it', 'and', 'simply', 'loved', 'it', '.', 'could', \"n't\", 'wait', 'to', 'get', 'my', 'own', 'copy', '.', 'just', 'love', 'all', 'the', 'beautiful', 'pictures', 'in', 'here', '.', 'finally', 'got', 'it', 'from', 'amazon', 'and', 'it', \"'s\", 'mine', '!', '!', 'no', 'need', 'to', 'borrow', 'from', 'the', 'library', 'anymore', '.']\n"
     ]
    }
   ],
   "source": [
    "print((x_train_tokens_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 12, 10, 16, 17, 18, 19, 20, 7, 21, 22, 10, 23, 24, 25, 26, 27, 28, 6, 29, 10, 30, 31, 12, 32, 33, 13, 12, 34, 35, 36, 36, 37, 38, 19, 39, 32, 26, 9, 40, 10]\n"
     ]
    }
   ],
   "source": [
    "print((train_id_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'bought', 'this', 'because', 'i', 'have', \"n't\", 'found', 'time', 'to', 'take', 'the', 'class', 'and', 'found', 'it', \"'s\", 'pretty', 'easy', 'to', 'follow', 'along', 'and', 'teach', 'yourself', 'everything', 'in', 'the', 'book', '.', 'there', 'is', 'step', 'by', 'step', 'instructions', 'for', 'different', 'designs', 'and', 'ideas', 'and', 'lots', 'of', 'hints', 'and', 'tricks', 'for', 'working', 'with', 'fondant', 'and', 'gumpaste', '.']\n"
     ]
    }
   ],
   "source": [
    "print((x_test_tokens_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41, 195, 4, 197, 41, 83, 17, 247, 243, 19, 257, 26, 424, 13, 247, 12, 34, 326, 234, 19, 608, 1163, 13, 1282, 1192, 344, 6, 26, 5, 10, 380, 79, 623, 426, 623, 179, 43, 659, 399, 13, 415, 13, 260, 74, 3015, 13, 637, 43, 806, 70, 371, 13, 996, 10]\n"
     ]
    }
   ],
   "source": [
    "print((test_id_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4301, 76, 4302, 305, 4149, 570, 166, 76, 54, 41, 138, 4, 145, 223, 80, 19, 235, 95, 44, 704, 168, 76, 41, 4303, 26, 147, 6, 12, 4304, 3428, 970, 10, 915, 706, 1326, 706, 50, 17, 412, 706, 983, 343, 19, 235, 12, 43, 1457, 76, 12, 34, 23, 489, 2088, 43, 245, 36, 979, 13, 1612, 2496, 498, 289, 12, 232, 87, 2659, 10]\n"
     ]
    }
   ],
   "source": [
    "print(max((train_id_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest review: 2\n",
      "Longest revies: 574\n"
     ]
    }
   ],
   "source": [
    "review_lengths = [len(review) for review in train_id_list]\n",
    "print(\"Shortest review:\", min(review_lengths))\n",
    "print(\"Longest review:\",max(review_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBERQAFBRESC/w8aVS4nQDGIJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b06629c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.axes()\n",
    "sns.distplot(review_lengths)\n",
    "ax.set_title(\"Distribution of the review lengths\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.431250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>55.240267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  800.000000\n",
       "mean    57.431250\n",
       "std     55.240267\n",
       "min      2.000000\n",
       "25%     27.000000\n",
       "50%     37.000000\n",
       "75%     68.000000\n",
       "max    574.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(review_lengths).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding padding to each review less than max_length and cutting off reviews greater than max length\n",
    "max_length = 200\n",
    "\n",
    "train_ids, z = utils.pad_np_array(train_id_list, max_len=200) \n",
    "test_ids, z = utils.pad_np_array(train_id_list, max_len=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 200)\n"
     ]
    }
   ],
   "source": [
    "print(train_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  5  6  7  8  9 10 11 12 13 14 15 12 10 16 17 18 19 20  7 21 22 10 23\n",
      " 24 25 26 27 28  6 29 10 30 31 12 32 33 13 12 34 35 36 36 37 38 19 39 32 26\n",
      "  9 40 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(train_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219753\n",
      "800\n",
      "[   0  776   44 1112    2 1250  777   41  776    2 3275 2181 2181    2\n",
      "    2   41 2498    2    2    2    2    2 2181 3776   44    2    2    2\n",
      "   41 3275    2   44    2    2   10    2    2 3275 2181    2    2 2181\n",
      " 1112    2 3873    2   41 1250    2   44 2498 3873    2  776   41    2\n",
      "    2    2    2    2    2 2181    2    2 3873    2   41 1250   10    2\n",
      "    2 3776 2181 2935    2 3873 2498 2028 1250    2 1112   44   41 1250\n",
      "    2 1250 2181    2    2    2 1250    2    2    2    2 2181 1112 2498\n",
      "    2 3776]\n",
      "29     Saw this book in my local library.  Borrowed i...\n",
      "535    i purchased this for a friend who enjoys cake ...\n",
      "Name: reviewText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(train_ids))\n",
    "print(len(X_train))\n",
    "print(train_ids[0:100])\n",
    "print(X_train[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.output_ (?, ?, 200)\n",
      "self.output_[:, -1] (?, 200)\n",
      "self.predictions (?, 1)\n",
      "self.target (?, ?)\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "\n",
    "TF_GRAPHDIR = \"/tmp/w266/a4_graph\"\n",
    "\n",
    "# Clear old log directory.\n",
    "shutil.rmtree(TF_GRAPHDIR, ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(V=vocab.size, H=200, num_layers=2, gl_embed=hands.W)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "#lm.BuildSamplerGraph()\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(TF_GRAPHDIR, lm.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=0.1):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "    loss = lm.loss_\n",
    "    if train:\n",
    "        #train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "        \n",
    "    else:\n",
    "        #train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "        \n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator, 0):\n",
    "        #print('w shape', w.shape)\n",
    "        #print('y shape', y.shape)\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "        \n",
    "        \n",
    "        #### YOUR CODE HERE ####\n",
    "        \n",
    "       \n",
    "        feed_dict = {lm.input_w_: w, lm.initial_h_: h, lm.target_y_: y,  lm.learning_rate_: learning_rate, lm.use_dropout_ : use_dropout}\n",
    "\n",
    "        cost,h, _ = session.run([loss, lm.final_h_,lm.optimizer], feed_dict=feed_dict)   \n",
    "         \n",
    "        #### END(YOUR CODE) ####\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print(\"[batch {:d}]: seen {:d} words at {:.1f} wps, loss = {:.3f}\".format(\n",
    "                i, total_words, avg_wps, avg_cost))\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = utils.rnnlm_batch_generator(ids, batch_size=100, max_time=200)\n",
    "    cost = run_epoch(lm, session, batch_iterator=bi, \n",
    "                     learning_rate=1.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print(\"{:s}: avg. loss: {:.03f}  (perplexity: {:.02f})\".format(name, cost, np.exp(cost)))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(ids, labels, batch_size=100):\n",
    "    \n",
    "    n_batches = len(ids)//batch_size\n",
    "    ids, labels = ids[:n_batches*batch_size], labels[:n_batches*batch_size]\n",
    "    \n",
    "    for ii in range(0, len(ids), batch_size):\n",
    "        yield ids[ii:ii+batch_size], labels[ii:ii+batch_size]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "V= vocab.size\n",
    "max_time = 200 #max_sequence_length\n",
    "batch_size = 50\n",
    "learning_rate = 0.01\n",
    "num_epochs = 2\n",
    "#num_epochs = 5\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=100, \n",
    "                    softmax_ns=200,\n",
    "                    num_layers=1,\n",
    "                   gl_embed=hands.W)\n",
    "\n",
    "TF_SAVEDIR = \"/tmp/w266/a4_model\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.output_ (?, ?, 100)\n",
      "self.output_[:, -1] (?, 100)\n",
      "self.predictions (?, 1)\n",
      "self.target (?,)\n",
      "[epoch 1] Starting epoch 1\n",
      "[epoch 1] Completed in 0:00:06\n",
      "[epoch 1] \n",
      "[epoch 2] Starting epoch 2\n",
      "[epoch 2] Completed in 0:00:06\n",
      "[epoch 2] \n"
     ]
    }
   ],
   "source": [
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        #bi = utils.rnnlm_batch_generator(train_ids, y_train, batch_size, max_time)\n",
    "        bi = batch_generator(train_ids, y_train, batch_size)\n",
    "        print(\"[epoch {:d}] Starting epoch {:d}\".format(epoch, epoch))\n",
    "        #### YOUR CODE HERE ####\n",
    "        # Run a training epoch.\n",
    "        \n",
    "        avg_cost = run_epoch(lm, session, bi,\n",
    "              train=True, verbose=False,\n",
    "              tick_s=10, learning_rate=0.01)\n",
    "    \n",
    "        \n",
    "        \n",
    "        #### END(YOUR CODE) ####\n",
    "        \n",
    "        if (i % print_interval == 0):\n",
    "            print(\"[epoch %d] seen %d minibatches\" % (epoch, i))\n",
    "        \n",
    "        print(\"[epoch {:d}] Completed in {:s}\".format(epoch, utils.pretty_timedelta(since=t0_epoch)))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "#       score_dataset(lm, session, train_ids, name=\"Train set\")\n",
    "#         print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "#         score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
