{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the save now works\n"
     ]
    }
   ],
   "source": [
    "# !sudo pip install -U nltk\n",
    "# !sudo pip install wget\n",
    "# !sudo pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 (default, Nov 23 2017, 16:37:01) \n",
      "[GCC 5.4.0 20160609]\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "# Install a few python packages using pip\n",
    "#from common import utils\n",
    "from common import utils\n",
    "utils.require_package('nltk')\n",
    "utils.require_package(\"wget\")      # for fetching dataset\n",
    "#from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_curve, auc\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys, time\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "# Numerical manipulation libraries.\n",
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "#comment or uncomment based on anamika/ arunima\n",
    "# Helper libraries\n",
    "# from common import utils, vocabulary, glove_helper\n",
    "\n",
    "# from common import utils, vocabulary\n",
    "from common import utils, vocabulary\n",
    "from common import glove_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read the amazon review data files\n",
    "def parse(path):\n",
    "  print('start parse')\n",
    "  start_parse = time.time()\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "  end_parse = time.time()\n",
    "  print('end parse with time for parse',end_parse - start_parse)\n",
    "\n",
    "def getDF(path):\n",
    "  print('start getDF')\n",
    "  start = time.time()\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  print('end getDF')\n",
    "  end = time.time()\n",
    "  print('time taken to load data = ',end-start)\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "#df = getDF('reviews_Toys_and_Games.json.gz') #old def function corresponding to the step bt step vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.100d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 100))\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Using pretrained GLove embeddings\n",
    "hands = glove_helper.Hands(ndim=100)  # 50, 100, 200, 300 dim are available\n",
    "hands.shape\n",
    "print(hands.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please note that i had to comment out the path. Please uncomment before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 125.74523878097534\n",
      "end getDF\n",
      "time taken to load data =  125.74552416801453\n"
     ]
    }
   ],
   "source": [
    "#df_toys = getDF('/newvolume/reviews_Toys_and_Games.json.gz')\n",
    "df_toys = getDF('reviews_Toys_and_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 84.4864284992218\n",
      "end getDF\n",
      "time taken to load data =  84.48704028129578\n"
     ]
    }
   ],
   "source": [
    "#df_vid = getDF('/newvolume/reviews_Video_Games.json.gz')\n",
    "df_vid = getDF('reviews_Video_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 76.17380952835083\n",
      "end getDF\n",
      "time taken to load data =  76.17444372177124\n"
     ]
    }
   ],
   "source": [
    "#df_aut = getDF('/newvolume/reviews_Automotive.json.gz')\n",
    "df_aut = getDF('reviews_Automotive.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 242.47316074371338\n",
      "end getDF\n",
      "time taken to load data =  242.4738221168518\n"
     ]
    }
   ],
   "source": [
    "df_hnk = getDF('reviews_Home_and_Kitchen.json.gz')\n",
    "#df_hnk = getDF('/newvolume/reviews_Home_and_Kitchen.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Home and Kitchen reviews examples\n",
      "\n",
      "A210NOCSTBT4OD\n",
      "Have you ever thought about how you met your best friend? Was it normal, or was it wacky - like how Elias met Shohei? Pulling a boa constrictor snake named Mathilda out of your backpack can make a remarkable first impression! This book is about three best friends Elias, Honoria, and Shohei, who are united against \"That Which Is The Peshtigo School\". Their goal is to make it through the annual school science fair, but things don't always go as planned.Elias is part of a family made up of science fanatics who would do anything to win a science fair. Elias isn't exactly what you'd call the ambitious type, especially when it comes to science fairs. So he becomes like Galileo and \"retests\" one of his sibling's past projects. Honoria loves to be ambitious, especially when it comes to being a legal counsel extraordinaire. But when she faces a bigger challenge than beating Goliath Reed or getting a piranha to become vegetarian, she doesn't know if she can make it. Shohei is an all around slacker who tries to mooch off Elias instead of creating something on his own. His adoptive parents are constantly encouraging him to start \"hearing\" his ancestors. His mom has even turned Shohei's room into what looks like a walk-in Japanese museum exhibit!This book is laugh out loud hilarious and the more you read, the more exciting and unexpected it gets. I love the title on this book because it really made me laugh and want to read the book. I also like how people so different from one another can be such close friends. There is not much excitement in the beginning, but it builds up very quickly. So if you like that type of story, then this is the book for you.\n",
      "A28ILV4TOG8BH2\n",
      "The butter dish is serving us well, and keeping the butter fresh and healthy. Couldn't be happier with it, and the color is a pleasing green.\n"
     ]
    }
   ],
   "source": [
    "#Looking at a few examples of review text\n",
    "# print('Toys reviews examples\\n')\n",
    "# for i in range(1):\n",
    "#     print(df_toys['reviewerID'].iloc[i])\n",
    "#     print(df_toys['reviewText'].iloc[i])\n",
    "\n",
    "# print('\\n Video games reviews examples\\n')\n",
    "# for i in range(1):\n",
    "#     print(df_vid['reviewerID'].iloc[i])\n",
    "#     print(df_vid['reviewText'].iloc[i])\n",
    "    \n",
    "# print('\\n Automobile reviews examples\\n')\n",
    "# for i in range(1):\n",
    "#     print(df_aut['reviewerID'].iloc[i])\n",
    "#     print(df_aut['reviewText'].iloc[i])\n",
    "    \n",
    "print('\\n Home and Kitchen reviews examples\\n')\n",
    "for i in range(2):\n",
    "    print(df_hnk['reviewerID'].iloc[i])\n",
    "    print(df_hnk['reviewText'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy reviews train, dev and test set dataframe shape: (1351662, 9) (450554, 9) (450555, 9)\n",
      "Video games reviews train, dev and test set dataframe shape: (794851, 9) (264951, 9) (264951, 9)\n",
      "Auto reviews train, dev and test set dataframe shape: (824260, 9) (274754, 9) (274754, 9)\n",
      "Home and Kitchen reviews train, dev and test set dataframe shape: (2552355, 9) (850785, 9) (850786, 9)\n"
     ]
    }
   ],
   "source": [
    "# Create train,dev,test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_toys,devtest = train_test_split(df_toys, test_size=0.4, random_state=42)\n",
    "dev_toys,test_toys = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "print('Toy reviews train, dev and test set dataframe shape:',train_toys.shape,dev_toys.shape,test_toys.shape)\n",
    "\n",
    "#For Video games reviews\n",
    "train_vid,devtest = train_test_split(df_vid, test_size=0.4, random_state=42)\n",
    "dev_vid,test_vid = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "print('Video games reviews train, dev and test set dataframe shape:',train_vid.shape,dev_vid.shape,test_vid.shape)\n",
    "\n",
    "#For Auto reviews\n",
    "train_aut,devtest = train_test_split(df_aut, test_size=0.4, random_state=42)\n",
    "dev_aut,test_aut = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "print('Auto reviews train, dev and test set dataframe shape:',train_aut.shape,dev_aut.shape,test_aut.shape)\n",
    "\n",
    "#For Home and Kitchen reviews\n",
    "train_hnk,devtest = train_test_split(df_hnk, test_size=0.4, random_state=42)\n",
    "dev_hnk,test_hnk = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "print('Home and Kitchen reviews train, dev and test set dataframe shape:',train_hnk.shape,dev_hnk.shape,test_hnk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a smaller sized train and dev data set. Enables testing accuracy for different sizes.\n",
    "#Also binarizes the labels. Ratings of 1,2 and to 0; Ratings of 4,5 to 1.\n",
    "\n",
    "def set_df_size(size,data_train,data_dev):\n",
    "    size_train = size\n",
    "    len_max_train = data_train[data_train.overall!=3].shape[0] #max possible length of train data set taking out the 3 ratings.\n",
    "    #print(\"Number of reviews with ratings != 3 in train set\",len_max_train)\n",
    "    temp_size_train = min(len_max_train,size_train)\n",
    "\n",
    "    len_max_dev = data_dev[data_dev.overall!=3].shape[0]\n",
    "    #print(\"Number of reviews with ratings != 3 in dev set\",len_max_dev)\n",
    "    temp_size_dev = min(len_max_dev,int(0.3*temp_size_train)) #making the dev set about 0.3 times the train set.\n",
    "\n",
    "    temp_train_data = data_train[data_train.overall != 3][:temp_size_train]\n",
    "    #print('Size of train data',temp_train_data.shape)\n",
    "    #print(temp_train_data.groupby('overall').count())\n",
    "    #print(temp_train_toys[:5])\n",
    "\n",
    "    temp_dev_data = data_dev[data_dev.overall!=3][:temp_size_dev]\n",
    "    #print('Size of dev data',temp_dev_data.shape)\n",
    "    #print(temp_dev_data.groupby('overall').count())\n",
    "    #print(temp_dev_data[:2])\n",
    "    \n",
    "    #Binarize ratings\n",
    "    temp_train_y = np.zeros(temp_size_train)\n",
    "    temp_train_y[temp_train_data.overall > 3] = 1\n",
    "    temp_dev_y = np.zeros(temp_size_dev)\n",
    "    temp_dev_y[temp_dev_data.overall>3] = 1\n",
    "    #print('binarized y shape',temp_train_y.shape,temp_dev_y.shape)\n",
    "    #print(temp_dev_y[:20],data_dev.overall[:20])\n",
    "    return temp_train_data,temp_dev_data,temp_train_y,temp_dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = ['toys','vid','aut','hnk'] #list of keys that refer to each dataframe. Adding a new dataframe would require updating this list\n",
    "dict_train_df = {} #Dict to store train input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_dev_df = {} #Dict to store dev input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_train_y = {} #Dict to store binarized train data label for each domain\n",
    "dict_dev_y = {} #Dict to store binarized dev data label for each domain\n",
    "#print(len(dict_train_df))\n",
    "\n",
    "size_initial = 500000\n",
    "def create_sized_data(size = 10000):\n",
    "    size_train = size #Set size of train set here. This is a hyperparameter.\n",
    "    key = list_df[0]\n",
    "    #print('Toys reviews\\n')\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_toys,dev_toys)\n",
    "    #print('\\n Video games reviews\\n')\n",
    "    key = list_df[1]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_vid,dev_vid)\n",
    "    #print('\\n Auto reviews\\n')\n",
    "    key = list_df[2]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_aut,dev_aut)\n",
    "    #print('\\n Home and Kitchen reviews\\n')\n",
    "    key = list_df[3]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_hnk,dev_hnk)\n",
    "    \n",
    "create_sized_data(size_initial)\n",
    "#create_sized_data(500)\n",
    "#print(len(dict_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_processor = tflearn.data_utils.VocabularyProcessor(max_length, min_frequency=0)\n",
    "#Note : Above function was used instead of the below, which is deprecated. \n",
    "# vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(max_length)\n",
    "\n",
    "def process_inputs(key, vocab_processor):\n",
    "    \n",
    "    start_vectorize = time.time()\n",
    "    x_train = dict_train_df[key].reviewText\n",
    "    y_train = dict_train_y[key]\n",
    "    x_dev = dict_dev_df[key].reviewText\n",
    "    y_dev = dict_dev_y[key]\n",
    "    print(x_train.shape)\n",
    "    \n",
    "    # Train the vocab_processor from the training set\n",
    "    x_train = vocab_processor.fit_transform(x_train)\n",
    "    # Transform our test set with the vocabulary processor\n",
    "    x_dev = vocab_processor.transform(x_dev)\n",
    "\n",
    "    # We need these to be np.arrays instead of generators\n",
    "    x_train = np.array(list(x_train))\n",
    "    print(x_train.shape)\n",
    "    x_dev = np.array(list(x_dev))\n",
    "    y_train = np.array(y_train).astype(int)\n",
    "    y_dev = np.array(y_dev).astype(int)\n",
    "    \n",
    "#     y_train = tf.expand_dims(y_train,1)\n",
    "#     y_dev = tf.expand_dims(y_dev,1)\n",
    "    print('y train shape',y_train.shape)\n",
    "\n",
    "    V = len(vocab_processor.vocabulary_)\n",
    "    print('Total words: %d' % V)\n",
    "    end_vectorize = time.time()\n",
    "    print('Time taken to vectorize %d size dataframe'%x_train.shape[0],end_vectorize-start_vectorize)\n",
    "\n",
    "    # Return the transformed data and the number of words\n",
    "    return x_train, y_train, x_dev, y_dev, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toys\n",
      "(500000,)\n",
      "(500000, 150)\n",
      "y train shape (500000,)\n",
      "Total words: 108144\n",
      "Time taken to vectorize 500000 size dataframe 81.25163102149963\n",
      "Number words in training corpus for toys 108144\n",
      "toys dataset id shapes (500000, 150) (150000, 150)\n",
      "sample review for domain toys It's just the model I was hoping for and more. It's challenging and has given me something more to learn in developing my model building skills. Revell as always makes good models to build! \n",
      "\n",
      "corresponding ids\n",
      " [ 114   41    1  378    6   15 1122    8    2   58  114  796    2   42  632\n",
      "   96  229   58    3  399   12 4088   14  378  541  768 6220   22  272  223\n",
      "   66  935    3  393    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0] \n",
      "\n",
      "vid\n",
      "(500000,)\n",
      "(500000, 150)\n",
      "y train shape (500000,)\n",
      "Total words: 162546\n",
      "Time taken to vectorize 500000 size dataframe 131.60494947433472\n",
      "Number words in training corpus for vid 162546\n",
      "vid dataset id shapes (500000, 150) (150000, 150)\n",
      "sample review for domain vid First things first. I love the Lego games. So, my view on this game is skewed. This game follows the typical Lego quality game with a slight change in game play. When playing with two players, the screen splits, which is great, because you don't have to drop out all the time. However, watch changing players or using Jack's compass when the screen is split because it will sometimes freeze up on you. If you like Legos, the other Lego games, or Pirates of the Carribean, then this game is for you. \n",
      "\n",
      "corresponding ids\n",
      " [  534   171    78     5    92     1  1669    29   182    24   976    19\n",
      "    11     9     6 15187    37     9  2416     1  1751  1669   285     9\n",
      "    15     4  2121   394    13     9    34   286    75    15   157   274\n",
      "     1   253 14173    69     6    42    77    10    81    16     3  1126\n",
      "    44    30     1    53   312   656  1849   274    32   244 19994 11197\n",
      "    57     1   253     6  2301    77     8    43   446  2316    47    19\n",
      "    10    84    10    26  9900     1    70  1669    29    32  5409     7\n",
      "     1 26731    96    11     9     6    12    10     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0] \n",
      "\n",
      "aut\n",
      "(500000,)\n",
      "(500000, 150)\n",
      "y train shape (500000,)\n",
      "Total words: 95702\n",
      "Time taken to vectorize 500000 size dataframe 76.52182483673096\n",
      "Number words in training corpus for aut 95702\n",
      "aut dataset id shapes (500000, 150) (150000, 150)\n",
      "sample review for domain aut THE OLD LIGHTS WERE FOGGED OVER WITH THE NEW ONES MAKES DRIVING AT NIGHT A LOT SAFER A LOT BRIGHTER AND THEY WERE EASY TO INSTALL. \n",
      "\n",
      "corresponding ids\n",
      " [  399  5252  5846  4792 59723  5118  1613   399  2958 10655  8982 11931\n",
      "  2236 13544   175  3136 38635   175  3136 21198   580  1920  4792  2799\n",
      "   699  4138     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0] \n",
      "\n",
      "hnk\n",
      "(500000,)\n",
      "(500000, 150)\n",
      "y train shape (500000,)\n",
      "Total words: 96380\n",
      "Time taken to vectorize 500000 size dataframe 88.46836566925049\n",
      "Number words in training corpus for hnk 96380\n",
      "hnk dataset id shapes (500000, 150) (150000, 150)\n",
      "sample review for domain hnk These barstools are amazing. After scouring stores and the internet, I decided that these would be my best bet. I needed sturdy stools to deal with heavy use from kids, family, ect. They are 1000% solid. When they arrive you have to screw the seat onto the base swivel mechanism, however all the important parts that make it solid are already in place. You also have to attach the solid wooden seat onto the frame. The seat isn't pre-drilled so that is a bit annoying. Not hard, but annoying. These stools are going to last a very long time, without a doubt. I wouldn't hesitate to buy more. They feel stronger, more solid, and of higher quality than stools I saw for $300 each. I was a little nervous they would look clunky, but they are beautiful with very nice lines. I wish I would have ordered them two months ago when I first saw them.I forgot to mention the box was delivered to my door within two days. Fastest shipping ever. \n",
      "\n",
      "corresponding ids\n",
      " [  177 11181    23   604   275  8919   737     3     1  2455     2   392\n",
      "    12    53    40    28    13   182  3929     2   243   224  2544     4\n",
      "   443    14   247    29    46   531   441  7701    99    23  3485   534\n",
      "   260    36  1991    20    15     4   886     1  1514   930     1   551\n",
      "  3056  1513   516    42     1  1093   500    12    85     6   534    23\n",
      "   458    11   277   202    95    15     4  1632     1   534  1316  1514\n",
      "   930     1   694    18  1514   463  6192    24    12     7     5   180\n",
      "  1355   293   237    19  1355   177  2544    23   231     4   190     5\n",
      "    27   154    54   170     5  1872     2   541  2330     4   104    49\n",
      "    99   272  2264    49   534     3     8   969    93    50  2544     2\n",
      "   598     9  2246   332     2    17     5    69  3150    36    40   159\n",
      "  5719    19    36    23   354    14    27    86  1888     2   370     2\n",
      "    40    15   225    41   108   221] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting reviews to ids for all domains and add padding.\n",
    "\n",
    "# Hyperparameters\n",
    "min_frequency = 1\n",
    "max_length = 150\n",
    "\n",
    "dict_vectorizers = {} #Dict to store the vocab_processor fit on each domain\n",
    "dict_train_ids = {} #Dict to store train data reviews as sparse matrix of word ids\n",
    "dict_dev_ids = {} #Dict to store dev data reviews as sparse matrix of word ids\n",
    "dict_cnn = {} #Dict to store cnn model developed on each domain. Assumes input features are developed using the corresponding count_vectorizer\n",
    "dict_dev_ypred = {} #Dict to store dev predictions\n",
    "dict_vocab_len = {} #Store vocab length of each domain\n",
    "for key in list_df:\n",
    "    \n",
    "    #Converting ratings to tokenized word id counts as a sparse matrix using count_vectorizer\n",
    "    dict_vectorizers[key] = tflearn.data_utils.VocabularyProcessor(max_length, min_frequency=min_frequency)\n",
    "    print(key)\n",
    "    dict_train_ids[key], dict_train_y[key],dict_dev_ids[key], dict_dev_ypred[key], dict_vocab_len[key] = process_inputs(key,dict_vectorizers[key])\n",
    "    \n",
    "    print(\"Number words in training corpus for\",key,(dict_vocab_len[key]))\n",
    "    print(key,'dataset id shapes',dict_train_ids[key].shape, dict_dev_ids[key].shape)\n",
    "\n",
    "    #Print a few examples for viewing\n",
    "    print('sample review for domain',key, dict_train_df[key].reviewText.iloc[3],'\\n')\n",
    "    print('corresponding ids\\n',dict_train_ids[key][3],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toys (100000,)\n",
      "(array([58987, 24503,  8678,  3490,  1674,   922,   556,   370,   242,\n",
      "         159,    95,    68,    57,    43,    38,    31,    20,    10,\n",
      "           8,    49]), array([    0.,    50.,   100.,   150.,   200.,   250.,   300.,   350.,\n",
      "         400.,   450.,   500.,   550.,   600.,   650.,   700.,   750.,\n",
      "         800.,   850.,   900.,   950.,  1000.]))\n",
      "Number less than 100 83712\n",
      "Number less than 150 92223\n",
      "Number less than 175 94288\n",
      "Number less than 200 95652\n",
      "vid (100000,)\n",
      "(array([47996, 21688, 10292,  5920,  3620,  2440,  1692,  1282,   994,\n",
      "         680,   601,   459,   377,   307,   253,   194,   183,   143,\n",
      "         127,   752]), array([    0.,    50.,   100.,   150.,   200.,   250.,   300.,   350.,\n",
      "         400.,   450.,   500.,   550.,   600.,   650.,   700.,   750.,\n",
      "         800.,   850.,   900.,   950.,  1000.]))\n",
      "Number less than 100 69913\n",
      "Number less than 150 80111\n",
      "Number less than 175 83353\n",
      "Number less than 200 85960\n",
      "aut (100000,)\n",
      "(array([63741, 22809,  7245,  2918,  1404,   677,   456,   216,   166,\n",
      "         103,    87,    43,    27,    27,    20,    12,    10,     8,\n",
      "           5,    26]), array([   0.  ,   49.85,   99.7 ,  149.55,  199.4 ,  249.25,  299.1 ,\n",
      "        348.95,  398.8 ,  448.65,  498.5 ,  548.35,  598.2 ,  648.05,\n",
      "        697.9 ,  747.75,  797.6 ,  847.45,  897.3 ,  947.15,  997.  ]))\n",
      "Number less than 100 86739\n",
      "Number less than 150 93835\n",
      "Number less than 175 95556\n",
      "Number less than 200 96718\n",
      "hnk (100000,)\n",
      "(array([56142, 25500,  9051,  4115,  2030,  1087,   604,   433,   282,\n",
      "         185,   158,   116,    63,    47,    46,    22,    22,     9,\n",
      "          16,    72]), array([   0.  ,   49.95,   99.9 ,  149.85,  199.8 ,  249.75,  299.7 ,\n",
      "        349.65,  399.6 ,  449.55,  499.5 ,  549.45,  599.4 ,  649.35,\n",
      "        699.3 ,  749.25,  799.2 ,  849.15,  899.1 ,  949.05,  999.  ]))\n",
      "Number less than 100 81876\n",
      "Number less than 150 90765\n",
      "Number less than 175 93165\n",
      "Number less than 200 94837\n"
     ]
    }
   ],
   "source": [
    "#This code was used to pick max_length for all domains for the CNN, by using a sample of 100000, and a max_length of 10000 for analysis\n",
    "#it is not needed for running the CNN.\n",
    "# for key in list_df:\n",
    "#     length = np.count_nonzero(dict_train_ids[key],axis = 1)\n",
    "#     print(key,length.shape)\n",
    "#     print(np.histogram(length,bins = 20))\n",
    "#     print(\"Number less than 100\",np.count_nonzero(length[length <= 100]))\n",
    "#     print(\"Number less than 150\",np.count_nonzero(length[length <= 150]))\n",
    "#     print(\"Number less than 175\",np.count_nonzero(length[length <= 175]))\n",
    "#     print(\"Number less than 200\",np.count_nonzero(length[length <= 200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(y_train.shape)\n",
    "# print(y_dev.shape)\n",
    "# print(np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__( self, sequence_length, num_classes, vocab_size, learning_rate, momentum, embedding_size, \n",
    "                 gl_embed, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.int32, [None], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "\n",
    "        with tf.name_scope(\"embedding\"):\n",
    "            #self.W = tf.get_variable(\"W_in\",[vocab_size, embedding_size],initializer =tf.random_uniform_initializer(0,1)) #from wildML\n",
    "            self.W=tf.get_variable(name=\"embedding_\",shape=gl_embed.shape,\n",
    "                                       initializer=tf.constant_initializer(gl_embed),trainable=True)\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            #print('embedded_chars',self.embedded_chars.get_shape())\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "            #print('embedded_chars_expanded',self.embedded_chars_expanded.get_shape())\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                #W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                Wname = \"w_%d\"%filter_size\n",
    "                W = tf.get_variable(Wname, shape = filter_shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.Variable(tf.constant(0.0, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d( self.embedded_chars_expanded, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv\")\n",
    "\n",
    "                # Apply nonlinearity\n",
    "                conv+= b\n",
    "                h = tf.nn.relu(conv, name=\"relu\")\n",
    "                #print('h',h.get_shape())\n",
    "\n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(h, ksize=[1, sequence_length - filter_size + 1, 1, 1], strides=[1, 1, 1, 1],\n",
    "                    padding='VALID', name=\"pool\")\n",
    "                #print('pooled',pooled.get_shape())\n",
    "                pooled_outputs.append(pooled)\n",
    "                #print('pooled_outputs',type(pooled_outputs))\n",
    "                #print('pooled_outputs as array',type(np.array(pooled_outputs)),np.array(pooled_outputs).shape)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        #print('h_pool',self.h_pool.get_shape())\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "        #print('h_pool_flat',self.h_pool_flat.get_shape())\n",
    "        \n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\"W\", shape=[num_filters_total, num_classes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            #print('self.scores',self.scores.get_shape())\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "            self.pred_proba = tf.nn.softmax(self.scores, name=\"pred_proba\")\n",
    "            #print('self.predictions',self.predictions.get_shape())\n",
    "            \n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "            #self.loss = tf.losses.mean_squared_error(self.input_y, self.scores)\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(tf.cast(self.predictions,tf.int32), self.input_y)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "#             correct_pred = tf.equal(tf.cast(tf.round(self.scores), tf.int32), self.input_y)\n",
    "#             self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "        # AUC\n",
    "#         with tf.name_scope(\"auc\"):\n",
    "#             false_pos_rate, true_pos_rate, _ = roc_curve(self.input_y, self.pred_proba[:,1])\n",
    "#             self.auc = auc(false_pos_rate, true_pos_rate)\n",
    "            \n",
    "            \n",
    "        with tf.name_scope('train'):\n",
    "            #self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "            self.optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate,momentum=momentum,use_nesterov=True).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(ids, labels, batch_size=100, Trainable=False):\n",
    "            #ids is input, X_train\n",
    "            #need to fix this to shuffle between epochs\n",
    "            \n",
    "            n_batches = len(ids)//batch_size\n",
    "            ids, labels = ids[:n_batches*batch_size], labels[:n_batches*batch_size]\n",
    "            if Trainable:\n",
    "                shuffle = np.random.permutation(np.arange(n_batches*batch_size))\n",
    "                ids, labels = ids[shuffle], labels[shuffle]\n",
    "   \n",
    "            for ii in range(0, len(ids), batch_size):\n",
    "                yield ids[ii:ii+batch_size], labels[ii:ii+batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model parameters\n",
    "\n",
    "#embed_dim = 50 #use when not using pre-trained embeddings\n",
    "embed_dim = hands.shape[1]\n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 256\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "keep_prob = 0.8\n",
    "evaluate_train = 2 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 2 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 4 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 15\n",
    "#num_checkpoints = 2\n",
    "#batch_size = 64\n",
    "batch_size=128\n",
    "\n",
    "# out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "# print(\"Model saving  to {}\\n\".format(out_dir))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual training loop:\n",
    "\n",
    "def train_cnn(key, size=5000):\n",
    "     \n",
    "    x_train = dict_train_ids[key]\n",
    "    y_train = dict_train_y[key]\n",
    "    x_dev = dict_dev_ids[key]\n",
    "    y_dev = dict_dev_ypred[key]\n",
    "    V = dict_vocab_len[key]\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "        \n",
    "            cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, learning_rate = learning_rate,\n",
    "                        momentum = momentum, embedding_size=embed_dim, gl_embed = hands.W, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print('completed cnn creation')\n",
    "\n",
    "            # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "            size_folder =  \"size_\" + str(size) \n",
    "            out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", key, size_folder))\n",
    "            #out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", key))\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            model_name = key \n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, model_name  + \"_model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            \n",
    "            # Write vocabulary\n",
    "            ## vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "            \n",
    "            print('# batches =', len(x_train)//batch_size)\n",
    "            start = time.time()\n",
    "            for e in range(num_epochs):\n",
    "                    \n",
    "                #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                total_auc = 0\n",
    "                \n",
    "                for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size, Trainable=True), 1):\n",
    "                    feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                   # _, loss, accuracy, auc = sess.run([cnn.optimizer,cnn.loss, cnn.accuracy, cnn.auc],feed_dict = feed)\n",
    "                    _, loss, accuracy = sess.run([cnn.optimizer,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    \n",
    "                    #total_auc += auc*len(x)\n",
    "                    \n",
    "                if e%evaluate_train==0:\n",
    "                    avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                    avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                    #avg_auc = total_auc/(batch_size*(len(x_train)//batch_size))\n",
    "                   # print(\"Train epoch {}, average loss {:g}, average accuracy {:g},average auc {:g}\".format(e, avg_loss, avg_acc, avg_auc))\n",
    "                    print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "\n",
    "                if e%evaluate_dev==0:\n",
    "                    \n",
    "                    total_loss = 0\n",
    "                    total_acc = 0\n",
    "                    num_batches = 0\n",
    "                    total_auc = 0\n",
    "                    y_pred = []\n",
    "                    y_pred_proba = []\n",
    "                    y_shuffled = []\n",
    "                    total_batch_acc = 0\n",
    "                    \n",
    "                    for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size, Trainable=False), 1):\n",
    "                        \n",
    "                        feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                        #loss, accuracy, auc = sess.run([cnn.loss, cnn.accuracy, cnn.auc],feed_dict)\n",
    "                       # batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                        batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.predictions, cnn.pred_proba, cnn.loss, cnn.accuracy],feed_dict)\n",
    "                        total_loss += loss*len(x)\n",
    "                        total_acc += accuracy*len(x)\n",
    "                        \n",
    "                        batch_accuracy= np.sum(y==batch_pred)/y.shape[0]\n",
    "                        total_batch_acc += batch_accuracy\n",
    "                        y_pred= np.concatenate([y_pred, batch_pred])\n",
    "                        y_pred_proba= np.concatenate([y_pred_proba, batch_pred_proba[:,1]])\n",
    "                        y_shuffled = np.concatenate([y_shuffled, y])\n",
    "                        \n",
    "                        num_batches += 1\n",
    "                        \n",
    "                    avg_loss = total_loss/(num_batches*batch_size)\n",
    "                    avg_acc = total_acc/(num_batches*batch_size)\n",
    "                    \n",
    "                    print('y_dev.shape',y_dev.shape)\n",
    "                    print('y_shuffled.shape',y_shuffled.shape)\n",
    "                    \n",
    "                    if np.array_equal(y_shuffled,y_dev):\n",
    "                        print(\"Yes\")\n",
    "                    right_acc = total_batch_acc/(num_batches)\n",
    "                    #avg_auc = total_auc/(num_batches*batch_size)\n",
    "                    \n",
    "                    #Calculate Accuracy\n",
    "                    new_acc = accuracy_score(y_shuffled, y_pred, normalize=True ) \n",
    "                     \n",
    "                    \n",
    "                    false_pos_rate, true_pos_rate, _ = roc_curve(y_shuffled, y_pred_proba)  \n",
    "                    roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "                    \n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                    print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                    print(\"\\t\\tDev epoch {}, auc {:g}, new accuracy {:g}, right accuracy {:g},\".format(e,  roc_auc, new_acc, right_acc))\n",
    "                    #print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},average auc {:g}\".format(e, avg_loss, avg_acc, avg_auc))\n",
    "                if e%time_print == 0:\n",
    "                    end = time.time()\n",
    "                    print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)\n",
    "                    \n",
    "                    \n",
    "        # Save model weights for future use.\n",
    "        \n",
    "        \n",
    "            #save_path = saver.save(sess, checkpoint_prefix, global_step=20,write_meta_graph=False)\n",
    "            save_path = saver.save(sess, checkpoint_prefix)\n",
    "            print(\"Saved model\", model_name, save_path)\n",
    "            \n",
    "            #calculate predictions and prediction probability    \n",
    "#             feed_dict={cnn.input_x:x_dev, cnn.input_y: y_dev, cnn.dropout_keep_prob: 1.0}\n",
    "#             y_pred, y_pred_proba = sess.run([cnn.predictions, cnn.pred_proba],feed_dict)\n",
    "            #print(y_pred, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please make sure you change the size below so that the source model is saved with that name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = ['toys','vid','aut','hnk'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toys 100000\n",
      "completed cnn creation\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.326412, average accuracy 0.870329,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 0, average loss 0.247981, average accuracy 0.905849,\n",
      "\t\tDev epoch 0, auc 0.917311, new accuracy 0.905849, right accuracy 0.905849,\n",
      "\t\t\t\t    Time taken for 0 epochs =  56.59470534324646\n",
      "Train epoch 2, average loss 0.19472, average accuracy 0.923085,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 2, average loss 0.190053, average accuracy 0.924713,\n",
      "\t\tDev epoch 2, auc 0.948155, new accuracy 0.924713, right accuracy 0.924713,\n",
      "Train epoch 4, average loss 0.147714, average accuracy 0.942772,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 4, average loss 0.187572, average accuracy 0.926382,\n",
      "\t\tDev epoch 4, auc 0.954211, new accuracy 0.926382, right accuracy 0.926382,\n",
      "\t\t\t\t    Time taken for 4 epochs =  189.73777174949646\n",
      "Train epoch 6, average loss 0.110283, average accuracy 0.958717,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 6, average loss 0.174863, average accuracy 0.932559,\n",
      "\t\tDev epoch 6, auc 0.956852, new accuracy 0.932559, right accuracy 0.932559,\n",
      "Train epoch 8, average loss 0.0799499, average accuracy 0.971271,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 8, average loss 0.177602, average accuracy 0.933093,\n",
      "\t\tDev epoch 8, auc 0.958329, new accuracy 0.933093, right accuracy 0.933093,\n",
      "\t\t\t\t    Time taken for 8 epochs =  322.9811291694641\n",
      "Train epoch 10, average loss 0.0567333, average accuracy 0.980834,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 10, average loss 0.184794, average accuracy 0.932726,\n",
      "\t\tDev epoch 10, auc 0.958333, new accuracy 0.932726, right accuracy 0.932726,\n",
      "Train epoch 12, average loss 0.0408483, average accuracy 0.987216,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 12, average loss 0.194073, average accuracy 0.934896,\n",
      "\t\tDev epoch 12, auc 0.958512, new accuracy 0.934896, right accuracy 0.934896,\n",
      "\t\t\t\t    Time taken for 12 epochs =  456.40864515304565\n",
      "Train epoch 14, average loss 0.0290297, average accuracy 0.991907,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 14, average loss 0.201882, average accuracy 0.931591,\n",
      "\t\tDev epoch 14, auc 0.958837, new accuracy 0.931591, right accuracy 0.931591,\n",
      "Saved model toys /newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints/toys_model\n",
      "vid 100000\n",
      "completed cnn creation\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.398813, average accuracy 0.831576,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 0, average loss 0.322097, average accuracy 0.862614,\n",
      "\t\tDev epoch 0, auc 0.881232, new accuracy 0.862614, right accuracy 0.862614,\n",
      "\t\t\t\t    Time taken for 0 epochs =  34.95008635520935\n",
      "Train epoch 2, average loss 0.273329, average accuracy 0.885954,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 2, average loss 0.260473, average accuracy 0.894364,\n",
      "\t\tDev epoch 2, auc 0.92111, new accuracy 0.894364, right accuracy 0.894364,\n",
      "Train epoch 4, average loss 0.215066, average accuracy 0.912452,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 4, average loss 0.246178, average accuracy 0.900908,\n",
      "\t\tDev epoch 4, auc 0.930388, new accuracy 0.900908, right accuracy 0.900908,\n",
      "\t\t\t\t    Time taken for 4 epochs =  169.25235724449158\n",
      "Train epoch 6, average loss 0.166099, average accuracy 0.934799,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 6, average loss 0.245642, average accuracy 0.900975,\n",
      "\t\tDev epoch 6, auc 0.933907, new accuracy 0.900975, right accuracy 0.900975,\n",
      "Train epoch 8, average loss 0.12692, average accuracy 0.952105,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 8, average loss 0.244038, average accuracy 0.90595,\n",
      "\t\tDev epoch 8, auc 0.934683, new accuracy 0.90595, right accuracy 0.90595,\n",
      "\t\t\t\t    Time taken for 8 epochs =  303.5451157093048\n",
      "Train epoch 10, average loss 0.0917923, average accuracy 0.966479,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 10, average loss 0.25495, average accuracy 0.906884,\n",
      "\t\tDev epoch 10, auc 0.934148, new accuracy 0.906884, right accuracy 0.906884,\n",
      "Train epoch 12, average loss 0.0682957, average accuracy 0.976573,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 12, average loss 0.274015, average accuracy 0.907318,\n",
      "\t\tDev epoch 12, auc 0.933903, new accuracy 0.907318, right accuracy 0.907318,\n",
      "\t\t\t\t    Time taken for 12 epochs =  437.64132618904114\n",
      "Train epoch 14, average loss 0.0502499, average accuracy 0.983635,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 14, average loss 0.283107, average accuracy 0.90625,\n",
      "\t\tDev epoch 14, auc 0.933281, new accuracy 0.90625, right accuracy 0.90625,\n",
      "Saved model vid /newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints/vid_model\n",
      "aut 100000\n",
      "completed cnn creation\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.341688, average accuracy 0.864477,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 0, average loss 0.274249, average accuracy 0.886952,\n",
      "\t\tDev epoch 0, auc 0.884795, new accuracy 0.886952, right accuracy 0.886952,\n",
      "\t\t\t\t    Time taken for 0 epochs =  34.67738389968872\n",
      "Train epoch 2, average loss 0.224533, average accuracy 0.909701,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 2, average loss 0.221307, average accuracy 0.909555,\n",
      "\t\tDev epoch 2, auc 0.929003, new accuracy 0.909555, right accuracy 0.909555,\n",
      "Train epoch 4, average loss 0.17435, average accuracy 0.930828,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 4, average loss 0.208902, average accuracy 0.9169,\n",
      "\t\tDev epoch 4, auc 0.937615, new accuracy 0.9169, right accuracy 0.9169,\n",
      "\t\t\t\t    Time taken for 4 epochs =  167.8264515399933\n",
      "Train epoch 6, average loss 0.132002, average accuracy 0.948954,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 6, average loss 0.198363, average accuracy 0.92261,\n",
      "\t\tDev epoch 6, auc 0.941728, new accuracy 0.92261, right accuracy 0.92261,\n",
      "Train epoch 8, average loss 0.0977073, average accuracy 0.963868,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 8, average loss 0.202741, average accuracy 0.921575,\n",
      "\t\tDev epoch 8, auc 0.942427, new accuracy 0.921575, right accuracy 0.921575,\n",
      "\t\t\t\t    Time taken for 8 epochs =  300.9673366546631\n",
      "Train epoch 10, average loss 0.0689277, average accuracy 0.976332,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 10, average loss 0.224909, average accuracy 0.922843,\n",
      "\t\tDev epoch 10, auc 0.940277, new accuracy 0.922843, right accuracy 0.922843,\n",
      "Train epoch 12, average loss 0.0498339, average accuracy 0.983695,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 12, average loss 0.239903, average accuracy 0.923044,\n",
      "\t\tDev epoch 12, auc 0.942537, new accuracy 0.923044, right accuracy 0.923044,\n",
      "\t\t\t\t    Time taken for 12 epochs =  434.042142868042\n",
      "Train epoch 14, average loss 0.0370719, average accuracy 0.988726,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 14, average loss 0.241078, average accuracy 0.923945,\n",
      "\t\tDev epoch 14, auc 0.940728, new accuracy 0.923945, right accuracy 0.923945,\n",
      "Saved model aut /newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints/aut_model\n",
      "hnk 100000\n",
      "completed cnn creation\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.346576, average accuracy 0.855214,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 0, average loss 0.266563, average accuracy 0.888054,\n",
      "\t\tDev epoch 0, auc 0.913382, new accuracy 0.888054, right accuracy 0.888054,\n",
      "\t\t\t\t    Time taken for 0 epochs =  34.8063063621521\n",
      "Train epoch 2, average loss 0.215341, average accuracy 0.912892,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 2, average loss 0.207851, average accuracy 0.918102,\n",
      "\t\tDev epoch 2, auc 0.946659, new accuracy 0.918102, right accuracy 0.918102,\n",
      "Train epoch 4, average loss 0.164305, average accuracy 0.935849,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 4, average loss 0.213209, average accuracy 0.914196,\n",
      "\t\tDev epoch 4, auc 0.955386, new accuracy 0.914196, right accuracy 0.914196,\n",
      "\t\t\t\t    Time taken for 4 epochs =  168.50865769386292\n",
      "Train epoch 6, average loss 0.121427, average accuracy 0.954415,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 6, average loss 0.208898, average accuracy 0.919772,\n",
      "\t\tDev epoch 6, auc 0.9579, new accuracy 0.919772, right accuracy 0.919772,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 8, average loss 0.0876976, average accuracy 0.96816,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 8, average loss 0.204847, average accuracy 0.924112,\n",
      "\t\tDev epoch 8, auc 0.958948, new accuracy 0.924112, right accuracy 0.924112,\n",
      "\t\t\t\t    Time taken for 8 epochs =  301.99647784233093\n",
      "Train epoch 10, average loss 0.0628392, average accuracy 0.978453,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 10, average loss 0.199444, average accuracy 0.92725,\n",
      "\t\tDev epoch 10, auc 0.959642, new accuracy 0.92725, right accuracy 0.92725,\n",
      "Train epoch 12, average loss 0.0457157, average accuracy 0.985445,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 12, average loss 0.211818, average accuracy 0.92735,\n",
      "\t\tDev epoch 12, auc 0.959973, new accuracy 0.92735, right accuracy 0.92735,\n",
      "\t\t\t\t    Time taken for 12 epochs =  435.4455497264862\n",
      "Train epoch 14, average loss 0.0348752, average accuracy 0.989767,\n",
      "y_dev.shape (30000,)\n",
      "y_shuffled.shape (29952,)\n",
      "\t\tDev epoch 14, average loss 0.218774, average accuracy 0.92705,\n",
      "\t\tDev epoch 14, auc 0.960381, new accuracy 0.92705, right accuracy 0.92705,\n",
      "Saved model hnk /newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints/hnk_model\n"
     ]
    }
   ],
   "source": [
    "#Create and train the cnn models for all 4 domains\n",
    "#Pass the size to save the model name with size in different folders\n",
    "\n",
    "size_train = size_initial\n",
    "for key in list_df:\n",
    "    print(key, size_train)\n",
    "    train_cnn(key, size=size_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_accuracy(src_key, size, tar_key):\n",
    "    \n",
    "    batch_size=50\n",
    "    print('target',tar_key,'source', src_key)\n",
    "    V = dict_vocab_len[tar_key]\n",
    "    \n",
    "    size_folder =  \"size_\" + str(size) \n",
    "    out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", src_key, size_folder))\n",
    "    #out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", src_key))\n",
    "    checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "\n",
    "    \n",
    "    print(checkpoint_dir)\n",
    "    src_model = src_key\n",
    "    #graph_meta_file = checkpoint_dir + '/' + 'hnk01_model.meta'\n",
    "    graph_meta_file = checkpoint_dir + '/' + src_model +'_model.meta'\n",
    "    graph=tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "    \n",
    "      #new_saver = tf.train.import_meta_graph(checkpoint_dir/'hnk_model.meta')\n",
    "            new_saver = tf.train.import_meta_graph(graph_meta_file)\n",
    "            new_saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "    \n",
    "            x_dev = dict_dev_ids[tar_key]      \n",
    "            y_dev = dict_dev_ypred[tar_key]\n",
    "        \n",
    "            #create graph from saved model\n",
    "            input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "            input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "            dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "        \n",
    "            pred_proba = graph.get_operation_by_name(\"output/pred_proba\").outputs[0]\n",
    "            predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "        \n",
    "            y_pred = []\n",
    "            y_pred_proba = []\n",
    "            total_batch_acc = 0\n",
    "            num_batches = 0\n",
    "            y_shuffled = []\n",
    "            abs_y_pred_proba = []\n",
    "            for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size, Trainable=False), 1):\n",
    "                        \n",
    "                feed_dict = {input_x: x, input_y: y, dropout_keep_prob: 1.0}\n",
    "                batch_pred, batch_pred_proba  = sess.run([ predictions, pred_proba],feed_dict)\n",
    "                batch_accuracy= np.sum(y==batch_pred)/y.shape[0]\n",
    "                total_batch_acc += batch_accuracy\n",
    "                y_pred= np.concatenate([y_pred, batch_pred])\n",
    "                y_pred_proba= np.concatenate([y_pred_proba, batch_pred_proba[:,1]])\n",
    "                abs_y_pred_proba = np.concatenate([abs_y_pred_proba,np.absolute(batch_pred_proba[:,1] - batch_pred_proba[:,0])])\n",
    "                y_shuffled = np.concatenate([y_shuffled, y])\n",
    "\n",
    "                num_batches += 1           \n",
    "        \n",
    "            # Calculate auc\n",
    "            # false_pos_rate, true_pos_rate, _ = roc_curve(y_dev, y_pred_proba[:,1])\n",
    "            false_pos_rate, true_pos_rate, _ = roc_curve(y_shuffled, y_pred_proba)  \n",
    "            roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "            # print(src_key, tar_key, \"AUC\",\"{:.02%}\".format(roc_auc))\n",
    "            \n",
    "            #Calculate Accuracy\n",
    "            acc = accuracy_score(y_shuffled, y_pred, normalize=True )\n",
    "            #print('source',src_key, 'target',tar_key, \"accuracy\",\"{:.02%}\".format(acc))\n",
    "            #print(\"\")\n",
    "            f1_pos = f1_score(y_shuffled, y_pred, average = None)[1]\n",
    "            f1_neg = f1_score(y_shuffled, y_pred, average = None)[0]\n",
    "            f1_avg = f1_score(y_shuffled, y_pred, average = 'macro')\n",
    "        \n",
    "        #Save absolute_y_pred_proba\n",
    "        \n",
    "        #check if the batching process left remainders. This will result in incorrect length of y_pred_proba saved\n",
    "        if y_dev.shape[0] != abs_y_pred_proba.shape[0]:\n",
    "            print(\"Length of y_pred_proba does not match y_dev. Fix batch_size\")\n",
    "            print(\"Pred proba file not saved\")\n",
    "#         else:    \n",
    "#             file_name = \"src_\" + src_key + \"_tar_\" + tar_key + \"_\" + str(y_dev.shape[0])\n",
    "#             np.savez_compressed('test_file',pred_prob=abs_y_pred_proba)\n",
    "#             print( file_name, \"Saved file successfully\")\n",
    "    return acc, roc_auc, f1_pos, f1_neg, f1_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target toys source toys\n",
      "/newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints/toys_model\n",
      "target vid source toys\n",
      "/newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints/toys_model\n",
      "target aut source toys\n",
      "/newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints/toys_model\n",
      "target hnk source toys\n",
      "/newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/toys/size_100000/checkpoints/toys_model\n",
      "target toys source vid\n",
      "/newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints/vid_model\n",
      "target vid source vid\n",
      "/newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints/vid_model\n",
      "target aut source vid\n",
      "/newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints/vid_model\n",
      "target hnk source vid\n",
      "/newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/vid/size_100000/checkpoints/vid_model\n",
      "target toys source aut\n",
      "/newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints/aut_model\n",
      "target vid source aut\n",
      "/newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints/aut_model\n",
      "target aut source aut\n",
      "/newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints/aut_model\n",
      "target hnk source aut\n",
      "/newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/aut/size_100000/checkpoints/aut_model\n",
      "target toys source hnk\n",
      "/newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints/hnk_model\n",
      "target vid source hnk\n",
      "/newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints/hnk_model\n",
      "target aut source hnk\n",
      "/newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints/hnk_model\n",
      "target hnk source hnk\n",
      "/newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/size_100000/checkpoints/hnk_model\n",
      "\n",
      " Accuracy with transfer\n",
      "           toys       vid       aut       hnk\n",
      "toys  0.931633  0.756367    0.8206  0.811367\n",
      "vid     0.7463  0.906233  0.769567  0.779433\n",
      "aut   0.775133     0.759  0.923967  0.802267\n",
      "hnk   0.751433    0.7373  0.788933  0.927067\n",
      "\n",
      " AUC with transfer\n",
      "           toys       vid       aut       hnk\n",
      "toys  0.958905  0.509798  0.513877  0.507229\n",
      "vid   0.497448  0.933287  0.476135  0.522277\n",
      "aut   0.507536  0.498935  0.940801  0.494718\n",
      "hnk   0.504871  0.531176   0.44983  0.960401\n",
      "\n",
      " F1-positive with transfer\n",
      "           toys       vid       aut       hnk\n",
      "toys  0.959739   0.85741   0.90062  0.894526\n",
      "vid   0.851141  0.942845  0.868065  0.874103\n",
      "aut   0.870727  0.859584  0.956437  0.888922\n",
      "hnk   0.854586   0.84298  0.880964  0.956926\n",
      "\n",
      " F1-negative with transfer\n",
      "           toys       vid        aut       hnk\n",
      "toys  0.773545  0.163826  0.0790554  0.108398\n",
      "vid   0.142036  0.739126  0.0907536  0.110738\n",
      "aut   0.136899  0.150411   0.701401  0.100667\n",
      "hnk   0.144741  0.196554  0.0696444  0.762277\n",
      "\n",
      " F1-average with transfer\n",
      "           toys       vid       aut       hnk\n",
      "toys  0.866642  0.510618  0.489838  0.501462\n",
      "vid   0.496589  0.840986  0.479409  0.492421\n",
      "aut   0.503813  0.504998  0.828919  0.494795\n",
      "hnk   0.499663  0.519767  0.475304  0.859602\n"
     ]
    }
   ],
   "source": [
    "#calculate transfer accuracy for all domains, and save results in a dataframe\n",
    "list_df = ['toys','vid','aut','hnk'] \n",
    "#size = size_train\n",
    "size = size_initial\n",
    "transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "transfer_results_auc = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store AUC on transfer. Col = Model, row = dataframe\n",
    "transfer_results_f1_pos = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store f1-positive on transfer.\n",
    "transfer_results_f1_neg = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store f1-negative on transfer.\n",
    "transfer_results_f1_avg = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store f1-average on transfer.\n",
    "\n",
    "for s_key in list_df:\n",
    "    for t_key in list_df:\n",
    "        acc, roc_auc, f1_pos, f1_neg, f1_avg = predict_accuracy(s_key,size, t_key)\n",
    "        transfer_results[s_key][t_key] = acc\n",
    "        transfer_results_auc[s_key][t_key] = roc_auc\n",
    "        transfer_results_f1_pos[s_key][t_key] = f1_pos\n",
    "        transfer_results_f1_neg[s_key][t_key] = f1_neg\n",
    "        transfer_results_f1_avg[s_key][t_key] = f1_avg\n",
    "\n",
    "print('\\n Accuracy with transfer\\n',transfer_results)\n",
    "print('\\n AUC with transfer\\n',transfer_results_auc)\n",
    "print('\\n F1-positive with transfer\\n',transfer_results_f1_pos)\n",
    "print('\\n F1-negative with transfer\\n',transfer_results_f1_neg)\n",
    "print('\\n F1-average with transfer\\n',transfer_results_f1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_transfer_vect = {} #Dictionary to store two domain vocab_vectorizer\n",
    "dict_transfer_train_ids = {} #Dictionary to store review ids of train set based on on two domains vocab_vectorizer\n",
    "dict_transfer_dev_ids = {} #Dictionary to store review ids of train set based on on two domains vocab_vectorizer\n",
    "for s_key in list_df:\n",
    "    dict_transfer_vect[s_key] = {}\n",
    "    dict_transfer_train_ids[s_key] = {}\n",
    "    dict_transfer_dev_ids[s_key] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note : size of src and tgt needs to be less than the original size read into dict_train_df with create_sized data.\n",
    "\n",
    "def process_transfer_data(src_key,tgt_key, size_train = 10000):\n",
    "      \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    tmp_src_df = dict_train_df[src_key][:size_train] #picking the right sized subset from dict_train_df, dict_train_y\n",
    "    tmp_tgt_df = dict_train_df[tgt_key][:size_train]\n",
    "    tmp_src_df_dev = dict_dev_df[src_key][:np.int(size_train*0.3)] #picking the right sized subset from dict_train_df, dict_train_y\n",
    "    tmp_tgt_df_dev = dict_dev_df[tgt_key][:np.int(size_train*0.3)]\n",
    "    #print(tmp_src_df.shape,tmp_tgt_df.shape,tmp_src_df_dev.shape,tmp_tgt_df_dev.shape)\n",
    "    temp_two_df_reviews = pd.concat([tmp_src_df.reviewText,tmp_tgt_df.reviewText])\n",
    "    #print('combined df shape for',src_key,tgt_key,temp_two_df_reviews.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[src_key][tgt_key] = tflearn.data_utils.VocabularyProcessor(max_length, min_frequency=min_frequency)\n",
    "    dict_transfer_vect[src_key][tgt_key] = dict_transfer_vect[src_key][tgt_key].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",src_key,tgt_key,len(dict_transfer_vect[src_key][tgt_key].vocabulary_))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train_ids[src_key][tgt_key] = dict_transfer_vect[src_key][tgt_key].transform(tmp_src_df.reviewText)\n",
    "    dict_transfer_train_ids[tgt_key][src_key] = dict_transfer_vect[src_key][tgt_key].transform(tmp_tgt_df.reviewText)\n",
    "    dict_transfer_dev_ids[src_key][tgt_key] = dict_transfer_vect[src_key][tgt_key].transform(tmp_src_df_dev.reviewText)\n",
    "    dict_transfer_dev_ids[tgt_key][src_key] = dict_transfer_vect[src_key][tgt_key].transform(tmp_tgt_df_dev.reviewText)\n",
    "    # x_train = np.array(list(x_train))\n",
    "    dict_transfer_train_ids[src_key][tgt_key] = np.array(list(dict_transfer_train_ids[src_key][tgt_key]))\n",
    "    dict_transfer_train_ids[tgt_key][src_key] = np.array(list(dict_transfer_train_ids[tgt_key][src_key]))\n",
    "    dict_transfer_dev_ids[src_key][tgt_key] = np.array(list(dict_transfer_dev_ids[src_key][tgt_key]))\n",
    "    dict_transfer_dev_ids[tgt_key][src_key] = np.array(list(dict_transfer_dev_ids[tgt_key][src_key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source key hnk target key aut\n",
      "Number words in training corpus for keys hnk aut 150842\n",
      "hnk train set shape (500000, 150)\n",
      "aut train set shape (500000, 150)\n",
      "hnk dev set shape (150000, 150)\n",
      "aut dev set shape (150000, 150)\n"
     ]
    }
   ],
   "source": [
    "#Convert the train and dev data to ids using the combined source and target domain vocab_vectorizer\n",
    "size_initial = size_initial\n",
    "list_src = ['hnk']\n",
    "list_tgt = ['aut']\n",
    "for s_key in list_src:\n",
    "    #print(s_key)\n",
    "    for t_key in list_tgt:\n",
    "        print('source key',s_key, 'target key',t_key)\n",
    "        process_transfer_data(s_key,t_key, size_train = size_initial)\n",
    "        print(s_key,'train set shape',dict_transfer_train_ids[s_key][t_key].shape)\n",
    "        print(t_key,'train set shape',dict_transfer_train_ids[t_key][s_key].shape)\n",
    "        print(s_key,'dev set shape',dict_transfer_dev_ids[s_key][t_key].shape)\n",
    "        print(t_key,'dev set shape',dict_transfer_dev_ids[t_key][s_key].shape)\n",
    "#         print(dict_train_df[s_key]['reviewText'].iloc[1])\n",
    "#         print(dict_transfer_train_ids[s_key][t_key][1])\n",
    "#         print(dict_train_df[t_key]['reviewText'].iloc[1])\n",
    "#         print(dict_transfer_train_ids[t_key][s_key][1])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transfer_cnn(skey,tkey,size=10000):\n",
    "     \n",
    "    x_train =  dict_transfer_train_ids[skey][tkey][:size]\n",
    "    y_train = dict_train_y[skey][:size]\n",
    "    x_dev = dict_transfer_dev_ids[skey][tkey][:np.int(size*0.3)] #Note : 0.3 is hard coded as the relative size of dev vs train.\n",
    "    y_dev = dict_dev_ypred[skey][:np.int(size*0.3)]\n",
    "    x_dev_tgt = dict_transfer_dev_ids[tkey][skey][:np.int(size*0.3)]\n",
    "    y_dev_tgt = dict_dev_ypred[tkey][:np.int(size*0.3)]\n",
    "    V = len(dict_transfer_vect[skey][tkey].vocabulary_)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "        \n",
    "            cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, learning_rate = learning_rate,\n",
    "                        momentum = momentum, embedding_size=embed_dim, gl_embed = hands.W, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print('completed cnn creation')\n",
    "\n",
    "            # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "            size_folder =  \"size_\" + str(size) \n",
    "            out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", skey, tkey, size_folder))\n",
    "            #out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", key))\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            model_name = ''.join([skey, tkey])\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, model_name  + \"_model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            \n",
    "            # Write vocabulary\n",
    "            ## vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "            \n",
    "            tmp_ix = [2*e for e in range(np.int((num_epochs+2)/2))]\n",
    "            results = pd.DataFrame(index = tmp_ix,columns = ['size','acc','f1_avg','auc','f1_pos','f1_neg'])\n",
    "            print('# batches =', len(x_train)//batch_size)\n",
    "            start = time.time()\n",
    "            for e in range(num_epochs):\n",
    "                    \n",
    "                #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                total_auc = 0\n",
    "                \n",
    "                for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size, Trainable=True), 1):\n",
    "                    feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                   # _, loss, accuracy, auc = sess.run([cnn.optimizer,cnn.loss, cnn.accuracy, cnn.auc],feed_dict = feed)\n",
    "                    _, loss, accuracy = sess.run([cnn.optimizer,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    \n",
    "                    #total_auc += auc*len(x)\n",
    "                    \n",
    "                if e%evaluate_train==0:\n",
    "                    avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                    avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                    print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "\n",
    "                if e%evaluate_dev==0:\n",
    "                    \n",
    "                    total_loss = 0\n",
    "                    total_acc = 0\n",
    "                    num_batches = 0\n",
    "                    total_auc = 0\n",
    "                    y_pred = []\n",
    "                    y_pred_proba = []\n",
    "                    y_shuffled = []\n",
    "                    total_batch_acc = 0\n",
    "                    \n",
    "                    for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size, Trainable=False), 1):\n",
    "                        \n",
    "                        feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                        #loss, accuracy, auc = sess.run([cnn.loss, cnn.accuracy, cnn.auc],feed_dict)\n",
    "                       # batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                        batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.predictions, cnn.pred_proba, cnn.loss, cnn.accuracy],feed_dict)\n",
    "                        total_loss += loss*len(x)\n",
    "                        total_acc += accuracy*len(x)\n",
    "                        \n",
    "                        batch_accuracy= np.sum(y==batch_pred)/y.shape[0]\n",
    "                        total_batch_acc += batch_accuracy\n",
    "                        y_pred= np.concatenate([y_pred, batch_pred])\n",
    "                        y_pred_proba= np.concatenate([y_pred_proba, batch_pred_proba[:,1]])\n",
    "                        y_shuffled = np.concatenate([y_shuffled, y])\n",
    "                        \n",
    "                        num_batches += 1\n",
    "                        \n",
    "                    avg_loss = total_loss/(num_batches*batch_size)\n",
    "                    avg_acc = total_acc/(num_batches*batch_size)\n",
    "                    \n",
    "#                     print('y_dev.shape',y_dev.shape)\n",
    "#                     print('y_shuffled.shape',y_shuffled.shape)\n",
    "                    \n",
    "                    if np.array_equal(y_shuffled,y_dev):\n",
    "                        print(\"Yes\")\n",
    "                    #right_acc = total_batch_acc/(num_batches)\n",
    "                    #avg_auc = total_auc/(num_batches*batch_size)\n",
    "                    \n",
    "                    #Calculate Accuracy\n",
    "                    #new_acc = accuracy_score(y_shuffled, y_pred, normalize=True )                   \n",
    "                    false_pos_rate, true_pos_rate, _ = roc_curve(y_shuffled, y_pred_proba)  \n",
    "                    roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "                    f1_pos = f1_score(y_shuffled, y_pred, average = None)[1]\n",
    "                    f1_neg = f1_score(y_shuffled, y_pred, average = None)[0]\n",
    "                    f1_avg = f1_score(y_shuffled, y_pred, average = 'macro')\n",
    "                    \n",
    "                    results['acc'][e] = avg_acc\n",
    "                    results['f1_avg'][e] = f1_avg\n",
    "                    results['auc'][e] = roc_auc\n",
    "                    results['f1_pos'][e] = f1_pos\n",
    "                    results['f1_neg'][e] =  f1_neg\n",
    "                \n",
    "                    \n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                    print(\"\\tDev epoch %d,average loss %0.3f,average accuracy %0.3f,auc %0.3f,f1_pos %0.3f,f1_neg %0.3f,f1_avg %0.3f\"\n",
    "                          %(e, avg_loss, avg_acc, roc_auc,f1_pos,f1_neg,f1_avg))\n",
    "                if e%time_print == 0:\n",
    "                    end = time.time()\n",
    "                    print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)\n",
    "                    \n",
    "                    \n",
    "            #Estimate accuracy on target dev set\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            num_batches = 0\n",
    "            total_auc = 0\n",
    "            y_pred = []\n",
    "            y_pred_proba = []\n",
    "            y_shuffled = []\n",
    "            total_batch_acc = 0\n",
    "            for ii, (x, y) in enumerate(batch_generator(x_dev_tgt, y_dev_tgt, batch_size, Trainable=False), 1):\n",
    "\n",
    "                feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                #loss, accuracy, auc = sess.run([cnn.loss, cnn.accuracy, cnn.auc],feed_dict)\n",
    "                # batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.predictions, cnn.pred_proba, cnn.loss, cnn.accuracy],feed_dict)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "\n",
    "                batch_accuracy= np.sum(y==batch_pred)/y.shape[0]\n",
    "                total_batch_acc += batch_accuracy\n",
    "                y_pred= np.concatenate([y_pred, batch_pred])\n",
    "                y_pred_proba= np.concatenate([y_pred_proba, batch_pred_proba[:,1]])\n",
    "                y_shuffled = np.concatenate([y_shuffled, y])\n",
    "\n",
    "                num_batches += 1\n",
    "                    \n",
    "            avg_loss = total_loss/(num_batches*batch_size)\n",
    "            avg_acc = total_acc/(num_batches*batch_size)\n",
    "\n",
    "#             print('y_dev.shape',y_dev.shape)\n",
    "#             print('y_shuffled.shape',y_shuffled.shape)\n",
    "\n",
    "            if np.array_equal(y_shuffled,y_dev):\n",
    "                print(\"Yes\")\n",
    "                #right_acc = total_batch_acc/(num_batches)\n",
    "\n",
    "            #Calculate Accuracy, AUC\n",
    "            #new_acc = accuracy_score(y_shuffled, y_pred, normalize=True ) \n",
    "            false_pos_rate, true_pos_rate, _ = roc_curve(y_shuffled, y_pred_proba)  \n",
    "            roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "            f1_pos = f1_score(y_shuffled, y_pred, average = None)[1]\n",
    "            f1_neg = f1_score(y_shuffled, y_pred, average = None)[0]\n",
    "            f1_avg = f1_score(y_shuffled, y_pred, average = 'macro')\n",
    "            #print(\"\\t\\t\",tkey,\"Dev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            print(\"\\t\\t\",tkey,\"Dev epoch %d, average loss %0.3f,average accuracy %0.3f,auc %0.3f,f1_pos %0.3f,f1_neg %0.3f,f1_avg %0.3f\"\n",
    "                  %(e, avg_loss, avg_acc, roc_auc,f1_pos,f1_neg,f1_avg))\n",
    "\n",
    "        # Save model weights for future use.       \n",
    "            #save_path = saver.save(sess, checkpoint_prefix, global_step=20,write_meta_graph=False)\n",
    "            save_path = saver.save(sess, checkpoint_prefix)\n",
    "            print(\"Saved model\", model_name, save_path)\n",
    "    return results\n",
    "            \n",
    "            #calculate predictions and prediction probability    \n",
    "#             feed_dict={cnn.input_x:x_dev, cnn.input_y: y_dev, cnn.dropout_keep_prob: 1.0}\n",
    "#             y_pred, y_pred_proba = sess.run([cnn.predictions, cnn.pred_proba],feed_dict)\n",
    "            #print(y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source key hnk target key aut\n",
      "completed cnn creation\n",
      "# batches = 3906\n",
      "Train epoch 0, average loss 0.258582, average accuracy 0.893489,\n",
      "\tDev epoch 0,average loss 0.191,average accuracy 0.922,auc 0.958,f1_pos 0.954,f1_neg 0.729,f1_avg 0.841\n",
      "\t\t\t\t    Time taken for 0 epochs =  171.32153391838074\n",
      "Train epoch 2, average loss 0.160047, average accuracy 0.93687,\n",
      "\tDev epoch 2,average loss 0.157,average accuracy 0.938,auc 0.970,f1_pos 0.964,f1_neg 0.799,f1_avg 0.881\n",
      "Train epoch 4, average loss 0.129111, average accuracy 0.950169,\n",
      "\tDev epoch 4,average loss 0.156,average accuracy 0.940,auc 0.973,f1_pos 0.965,f1_neg 0.802,f1_avg 0.883\n",
      "\t\t\t\t    Time taken for 4 epochs =  830.5376477241516\n",
      "Train epoch 6, average loss 0.10733, average accuracy 0.958645,\n",
      "\tDev epoch 6,average loss 0.171,average accuracy 0.937,auc 0.972,f1_pos 0.963,f1_neg 0.788,f1_avg 0.875\n",
      "Train epoch 8, average loss 0.0912652, average accuracy 0.965222,\n",
      "\tDev epoch 8,average loss 0.159,average accuracy 0.942,auc 0.974,f1_pos 0.965,f1_neg 0.832,f1_avg 0.899\n",
      "\t\t\t\t    Time taken for 8 epochs =  1489.2059216499329\n",
      "Train epoch 10, average loss 0.0779423, average accuracy 0.970518,\n",
      "\tDev epoch 10,average loss 0.162,average accuracy 0.944,auc 0.973,f1_pos 0.967,f1_neg 0.826,f1_avg 0.896\n",
      "Train epoch 12, average loss 0.068073, average accuracy 0.974434,\n",
      "\tDev epoch 12,average loss 0.171,average accuracy 0.943,auc 0.973,f1_pos 0.966,f1_neg 0.824,f1_avg 0.895\n",
      "\t\t\t\t    Time taken for 12 epochs =  2147.478137254715\n",
      "Train epoch 14, average loss 0.0585672, average accuracy 0.978113,\n",
      "\tDev epoch 14,average loss 0.177,average accuracy 0.944,auc 0.972,f1_pos 0.966,f1_neg 0.830,f1_avg 0.898\n",
      "\t\t aut Dev epoch 14, average loss 0.224,average accuracy 0.924,auc 0.951,f1_pos 0.955,f1_neg 0.743,f1_avg 0.849\n",
      "Saved model hnkaut /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1_avg</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>f1_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.922028</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.957551</td>\n",
       "      <td>0.954477</td>\n",
       "      <td>0.728506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.938281</td>\n",
       "      <td>0.881318</td>\n",
       "      <td>0.970426</td>\n",
       "      <td>0.96354</td>\n",
       "      <td>0.799097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.939842</td>\n",
       "      <td>0.883293</td>\n",
       "      <td>0.972707</td>\n",
       "      <td>0.964531</td>\n",
       "      <td>0.802055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.93718</td>\n",
       "      <td>0.875491</td>\n",
       "      <td>0.972184</td>\n",
       "      <td>0.963131</td>\n",
       "      <td>0.787851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.94221</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.973614</td>\n",
       "      <td>0.965104</td>\n",
       "      <td>0.831989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.943831</td>\n",
       "      <td>0.896376</td>\n",
       "      <td>0.972874</td>\n",
       "      <td>0.966501</td>\n",
       "      <td>0.826251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.943118</td>\n",
       "      <td>0.895197</td>\n",
       "      <td>0.972712</td>\n",
       "      <td>0.966065</td>\n",
       "      <td>0.824329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>500000</td>\n",
       "      <td>0.943798</td>\n",
       "      <td>0.897967</td>\n",
       "      <td>0.972327</td>\n",
       "      <td>0.96635</td>\n",
       "      <td>0.829584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size       acc    f1_avg       auc    f1_pos    f1_neg\n",
       "0   500000  0.922028  0.841492  0.957551  0.954477  0.728506\n",
       "2   500000  0.938281  0.881318  0.970426   0.96354  0.799097\n",
       "4   500000  0.939842  0.883293  0.972707  0.964531  0.802055\n",
       "6   500000   0.93718  0.875491  0.972184  0.963131  0.787851\n",
       "8   500000   0.94221  0.898546  0.973614  0.965104  0.831989\n",
       "10  500000  0.943831  0.896376  0.972874  0.966501  0.826251\n",
       "12  500000  0.943118  0.895197  0.972712  0.966065  0.824329\n",
       "14  500000  0.943798  0.897967  0.972327   0.96635  0.829584"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "results_transfer = pd.DataFrame()\n",
    "s_key = 'hnk' #Note : these need to be the same or a subset of the keys in the process_transfer input function which does the combined vocabulary preprocessing.\n",
    "t_key = 'aut'\n",
    "print('source key',s_key, 'target key',t_key)\n",
    "results = train_transfer_cnn(s_key,t_key,size_initial)\n",
    "results['size'] = size_initial\n",
    "results_transfer = pd.concat([results_transfer,results])\n",
    "results_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated continue_train for adding samples from target domain to continue to train on source domain.\n",
    "def continue_transfer_train(skey,size,tkey,tgt_train_df,tgt_train_y): \n",
    "#Note size is size of source domain train set for picking the right sized model parameters\n",
    "    \n",
    "    #out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", src_key))\n",
    "    #out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"testruns\", src_key))\n",
    "    \n",
    "    size_folder =  \"size_\" + str(size) \n",
    "    out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", skey, tkey, size_folder))\n",
    "    #saved model being picked is the one that was trained on source domain, but with the vocabulary of both domains combined\n",
    "    checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "    print(checkpoint_dir)\n",
    "    src_model = ''.join([skey, tkey])\n",
    "    #graph_meta_file = checkpoint_dir + '/' + 'hnk01_model.meta'\n",
    "#     graph_meta_file = checkpoint_dir + '/' + src_model +'01_model.meta'\n",
    "    graph=tf.Graph()\n",
    "    \n",
    "    x_train = tgt_train_df\n",
    "    y_train = tgt_train_y\n",
    "    x_dev = dict_transfer_dev_ids[tkey][skey][:np.int(size*0.3)]\n",
    "    y_dev = dict_dev_ypred[tkey][:np.int(size*0.3)]\n",
    "    V = len(dict_transfer_vect[skey][tkey].vocabulary_)\n",
    "    \n",
    "    #create a dataframe to store the results together and pass back out of the function\n",
    "    tmp_ix = [2*e for e in range(int((num_epochs+2)/2))]\n",
    "    results = pd.DataFrame(index = tmp_ix,columns = ['size','acc','auc','f1_neg','f1_pos','f1_avg'])\n",
    "       \n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:           \n",
    "            cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, learning_rate = learning_rate,\n",
    "                        momentum = momentum, embedding_size=embed_dim, gl_embed = hands.W, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    " \n",
    "            saver = tf.train.Saver()\n",
    "    \n",
    "          #new_saver = tf.train.import_meta_graph(checkpoint_dir/'hnk_model.meta')\n",
    "#             new_saver = tf.train.import_meta_graph(graph_meta_file)\n",
    "#             new_saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "            \n",
    "            \n",
    "            #initializing weights from a previous session \n",
    "            initialising_model = src_model+'_model'\n",
    "            print(\" RESTORING SESSION FOR WEIGHTS INITIALIZATION\")\n",
    "            # Exclude output layer weights from variables we will restore\n",
    "            variables_to_restore = [v for v in tf.global_variables()]\n",
    "            # Replace variables scope with that of the current model\n",
    "            loader = tf.train.Saver({v.op.name.replace(src_model, initialising_model): v for v in variables_to_restore})\n",
    "            load_path = checkpoint_dir + '/' + initialising_model \n",
    "            #load_path = checkpoint_dir  \n",
    "            loader.restore(sess, load_path)\n",
    "            print(\" Model loaded from: \" + load_path) \n",
    "            print('# batches =', len(x_train)//batch_size)\n",
    "            start = time.time()\n",
    "           \n",
    "            for e in range(num_epochs):\n",
    "                    \n",
    "                #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                total_auc = 0\n",
    "                for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size, Trainable=True), 1):\n",
    "                    feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                   # _, loss, accuracy, auc = sess.run([cnn.optimizer,cnn.loss, cnn.accuracy, cnn.auc],feed_dict = feed)\n",
    "                    _, loss, accuracy = sess.run([cnn.optimizer,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    \n",
    "                    #total_auc += auc*len(x)\n",
    "                    \n",
    "                if e%evaluate_train==0:\n",
    "                    avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                    avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                    #avg_auc = total_auc/(batch_size*(len(x_train)//batch_size))\n",
    "                   # print(\"Train epoch {}, average loss {:g}, average accuracy {:g},average auc {:g}\".format(e, avg_loss, avg_acc, avg_auc))\n",
    "                    print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "\n",
    "                if e%evaluate_dev==0:\n",
    "                    \n",
    "                    total_loss = 0\n",
    "                    total_acc = 0\n",
    "                    num_batches = 0\n",
    "                    total_auc = 0\n",
    "                    y_pred = []\n",
    "                    y_pred_proba = []\n",
    "                    y_shuffled = []\n",
    "                    total_batch_acc = 0\n",
    "                    for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size, Trainable=False), 1):\n",
    "                        feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                        #loss, accuracy, auc = sess.run([cnn.loss, cnn.accuracy, cnn.auc],feed_dict)\n",
    "                       # batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                        batch_pred,batch_pred_proba,loss, accuracy  = sess.run([cnn.predictions, cnn.pred_proba, cnn.loss, cnn.accuracy],feed_dict)\n",
    "                        total_loss += loss*len(x)\n",
    "                        total_acc += accuracy*len(x)\n",
    "                        \n",
    "                        batch_accuracy= np.sum(y==batch_pred)/y.shape[0]\n",
    "                        total_batch_acc += batch_accuracy\n",
    "                        y_pred= np.concatenate([y_pred, batch_pred])\n",
    "                        y_pred_proba= np.concatenate([y_pred_proba, batch_pred_proba[:,1]])\n",
    "                        y_shuffled = np.concatenate([y_shuffled, y])\n",
    "                        \n",
    "                        num_batches += 1\n",
    "                        \n",
    "                    avg_loss = total_loss/(num_batches*batch_size)\n",
    "                    avg_acc = total_acc/(num_batches*batch_size)\n",
    "                                    \n",
    "                    #right_acc = total_batch_acc/(num_batches)\n",
    "                    #avg_auc = total_auc/(num_batches*batch_size)\n",
    "                    \n",
    "                    #Calculate Accuracy\n",
    "                    #new_acc = accuracy_score(y_shuffled, y_pred, normalize=True ) \n",
    "                     \n",
    "                    false_pos_rate, true_pos_rate, _ = roc_curve(y_shuffled, y_pred_proba)  \n",
    "                    roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "                    f1_pos = f1_score(y_shuffled, y_pred, average = None)[1]\n",
    "                    f1_neg = f1_score(y_shuffled, y_pred, average = None)[0]\n",
    "                    f1_avg = f1_score(y_shuffled, y_pred, average = 'macro')\n",
    "                    \n",
    "                    results['acc'][e] = avg_acc\n",
    "                    results['auc'][e] = roc_auc\n",
    "                    results['f1_avg'][e] = f1_avg\n",
    "                    results['f1_pos'][e] = f1_pos\n",
    "                    results['f1_neg'][e] = f1_neg\n",
    "                    \n",
    "                    \n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                    print(\"\\t\\t\",tkey,\"Dev epoch %d, average loss %0.3f,average accuracy %0.3f,auc %0.3f,f1_pos %0.3f,f1_neg %0.3f,f1_avg %0.3f\"\n",
    "                  %(e, avg_loss, avg_acc, roc_auc,f1_pos,f1_neg,f1_avg))\n",
    "                    #print(\"\\t\\tDev epoch {}, auc {:g}, new accuracy {:g}, right accuracy {:g},\".format(e,  roc_auc, new_acc, right_acc))\n",
    "                    #print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},average auc {:g}\".format(e, avg_loss, avg_acc, avg_auc))\n",
    "                if e%time_print == 0:\n",
    "                    end = time.time()\n",
    "                    print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)\n",
    "                    \n",
    "    return results\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the predicted probability for positive and negative class on target train set using source model\n",
    "#source model is the one built on the combined vocabulary of both\n",
    "def predict_transfer_probability(src_key, size, tar_key):\n",
    "    #size here is full target train set size - so we can calculate uncertainty on all of it before sorting\n",
    "    \n",
    "    batch_size=50\n",
    "    print('target',tar_key,'source', src_key)\n",
    "    V = len(dict_transfer_vect[src_key][tar_key].vocabulary_)\n",
    "    \n",
    "    size_folder =  \"size_\" + str(size) \n",
    "    out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", src_key, tar_key, size_folder))\n",
    "    #out_dir  = os.path.abspath(os.path.join(os.path.curdir, \"runs\", src_key))\n",
    "    checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))    \n",
    "    print(checkpoint_dir)\n",
    "    src_model = ''.join([src_key, tar_key])\n",
    "    #graph_meta_file = checkpoint_dir + '/' + 'hnk01_model.meta'\n",
    "    graph_meta_file = checkpoint_dir + '/' + src_model +'_model.meta'\n",
    "    graph=tf.Graph()\n",
    "    \n",
    "    x_train = dict_transfer_train_ids[tar_key][src_key][:size]\n",
    "    y_train = dict_train_y[tar_key][:size]\n",
    "\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "    \n",
    "      #new_saver = tf.train.import_meta_graph(checkpoint_dir/'hnk_model.meta')\n",
    "            new_saver = tf.train.import_meta_graph(graph_meta_file)\n",
    "            new_saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir))\n",
    "        \n",
    "            #create graph from saved model\n",
    "            input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "            input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "            dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "        \n",
    "            pred_proba = graph.get_operation_by_name(\"output/pred_proba\").outputs[0]\n",
    "            predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "        \n",
    "            y_pred = []\n",
    "            y_pred_proba = []\n",
    "            total_batch_acc = 0\n",
    "            num_batches = 0\n",
    "            y_shuffled = []\n",
    "            abs_y_pred_proba = []\n",
    "            for ii, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size, Trainable=False), 1):\n",
    "                        \n",
    "                feed_dict = {input_x: x, input_y: y, dropout_keep_prob: 1.0}\n",
    "                batch_pred, batch_pred_proba  = sess.run([ predictions, pred_proba],feed_dict)\n",
    "                batch_accuracy= np.sum(y==batch_pred)/y.shape[0]\n",
    "                total_batch_acc += batch_accuracy\n",
    "                y_pred= np.concatenate([y_pred, batch_pred])\n",
    "                y_pred_proba= np.concatenate([y_pred_proba, batch_pred_proba[:,1]])\n",
    "                abs_y_pred_proba = np.concatenate([abs_y_pred_proba,np.absolute(batch_pred_proba[:,1] - batch_pred_proba[:,0])])\n",
    "                y_shuffled = np.concatenate([y_shuffled, y])\n",
    "\n",
    "                num_batches += 1       \n",
    "            #y_pred = np.array(y_pred_list)         \n",
    "              \n",
    "            new_acc = total_batch_acc/(num_batches)\n",
    "            print(new_acc)\n",
    "        \n",
    "            # Calculate auc\n",
    "            # false_pos_rate, true_pos_rate, _ = roc_curve(y_dev, y_pred_proba[:,1])\n",
    "            false_pos_rate, true_pos_rate, _ = roc_curve(y_shuffled, y_pred_proba)  \n",
    "            roc_auc = auc(false_pos_rate, true_pos_rate)\n",
    "            print(src_key, tar_key, \"AUC\",\"{:.02%}\".format(roc_auc))\n",
    "            \n",
    "            #Calculate Accuracy\n",
    "            acc = accuracy_score(y_shuffled, y_pred, normalize=True )\n",
    "            #print(np.sum(y_shuffled==y_pred)/y_pred.shape[0])\n",
    "            print('source',src_key, 'target',tar_key, \"accuracy\",\"{:.02%}\".format(acc))\n",
    "            print(\"\")\n",
    "        \n",
    "        #Save absolute_y_pred_proba\n",
    "        \n",
    "        #check if the batching process left remainders. This will result in incorrect length of y_pred_proba saved\n",
    "        if y_train.shape[0] != abs_y_pred_proba.shape[0]:\n",
    "            print(\"Length of y_pred_proba does not match y_dev. Fix batch_size\")\n",
    "            print(\"Pred proba file not saved\")\n",
    "        else:\n",
    "            return abs_y_pred_proba\n",
    "#             file_name = \"src_\" + src_key + \"_tar_\" + tar_key + \"_\" + \"train\" + str(y_train.shape[0])\n",
    "#             np.savez_compressed(file_name,pred_prob=abs_y_pred_proba)\n",
    "#             print( file_name, \"Saved file successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source domain hnk Target Domain aut\n",
      "Training on target sample of size: 20000\n",
      "(20000, 150) (20000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 156\n",
      "Train epoch 0, average loss 0.254172, average accuracy 0.917768,\n",
      "\t\t aut Dev epoch 0, average loss 0.221,average accuracy 0.927,auc 0.946,f1_pos 0.958,f1_neg 0.703,f1_avg 0.831\n",
      "\t\t\t\t    Time taken for 0 epochs =  18.831366300582886\n",
      "Train epoch 2, average loss 0.0760896, average accuracy 0.973407,\n",
      "\t\t aut Dev epoch 2, average loss 0.204,average accuracy 0.930,auc 0.949,f1_pos 0.960,f1_neg 0.745,f1_avg 0.852\n",
      "Train epoch 4, average loss 0.0430212, average accuracy 0.987079,\n",
      "\t\t aut Dev epoch 4, average loss 0.210,average accuracy 0.930,auc 0.951,f1_pos 0.959,f1_neg 0.742,f1_avg 0.851\n",
      "\t\t\t\t    Time taken for 4 epochs =  68.58986330032349\n",
      "Train epoch 6, average loss 0.0267046, average accuracy 0.99379,\n",
      "\t\t aut Dev epoch 6, average loss 0.230,average accuracy 0.931,auc 0.949,f1_pos 0.960,f1_neg 0.728,f1_avg 0.844\n",
      "Train epoch 8, average loss 0.0190894, average accuracy 0.996094,\n",
      "\t\t aut Dev epoch 8, average loss 0.219,average accuracy 0.931,auc 0.952,f1_pos 0.960,f1_neg 0.744,f1_avg 0.852\n",
      "\t\t\t\t    Time taken for 8 epochs =  118.34777665138245\n",
      "Train epoch 10, average loss 0.0155893, average accuracy 0.996895,\n",
      "\t\t aut Dev epoch 10, average loss 0.231,average accuracy 0.931,auc 0.952,f1_pos 0.960,f1_neg 0.737,f1_avg 0.849\n",
      "Train epoch 12, average loss 0.0116561, average accuracy 0.998448,\n",
      "\t\t aut Dev epoch 12, average loss 0.227,average accuracy 0.931,auc 0.952,f1_pos 0.960,f1_neg 0.748,f1_avg 0.854\n",
      "\t\t\t\t    Time taken for 12 epochs =  168.04546308517456\n",
      "Train epoch 14, average loss 0.00947399, average accuracy 0.999199,\n",
      "\t\t aut Dev epoch 14, average loss 0.247,average accuracy 0.931,auc 0.952,f1_pos 0.961,f1_neg 0.732,f1_avg 0.846\n",
      "Training on target sample of size: 50000\n",
      "(50000, 150) (50000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 390\n",
      "Train epoch 0, average loss 0.240113, average accuracy 0.918249,\n",
      "\t\t aut Dev epoch 0, average loss 0.194,average accuracy 0.929,auc 0.946,f1_pos 0.959,f1_neg 0.732,f1_avg 0.845\n",
      "\t\t\t\t    Time taken for 0 epochs =  28.03827929496765\n",
      "Train epoch 2, average loss 0.0988474, average accuracy 0.9628,\n",
      "\t\t aut Dev epoch 2, average loss 0.200,average accuracy 0.931,auc 0.950,f1_pos 0.961,f1_neg 0.734,f1_avg 0.847\n",
      "Train epoch 4, average loss 0.0588787, average accuracy 0.979407,\n",
      "\t\t aut Dev epoch 4, average loss 0.200,average accuracy 0.933,auc 0.952,f1_pos 0.961,f1_neg 0.748,f1_avg 0.855\n",
      "\t\t\t\t    Time taken for 4 epochs =  115.55077362060547\n",
      "Train epoch 6, average loss 0.0398816, average accuracy 0.988502,\n",
      "\t\t aut Dev epoch 6, average loss 0.208,average accuracy 0.933,auc 0.953,f1_pos 0.961,f1_neg 0.747,f1_avg 0.854\n",
      "Train epoch 8, average loss 0.0281732, average accuracy 0.993429,\n",
      "\t\t aut Dev epoch 8, average loss 0.215,average accuracy 0.933,auc 0.953,f1_pos 0.961,f1_neg 0.749,f1_avg 0.855\n",
      "\t\t\t\t    Time taken for 8 epochs =  203.17495346069336\n",
      "Train epoch 10, average loss 0.0220534, average accuracy 0.995072,\n",
      "\t\t aut Dev epoch 10, average loss 0.216,average accuracy 0.933,auc 0.953,f1_pos 0.961,f1_neg 0.755,f1_avg 0.858\n",
      "Train epoch 12, average loss 0.0171578, average accuracy 0.996514,\n",
      "\t\t aut Dev epoch 12, average loss 0.219,average accuracy 0.933,auc 0.954,f1_pos 0.961,f1_neg 0.756,f1_avg 0.859\n",
      "\t\t\t\t    Time taken for 12 epochs =  290.8682265281677\n",
      "Train epoch 14, average loss 0.0142282, average accuracy 0.997396,\n",
      "\t\t aut Dev epoch 14, average loss 0.251,average accuracy 0.932,auc 0.952,f1_pos 0.961,f1_neg 0.732,f1_avg 0.847\n",
      "Training on target sample of size: 100000\n",
      "(100000, 150) (100000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.226757, average accuracy 0.919714,\n",
      "\t\t aut Dev epoch 0, average loss 0.188,average accuracy 0.928,auc 0.950,f1_pos 0.958,f1_neg 0.746,f1_avg 0.852\n",
      "\t\t\t\t    Time taken for 0 epochs =  43.84932613372803\n",
      "Train epoch 2, average loss 0.113608, average accuracy 0.956756,\n",
      "\t\t aut Dev epoch 2, average loss 0.182,average accuracy 0.934,auc 0.955,f1_pos 0.962,f1_neg 0.749,f1_avg 0.856\n",
      "Train epoch 4, average loss 0.0746121, average accuracy 0.973061,\n",
      "\t\t aut Dev epoch 4, average loss 0.187,average accuracy 0.935,auc 0.956,f1_pos 0.962,f1_neg 0.761,f1_avg 0.861\n",
      "\t\t\t\t    Time taken for 4 epochs =  194.75835132598877\n",
      "Train epoch 6, average loss 0.0533392, average accuracy 0.981834,\n",
      "\t\t aut Dev epoch 6, average loss 0.217,average accuracy 0.934,auc 0.951,f1_pos 0.962,f1_neg 0.738,f1_avg 0.850\n",
      "Train epoch 8, average loss 0.0399462, average accuracy 0.987606,\n",
      "\t\t aut Dev epoch 8, average loss 0.203,average accuracy 0.933,auc 0.956,f1_pos 0.961,f1_neg 0.766,f1_avg 0.863\n",
      "\t\t\t\t    Time taken for 8 epochs =  345.84131264686584\n",
      "Train epoch 10, average loss 0.0312478, average accuracy 0.991347,\n",
      "\t\t aut Dev epoch 10, average loss 0.213,average accuracy 0.934,auc 0.955,f1_pos 0.962,f1_neg 0.760,f1_avg 0.861\n",
      "Train epoch 12, average loss 0.0240519, average accuracy 0.993748,\n",
      "\t\t aut Dev epoch 12, average loss 0.222,average accuracy 0.935,auc 0.955,f1_pos 0.962,f1_neg 0.765,f1_avg 0.864\n",
      "\t\t\t\t    Time taken for 12 epochs =  496.8087182044983\n",
      "Train epoch 14, average loss 0.0202334, average accuracy 0.994938,\n",
      "\t\t aut Dev epoch 14, average loss 0.226,average accuracy 0.935,auc 0.956,f1_pos 0.962,f1_neg 0.766,f1_avg 0.864\n",
      "Training on target sample of size: 150000\n",
      "(150000, 150) (150000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1171\n",
      "Train epoch 0, average loss 0.222401, average accuracy 0.919934,\n",
      "\t\t aut Dev epoch 0, average loss 0.198,average accuracy 0.927,auc 0.950,f1_pos 0.958,f1_neg 0.690,f1_avg 0.824\n",
      "\t\t\t\t    Time taken for 0 epochs =  59.714216470718384\n",
      "Train epoch 2, average loss 0.121244, average accuracy 0.953038,\n",
      "\t\t aut Dev epoch 2, average loss 0.179,average accuracy 0.935,auc 0.956,f1_pos 0.963,f1_neg 0.751,f1_avg 0.857\n",
      "Train epoch 4, average loss 0.0848078, average accuracy 0.968343,\n",
      "\t\t aut Dev epoch 4, average loss 0.182,average accuracy 0.936,auc 0.957,f1_pos 0.963,f1_neg 0.769,f1_avg 0.866\n",
      "\t\t\t\t    Time taken for 4 epochs =  273.69706559181213\n",
      "Train epoch 6, average loss 0.0624131, average accuracy 0.97795,\n",
      "\t\t aut Dev epoch 6, average loss 0.191,average accuracy 0.936,auc 0.957,f1_pos 0.963,f1_neg 0.764,f1_avg 0.863\n",
      "Train epoch 8, average loss 0.0481468, average accuracy 0.983868,\n",
      "\t\t aut Dev epoch 8, average loss 0.199,average accuracy 0.935,auc 0.957,f1_pos 0.962,f1_neg 0.767,f1_avg 0.864\n",
      "\t\t\t\t    Time taken for 8 epochs =  487.64967370033264\n",
      "Train epoch 10, average loss 0.0382967, average accuracy 0.987591,\n",
      "\t\t aut Dev epoch 10, average loss 0.207,average accuracy 0.934,auc 0.957,f1_pos 0.962,f1_neg 0.767,f1_avg 0.864\n",
      "Train epoch 12, average loss 0.0310529, average accuracy 0.99054,\n",
      "\t\t aut Dev epoch 12, average loss 0.216,average accuracy 0.935,auc 0.957,f1_pos 0.962,f1_neg 0.768,f1_avg 0.865\n",
      "\t\t\t\t    Time taken for 12 epochs =  701.838125705719\n",
      "Train epoch 14, average loss 0.0260882, average accuracy 0.992248,\n",
      "\t\t aut Dev epoch 14, average loss 0.231,average accuracy 0.936,auc 0.956,f1_pos 0.963,f1_neg 0.764,f1_avg 0.863\n",
      "Training on target sample of size: 200000\n",
      "(200000, 150) (200000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1562\n",
      "Train epoch 0, average loss 0.217244, average accuracy 0.921135,\n",
      "\t\t aut Dev epoch 0, average loss 0.184,average accuracy 0.930,auc 0.952,f1_pos 0.960,f1_neg 0.723,f1_avg 0.842\n",
      "\t\t\t\t    Time taken for 0 epochs =  75.44620251655579\n",
      "Train epoch 2, average loss 0.126265, average accuracy 0.951219,\n",
      "\t\t aut Dev epoch 2, average loss 0.175,average accuracy 0.936,auc 0.958,f1_pos 0.963,f1_neg 0.752,f1_avg 0.858\n",
      "Train epoch 4, average loss 0.0938922, average accuracy 0.964724,\n",
      "\t\t aut Dev epoch 4, average loss 0.183,average accuracy 0.936,auc 0.958,f1_pos 0.963,f1_neg 0.753,f1_avg 0.858\n",
      "\t\t\t\t    Time taken for 4 epochs =  352.7662105560303\n",
      "Train epoch 6, average loss 0.0734392, average accuracy 0.972966,\n",
      "\t\t aut Dev epoch 6, average loss 0.184,average accuracy 0.936,auc 0.959,f1_pos 0.962,f1_neg 0.774,f1_avg 0.868\n",
      "Train epoch 8, average loss 0.0571819, average accuracy 0.979909,\n",
      "\t\t aut Dev epoch 8, average loss 0.192,average accuracy 0.936,auc 0.958,f1_pos 0.963,f1_neg 0.768,f1_avg 0.866\n",
      "\t\t\t\t    Time taken for 8 epochs =  630.0042014122009\n",
      "Train epoch 10, average loss 0.0469925, average accuracy 0.983985,\n",
      "\t\t aut Dev epoch 10, average loss 0.208,average accuracy 0.937,auc 0.957,f1_pos 0.964,f1_neg 0.763,f1_avg 0.863\n",
      "Train epoch 12, average loss 0.0389434, average accuracy 0.987016,\n",
      "\t\t aut Dev epoch 12, average loss 0.235,average accuracy 0.936,auc 0.953,f1_pos 0.963,f1_neg 0.748,f1_avg 0.855\n",
      "\t\t\t\t    Time taken for 12 epochs =  907.2140045166016\n",
      "Train epoch 14, average loss 0.0331044, average accuracy 0.989267,\n",
      "\t\t aut Dev epoch 14, average loss 0.221,average accuracy 0.935,auc 0.956,f1_pos 0.962,f1_neg 0.771,f1_avg 0.867\n",
      "Training on target sample of size: 300000\n",
      "(300000, 150) (300000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 2343\n",
      "Train epoch 0, average loss 0.208181, average accuracy 0.923129,\n",
      "\t\t aut Dev epoch 0, average loss 0.171,average accuracy 0.934,auc 0.957,f1_pos 0.962,f1_neg 0.748,f1_avg 0.855\n",
      "\t\t\t\t    Time taken for 0 epochs =  106.9891402721405\n",
      "Train epoch 2, average loss 0.13072, average accuracy 0.949474,\n",
      "\t\t aut Dev epoch 2, average loss 0.169,average accuracy 0.936,auc 0.961,f1_pos 0.964,f1_neg 0.751,f1_avg 0.857\n",
      "Train epoch 4, average loss 0.10302, average accuracy 0.960934,\n",
      "\t\t aut Dev epoch 4, average loss 0.167,average accuracy 0.938,auc 0.963,f1_pos 0.964,f1_neg 0.776,f1_avg 0.870\n",
      "\t\t\t\t    Time taken for 4 epochs =  510.52668833732605\n",
      "Train epoch 6, average loss 0.0825237, average accuracy 0.96936,\n",
      "\t\t aut Dev epoch 6, average loss 0.178,average accuracy 0.939,auc 0.960,f1_pos 0.965,f1_neg 0.768,f1_avg 0.866\n",
      "Train epoch 8, average loss 0.0682703, average accuracy 0.974759,\n",
      "\t\t aut Dev epoch 8, average loss 0.187,average accuracy 0.939,auc 0.959,f1_pos 0.965,f1_neg 0.772,f1_avg 0.868\n",
      "\t\t\t\t    Time taken for 8 epochs =  914.1747541427612\n",
      "Train epoch 10, average loss 0.0573623, average accuracy 0.979187,\n",
      "\t\t aut Dev epoch 10, average loss 0.203,average accuracy 0.939,auc 0.959,f1_pos 0.965,f1_neg 0.768,f1_avg 0.867\n",
      "Train epoch 12, average loss 0.0498296, average accuracy 0.982114,\n",
      "\t\t aut Dev epoch 12, average loss 0.219,average accuracy 0.938,auc 0.957,f1_pos 0.964,f1_neg 0.759,f1_avg 0.862\n",
      "\t\t\t\t    Time taken for 12 epochs =  1317.9438281059265\n",
      "Train epoch 14, average loss 0.0429114, average accuracy 0.984969,\n",
      "\t\t aut Dev epoch 14, average loss 0.221,average accuracy 0.938,auc 0.956,f1_pos 0.964,f1_neg 0.768,f1_avg 0.866\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>f1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.927092</td>\n",
       "      <td>0.945534</td>\n",
       "      <td>0.703301</td>\n",
       "      <td>0.95844</td>\n",
       "      <td>0.830871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.930281</td>\n",
       "      <td>0.949258</td>\n",
       "      <td>0.744823</td>\n",
       "      <td>0.959625</td>\n",
       "      <td>0.852224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.929968</td>\n",
       "      <td>0.950764</td>\n",
       "      <td>0.742411</td>\n",
       "      <td>0.959475</td>\n",
       "      <td>0.850943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.930515</td>\n",
       "      <td>0.94889</td>\n",
       "      <td>0.727534</td>\n",
       "      <td>0.96018</td>\n",
       "      <td>0.843857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.931102</td>\n",
       "      <td>0.951785</td>\n",
       "      <td>0.744185</td>\n",
       "      <td>0.96019</td>\n",
       "      <td>0.852187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.931209</td>\n",
       "      <td>0.951819</td>\n",
       "      <td>0.737051</td>\n",
       "      <td>0.960428</td>\n",
       "      <td>0.84874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.931469</td>\n",
       "      <td>0.951808</td>\n",
       "      <td>0.747926</td>\n",
       "      <td>0.960344</td>\n",
       "      <td>0.854135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.931342</td>\n",
       "      <td>0.951628</td>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.96063</td>\n",
       "      <td>0.846265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.928733</td>\n",
       "      <td>0.946069</td>\n",
       "      <td>0.731581</td>\n",
       "      <td>0.958912</td>\n",
       "      <td>0.845247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.931302</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.733769</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.847166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.93251</td>\n",
       "      <td>0.951787</td>\n",
       "      <td>0.748108</td>\n",
       "      <td>0.961035</td>\n",
       "      <td>0.854571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.93303</td>\n",
       "      <td>0.952861</td>\n",
       "      <td>0.747064</td>\n",
       "      <td>0.961406</td>\n",
       "      <td>0.854235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.93319</td>\n",
       "      <td>0.952613</td>\n",
       "      <td>0.749412</td>\n",
       "      <td>0.961457</td>\n",
       "      <td>0.855434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>0.953335</td>\n",
       "      <td>0.755396</td>\n",
       "      <td>0.961088</td>\n",
       "      <td>0.858242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.93257</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.75617</td>\n",
       "      <td>0.960875</td>\n",
       "      <td>0.858522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.932289</td>\n",
       "      <td>0.95248</td>\n",
       "      <td>0.731856</td>\n",
       "      <td>0.961253</td>\n",
       "      <td>0.846554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.928427</td>\n",
       "      <td>0.949955</td>\n",
       "      <td>0.746287</td>\n",
       "      <td>0.958337</td>\n",
       "      <td>0.852312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.933557</td>\n",
       "      <td>0.955183</td>\n",
       "      <td>0.749478</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.855589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.934638</td>\n",
       "      <td>0.955957</td>\n",
       "      <td>0.760669</td>\n",
       "      <td>0.962151</td>\n",
       "      <td>0.86141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.933911</td>\n",
       "      <td>0.950856</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.962181</td>\n",
       "      <td>0.850218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.932803</td>\n",
       "      <td>0.955912</td>\n",
       "      <td>0.765767</td>\n",
       "      <td>0.960775</td>\n",
       "      <td>0.863271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.934384</td>\n",
       "      <td>0.955138</td>\n",
       "      <td>0.76021</td>\n",
       "      <td>0.961992</td>\n",
       "      <td>0.861101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.934785</td>\n",
       "      <td>0.954719</td>\n",
       "      <td>0.765176</td>\n",
       "      <td>0.962134</td>\n",
       "      <td>0.863655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.934718</td>\n",
       "      <td>0.955554</td>\n",
       "      <td>0.765601</td>\n",
       "      <td>0.962078</td>\n",
       "      <td>0.863839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.926605</td>\n",
       "      <td>0.950026</td>\n",
       "      <td>0.689982</td>\n",
       "      <td>0.958375</td>\n",
       "      <td>0.824179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935425</td>\n",
       "      <td>0.95595</td>\n",
       "      <td>0.750728</td>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.856818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.936226</td>\n",
       "      <td>0.956665</td>\n",
       "      <td>0.769112</td>\n",
       "      <td>0.963003</td>\n",
       "      <td>0.866058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935745</td>\n",
       "      <td>0.956712</td>\n",
       "      <td>0.763709</td>\n",
       "      <td>0.962817</td>\n",
       "      <td>0.863263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.934605</td>\n",
       "      <td>0.957107</td>\n",
       "      <td>0.766786</td>\n",
       "      <td>0.96197</td>\n",
       "      <td>0.864378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.934097</td>\n",
       "      <td>0.956712</td>\n",
       "      <td>0.766753</td>\n",
       "      <td>0.961628</td>\n",
       "      <td>0.864191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935245</td>\n",
       "      <td>0.957408</td>\n",
       "      <td>0.767799</td>\n",
       "      <td>0.962376</td>\n",
       "      <td>0.865088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935892</td>\n",
       "      <td>0.955676</td>\n",
       "      <td>0.763645</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>0.863281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.930448</td>\n",
       "      <td>0.952295</td>\n",
       "      <td>0.722806</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.84152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.935885</td>\n",
       "      <td>0.958204</td>\n",
       "      <td>0.752256</td>\n",
       "      <td>0.963178</td>\n",
       "      <td>0.857717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.936139</td>\n",
       "      <td>0.957963</td>\n",
       "      <td>0.753083</td>\n",
       "      <td>0.963327</td>\n",
       "      <td>0.858205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.935619</td>\n",
       "      <td>0.95851</td>\n",
       "      <td>0.773984</td>\n",
       "      <td>0.962463</td>\n",
       "      <td>0.868223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.936299</td>\n",
       "      <td>0.958458</td>\n",
       "      <td>0.768084</td>\n",
       "      <td>0.963079</td>\n",
       "      <td>0.865581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.936779</td>\n",
       "      <td>0.957264</td>\n",
       "      <td>0.762673</td>\n",
       "      <td>0.963533</td>\n",
       "      <td>0.863103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.935565</td>\n",
       "      <td>0.952564</td>\n",
       "      <td>0.747846</td>\n",
       "      <td>0.963063</td>\n",
       "      <td>0.855455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.935278</td>\n",
       "      <td>0.956371</td>\n",
       "      <td>0.771111</td>\n",
       "      <td>0.962311</td>\n",
       "      <td>0.866711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.933891</td>\n",
       "      <td>0.957431</td>\n",
       "      <td>0.747959</td>\n",
       "      <td>0.961956</td>\n",
       "      <td>0.854957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.936326</td>\n",
       "      <td>0.96145</td>\n",
       "      <td>0.750692</td>\n",
       "      <td>0.963502</td>\n",
       "      <td>0.857097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.938227</td>\n",
       "      <td>0.962655</td>\n",
       "      <td>0.776109</td>\n",
       "      <td>0.964171</td>\n",
       "      <td>0.87014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.938688</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.767695</td>\n",
       "      <td>0.964683</td>\n",
       "      <td>0.866189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.938674</td>\n",
       "      <td>0.958717</td>\n",
       "      <td>0.772114</td>\n",
       "      <td>0.96457</td>\n",
       "      <td>0.868342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.958832</td>\n",
       "      <td>0.768386</td>\n",
       "      <td>0.964849</td>\n",
       "      <td>0.866617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.937593</td>\n",
       "      <td>0.957016</td>\n",
       "      <td>0.759017</td>\n",
       "      <td>0.964155</td>\n",
       "      <td>0.861586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.938301</td>\n",
       "      <td>0.956095</td>\n",
       "      <td>0.768081</td>\n",
       "      <td>0.964417</td>\n",
       "      <td>0.866249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size       acc       auc    f1_neg    f1_pos    f1_avg\n",
       "0    20000  0.927092  0.945534  0.703301   0.95844  0.830871\n",
       "2    20000  0.930281  0.949258  0.744823  0.959625  0.852224\n",
       "4    20000  0.929968  0.950764  0.742411  0.959475  0.850943\n",
       "6    20000  0.930515   0.94889  0.727534   0.96018  0.843857\n",
       "8    20000  0.931102  0.951785  0.744185   0.96019  0.852187\n",
       "10   20000  0.931209  0.951819  0.737051  0.960428   0.84874\n",
       "12   20000  0.931469  0.951808  0.747926  0.960344  0.854135\n",
       "14   20000  0.931342  0.951628    0.7319   0.96063  0.846265\n",
       "0    50000  0.928733  0.946069  0.731581  0.958912  0.845247\n",
       "2    50000  0.931302  0.950176  0.733769  0.960563  0.847166\n",
       "4    50000   0.93251  0.951787  0.748108  0.961035  0.854571\n",
       "6    50000   0.93303  0.952861  0.747064  0.961406  0.854235\n",
       "8    50000   0.93319  0.952613  0.749412  0.961457  0.855434\n",
       "10   50000  0.932857  0.953335  0.755396  0.961088  0.858242\n",
       "12   50000   0.93257  0.954229   0.75617  0.960875  0.858522\n",
       "14   50000  0.932289   0.95248  0.731856  0.961253  0.846554\n",
       "0   100000  0.928427  0.949955  0.746287  0.958337  0.852312\n",
       "2   100000  0.933557  0.955183  0.749478    0.9617  0.855589\n",
       "4   100000  0.934638  0.955957  0.760669  0.962151   0.86141\n",
       "6   100000  0.933911  0.950856  0.738255  0.962181  0.850218\n",
       "8   100000  0.932803  0.955912  0.765767  0.960775  0.863271\n",
       "10  100000  0.934384  0.955138   0.76021  0.961992  0.861101\n",
       "12  100000  0.934785  0.954719  0.765176  0.962134  0.863655\n",
       "14  100000  0.934718  0.955554  0.765601  0.962078  0.863839\n",
       "0   150000  0.926605  0.950026  0.689982  0.958375  0.824179\n",
       "2   150000  0.935425   0.95595  0.750728  0.962908  0.856818\n",
       "4   150000  0.936226  0.956665  0.769112  0.963003  0.866058\n",
       "6   150000  0.935745  0.956712  0.763709  0.962817  0.863263\n",
       "8   150000  0.934605  0.957107  0.766786   0.96197  0.864378\n",
       "10  150000  0.934097  0.956712  0.766753  0.961628  0.864191\n",
       "12  150000  0.935245  0.957408  0.767799  0.962376  0.865088\n",
       "14  150000  0.935892  0.955676  0.763645  0.962917  0.863281\n",
       "0   200000  0.930448  0.952295  0.722806  0.960235   0.84152\n",
       "2   200000  0.935885  0.958204  0.752256  0.963178  0.857717\n",
       "4   200000  0.936139  0.957963  0.753083  0.963327  0.858205\n",
       "6   200000  0.935619   0.95851  0.773984  0.962463  0.868223\n",
       "8   200000  0.936299  0.958458  0.768084  0.963079  0.865581\n",
       "10  200000  0.936779  0.957264  0.762673  0.963533  0.863103\n",
       "12  200000  0.935565  0.952564  0.747846  0.963063  0.855455\n",
       "14  200000  0.935278  0.956371  0.771111  0.962311  0.866711\n",
       "0   300000  0.933891  0.957431  0.747959  0.961956  0.854957\n",
       "2   300000  0.936326   0.96145  0.750692  0.963502  0.857097\n",
       "4   300000  0.938227  0.962655  0.776109  0.964171   0.87014\n",
       "6   300000  0.938688  0.960235  0.767695  0.964683  0.866189\n",
       "8   300000  0.938674  0.958717  0.772114   0.96457  0.868342\n",
       "10  300000  0.938961  0.958832  0.768386  0.964849  0.866617\n",
       "12  300000  0.937593  0.957016  0.759017  0.964155  0.861586\n",
       "14  300000  0.938301  0.956095  0.768081  0.964417  0.866249"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Continue training with adding random samples from target domain\n",
    "num_epochs = 15\n",
    "size_model = size_initial\n",
    "size_list = [20000,50000,100000,150000,200000,300000]\n",
    "src_key = s_key\n",
    "tgt_key = t_key\n",
    "print('Source domain',src_key,'Target Domain',tgt_key)\n",
    "results_random = pd.DataFrame()\n",
    "for size in size_list:\n",
    "    print('Training on target sample of size:',size)\n",
    "    tgt_train_df = dict_transfer_train_ids[tgt_key][src_key][:size]\n",
    "    tgt_train_y = dict_train_y[tgt_key][:size]\n",
    "    print(tgt_train_df.shape,tgt_train_y.shape)\n",
    "    results = continue_transfer_train(src_key,size_model,tgt_key,tgt_train_df,tgt_train_y)\n",
    "    results['size'] = size\n",
    "    results_random = pd.concat([results_random,results])\n",
    "\n",
    "results_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target aut source hnk\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "0.923664\n",
      "hnk aut AUC 95.13%\n",
      "source hnk target aut accuracy 92.37%\n",
      "\n",
      "(500000,) (500000,) (500000,)\n",
      "max, min uncertainty absolute 1.0 2.38120555878e-05\n",
      "max, min length 150 0\n",
      "max, min certainty*length inf 3.57627868652e-05\n",
      "For range 0.00 to 0.10, average certainty = 0.37, average length = 59.17, average certainty per length = inf\n",
      "For range 0.10 to 0.20, average certainty = 0.81, average length = 56.11, average certainty per length = 4.35\n",
      "For range 0.20 to 0.30, average certainty = 0.95, average length = 53.03, average certainty per length = 5.05\n",
      "For range 0.30 to 0.40, average certainty = 0.98, average length = 51.32, average certainty per length = 5.27\n",
      "For range 0.40 to 0.50, average certainty = 0.99, average length = 49.85, average certainty per length = 5.41\n",
      "For range 0.50 to 0.60, average certainty = 1.00, average length = 49.58, average certainty per length = 4.85\n",
      "For range 0.60 to 0.70, average certainty = 1.00, average length = 49.47, average certainty per length = 4.74\n",
      "For range 0.70 to 0.80, average certainty = 1.00, average length = 49.64, average certainty per length = 4.48\n",
      "For range 0.80 to 0.90, average certainty = 1.00, average length = 50.56, average certainty per length = 4.33\n",
      "For range 0.90 to 1.00, average certainty = 1.00, average length = 54.72, average certainty per length = 3.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "#Calculating certainty for target train set review\n",
    "\n",
    "src_key = s_key #source domain\n",
    "tgt_key = t_key #target domain\n",
    "size = size_initial #This is source model train set data size to read from the right file.\n",
    "\n",
    "#calculate absolute difference of positive and negative class probability for target train set using source model built on combined vocab.\n",
    "\n",
    "u_train_target_abs = predict_transfer_probability(src_key, size, tgt_key)\n",
    "train_target_len = np.count_nonzero(dict_transfer_train_ids[tgt_key][src_key],axis =1)\n",
    "c_div_len_target = u_train_target_abs*150/train_target_len #calculates certainty per word id in the review\n",
    "# file_name = \"src_\" + src_key + \"_tar_\" + tar_key + \"_\" + \"train\" + str(size)\n",
    "# u_train_target_abs = np.load(file_name)\n",
    "print(u_train_target_abs.shape,train_target_len.shape,c_div_len_target.shape)\n",
    "print('max, min uncertainty absolute',np.max(u_train_target_abs),np.min(u_train_target_abs))\n",
    "print('max, min length',np.max(train_target_len),np.min(train_target_len))\n",
    "print('max, min certainty*length',np.max(c_div_len_target),np.min(c_div_len_target))\n",
    "\n",
    "#See if certainty is correlated with length\n",
    "span = 0.1\n",
    "sort_ids = np.argsort(u_train_target_abs)\n",
    "u_train_target_sorted = u_train_target_abs[sort_ids]\n",
    "train_target_len_sorted = train_target_len[sort_ids]\n",
    "c_div_len_sorted = c_div_len_target[sort_ids]\n",
    "range_l = int(span*len(u_train_target_sorted))\n",
    "\n",
    "for i in range(np.int(1/span)):\n",
    "    print(\"For range %0.2f to %0.2f, average certainty = %0.2f, average length = %0.2f, average certainty per length = %0.2f\"\n",
    "          %(i*span,(i+1)*span,np.average(u_train_target_sorted[i*range_l:(i+1)*range_l]),np.average(train_target_len_sorted[i*range_l:(i+1)*range_l]),\n",
    "           np.average(c_div_len_sorted[i*range_l:(i+1)*range_l])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe23f8f8518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "import pylab\n",
    "\n",
    "matplotlib.pyplot.scatter(u_train_target_abs,train_target_len)\n",
    "\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target labels pre sort [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      " Target labels post sort [1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1]\n",
      "\n",
      " Certainty sorted \n",
      " First 20 [  2.38120556e-05   2.93254852e-05   3.64184380e-05   7.98702240e-05\n",
      "   1.17838383e-04   1.23530626e-04   1.44541264e-04   1.46538019e-04\n",
      "   1.56641006e-04   1.61826611e-04   1.83373690e-04   2.12520361e-04\n",
      "   2.48491764e-04   2.49713659e-04   2.94387341e-04   3.12894583e-04\n",
      "   3.53246927e-04   3.89039516e-04   3.92913818e-04   3.99649143e-04] \n",
      " Last 20 [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "\n",
      "Training on least certain first\n",
      "Training on target sample of size: 20000 with average certainty 0.161\n",
      "(20000, 150) (20000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 156\n",
      "Train epoch 0, average loss 0.840707, average accuracy 0.61263,\n",
      "\t\t aut Dev epoch 0, average loss 0.198,average accuracy 0.927,auc 0.938,f1_pos 0.958,f1_neg 0.720,f1_avg 0.839\n",
      "\t\t\t\t    Time taken for 0 epochs =  18.871079444885254\n",
      "Train epoch 2, average loss 0.398603, average accuracy 0.816607,\n",
      "\t\t aut Dev epoch 2, average loss 0.187,average accuracy 0.932,auc 0.948,f1_pos 0.961,f1_neg 0.750,f1_avg 0.855\n",
      "Train epoch 4, average loss 0.265187, average accuracy 0.897236,\n",
      "\t\t aut Dev epoch 4, average loss 0.189,average accuracy 0.933,auc 0.951,f1_pos 0.961,f1_neg 0.759,f1_avg 0.860\n",
      "\t\t\t\t    Time taken for 4 epochs =  68.66011142730713\n",
      "Train epoch 6, average loss 0.188731, average accuracy 0.939052,\n",
      "\t\t aut Dev epoch 6, average loss 0.195,average accuracy 0.933,auc 0.951,f1_pos 0.961,f1_neg 0.755,f1_avg 0.858\n",
      "Train epoch 8, average loss 0.143409, average accuracy 0.959385,\n",
      "\t\t aut Dev epoch 8, average loss 0.206,average accuracy 0.933,auc 0.949,f1_pos 0.961,f1_neg 0.751,f1_avg 0.856\n",
      "\t\t\t\t    Time taken for 8 epochs =  118.40397047996521\n",
      "Train epoch 10, average loss 0.106731, average accuracy 0.974659,\n",
      "\t\t aut Dev epoch 10, average loss 0.224,average accuracy 0.933,auc 0.948,f1_pos 0.962,f1_neg 0.740,f1_avg 0.851\n",
      "Train epoch 12, average loss 0.085411, average accuracy 0.982121,\n",
      "\t\t aut Dev epoch 12, average loss 0.216,average accuracy 0.933,auc 0.952,f1_pos 0.961,f1_neg 0.754,f1_avg 0.857\n",
      "\t\t\t\t    Time taken for 12 epochs =  168.1929051876068\n",
      "Train epoch 14, average loss 0.0695648, average accuracy 0.985527,\n",
      "\t\t aut Dev epoch 14, average loss 0.221,average accuracy 0.932,auc 0.951,f1_pos 0.960,f1_neg 0.757,f1_avg 0.859\n",
      "Training on target sample of size: 50000 with average certainty 0.369\n",
      "(50000, 150) (50000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 390\n",
      "Train epoch 0, average loss 0.717882, average accuracy 0.659075,\n",
      "\t\t aut Dev epoch 0, average loss 0.195,average accuracy 0.929,auc 0.942,f1_pos 0.959,f1_neg 0.727,f1_avg 0.843\n",
      "\t\t\t\t    Time taken for 0 epochs =  28.00824236869812\n",
      "Train epoch 2, average loss 0.417754, average accuracy 0.804107,\n",
      "\t\t aut Dev epoch 2, average loss 0.177,average accuracy 0.935,auc 0.951,f1_pos 0.963,f1_neg 0.756,f1_avg 0.859\n",
      "Train epoch 4, average loss 0.317467, average accuracy 0.864243,\n",
      "\t\t aut Dev epoch 4, average loss 0.179,average accuracy 0.935,auc 0.956,f1_pos 0.962,f1_neg 0.770,f1_avg 0.866\n",
      "\t\t\t\t    Time taken for 4 epochs =  115.70717930793762\n",
      "Train epoch 6, average loss 0.247384, average accuracy 0.899079,\n",
      "\t\t aut Dev epoch 6, average loss 0.188,average accuracy 0.937,auc 0.953,f1_pos 0.964,f1_neg 0.760,f1_avg 0.862\n",
      "Train epoch 8, average loss 0.194824, average accuracy 0.9253,\n",
      "\t\t aut Dev epoch 8, average loss 0.202,average accuracy 0.936,auc 0.953,f1_pos 0.963,f1_neg 0.752,f1_avg 0.858\n",
      "\t\t\t\t    Time taken for 8 epochs =  203.43974375724792\n",
      "Train epoch 10, average loss 0.157877, average accuracy 0.944671,\n",
      "\t\t aut Dev epoch 10, average loss 0.201,average accuracy 0.934,auc 0.955,f1_pos 0.961,f1_neg 0.768,f1_avg 0.865\n",
      "Train epoch 12, average loss 0.129486, average accuracy 0.956771,\n",
      "\t\t aut Dev epoch 12, average loss 0.211,average accuracy 0.936,auc 0.955,f1_pos 0.963,f1_neg 0.769,f1_avg 0.866\n",
      "\t\t\t\t    Time taken for 12 epochs =  291.22413063049316\n",
      "Train epoch 14, average loss 0.110041, average accuracy 0.965084,\n",
      "\t\t aut Dev epoch 14, average loss 0.228,average accuracy 0.929,auc 0.956,f1_pos 0.958,f1_neg 0.766,f1_avg 0.862\n",
      "Training on target sample of size: 100000 with average certainty 0.590\n",
      "(100000, 150) (100000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.59169, average accuracy 0.732624,\n",
      "\t\t aut Dev epoch 0, average loss 0.181,average accuracy 0.933,auc 0.953,f1_pos 0.961,f1_neg 0.746,f1_avg 0.853\n",
      "\t\t\t\t    Time taken for 0 epochs =  43.89976215362549\n",
      "Train epoch 2, average loss 0.382419, average accuracy 0.829846,\n",
      "\t\t aut Dev epoch 2, average loss 0.165,average accuracy 0.938,auc 0.960,f1_pos 0.964,f1_neg 0.770,f1_avg 0.867\n",
      "Train epoch 4, average loss 0.302923, average accuracy 0.870939,\n",
      "\t\t aut Dev epoch 4, average loss 0.168,average accuracy 0.939,auc 0.959,f1_pos 0.965,f1_neg 0.771,f1_avg 0.868\n",
      "\t\t\t\t    Time taken for 4 epochs =  195.1795060634613\n",
      "Train epoch 6, average loss 0.246305, average accuracy 0.898217,\n",
      "\t\t aut Dev epoch 6, average loss 0.173,average accuracy 0.938,auc 0.961,f1_pos 0.964,f1_neg 0.782,f1_avg 0.873\n",
      "Train epoch 8, average loss 0.20485, average accuracy 0.917874,\n",
      "\t\t aut Dev epoch 8, average loss 0.188,average accuracy 0.939,auc 0.959,f1_pos 0.965,f1_neg 0.769,f1_avg 0.867\n",
      "\t\t\t\t    Time taken for 8 epochs =  346.3112225532532\n",
      "Train epoch 10, average loss 0.171549, average accuracy 0.932458,\n",
      "\t\t aut Dev epoch 10, average loss 0.195,average accuracy 0.939,auc 0.959,f1_pos 0.964,f1_neg 0.778,f1_avg 0.871\n",
      "Train epoch 12, average loss 0.145031, average accuracy 0.944612,\n",
      "\t\t aut Dev epoch 12, average loss 0.207,average accuracy 0.939,auc 0.957,f1_pos 0.965,f1_neg 0.773,f1_avg 0.869\n",
      "\t\t\t\t    Time taken for 12 epochs =  497.5442087650299\n",
      "Train epoch 14, average loss 0.127391, average accuracy 0.952305,\n",
      "\t\t aut Dev epoch 14, average loss 0.214,average accuracy 0.938,auc 0.957,f1_pos 0.964,f1_neg 0.778,f1_avg 0.871\n",
      "Training on target sample of size: 150000 with average certainty 0.708\n",
      "(150000, 150) (150000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1171\n",
      "Train epoch 0, average loss 0.491642, average accuracy 0.790997,\n",
      "\t\t aut Dev epoch 0, average loss 0.171,average accuracy 0.935,auc 0.956,f1_pos 0.963,f1_neg 0.757,f1_avg 0.860\n",
      "\t\t\t\t    Time taken for 0 epochs =  59.58021569252014\n",
      "Train epoch 2, average loss 0.320979, average accuracy 0.863271,\n",
      "\t\t aut Dev epoch 2, average loss 0.162,average accuracy 0.939,auc 0.961,f1_pos 0.965,f1_neg 0.769,f1_avg 0.867\n",
      "Train epoch 4, average loss 0.257681, average accuracy 0.892973,\n",
      "\t\t aut Dev epoch 4, average loss 0.167,average accuracy 0.938,auc 0.965,f1_pos 0.964,f1_neg 0.787,f1_avg 0.876\n",
      "\t\t\t\t    Time taken for 4 epochs =  273.72418308258057\n",
      "Train epoch 6, average loss 0.212991, average accuracy 0.913295,\n",
      "\t\t aut Dev epoch 6, average loss 0.171,average accuracy 0.941,auc 0.963,f1_pos 0.966,f1_neg 0.783,f1_avg 0.874\n",
      "Train epoch 8, average loss 0.178633, average accuracy 0.928447,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t aut Dev epoch 8, average loss 0.178,average accuracy 0.941,auc 0.963,f1_pos 0.965,f1_neg 0.787,f1_avg 0.876\n",
      "\t\t\t\t    Time taken for 8 epochs =  488.0562789440155\n",
      "Train epoch 10, average loss 0.154182, average accuracy 0.939448,\n",
      "\t\t aut Dev epoch 10, average loss 0.195,average accuracy 0.941,auc 0.961,f1_pos 0.966,f1_neg 0.777,f1_avg 0.872\n",
      "Train epoch 12, average loss 0.132595, average accuracy 0.949369,\n",
      "\t\t aut Dev epoch 12, average loss 0.196,average accuracy 0.940,auc 0.963,f1_pos 0.965,f1_neg 0.787,f1_avg 0.876\n",
      "\t\t\t\t    Time taken for 12 epochs =  702.3493137359619\n",
      "Train epoch 14, average loss 0.117266, average accuracy 0.954813,\n",
      "\t\t aut Dev epoch 14, average loss 0.212,average accuracy 0.935,auc 0.962,f1_pos 0.962,f1_neg 0.784,f1_avg 0.873\n",
      "Training on target sample of size: 200000 with average certainty 0.777\n",
      "(200000, 150) (200000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1562\n",
      "Train epoch 0, average loss 0.415149, average accuracy 0.830426,\n",
      "\t\t aut Dev epoch 0, average loss 0.167,average accuracy 0.935,auc 0.959,f1_pos 0.963,f1_neg 0.749,f1_avg 0.856\n",
      "\t\t\t\t    Time taken for 0 epochs =  75.49021577835083\n",
      "Train epoch 2, average loss 0.271498, average accuracy 0.887174,\n",
      "\t\t aut Dev epoch 2, average loss 0.157,average accuracy 0.941,auc 0.964,f1_pos 0.966,f1_neg 0.781,f1_avg 0.873\n",
      "Train epoch 4, average loss 0.221881, average accuracy 0.910151,\n",
      "\t\t aut Dev epoch 4, average loss 0.161,average accuracy 0.941,auc 0.966,f1_pos 0.965,f1_neg 0.790,f1_avg 0.878\n",
      "\t\t\t\t    Time taken for 4 epochs =  353.0032961368561\n",
      "Train epoch 6, average loss 0.184369, average accuracy 0.926511,\n",
      "\t\t aut Dev epoch 6, average loss 0.178,average accuracy 0.941,auc 0.962,f1_pos 0.966,f1_neg 0.773,f1_avg 0.870\n",
      "Train epoch 8, average loss 0.157499, average accuracy 0.93806,\n",
      "\t\t aut Dev epoch 8, average loss 0.177,average accuracy 0.940,auc 0.964,f1_pos 0.965,f1_neg 0.788,f1_avg 0.877\n",
      "\t\t\t\t    Time taken for 8 epochs =  630.4667348861694\n",
      "Train epoch 10, average loss 0.134326, average accuracy 0.947663,\n",
      "\t\t aut Dev epoch 10, average loss 0.185,average accuracy 0.941,auc 0.963,f1_pos 0.966,f1_neg 0.786,f1_avg 0.876\n",
      "Train epoch 12, average loss 0.11727, average accuracy 0.955086,\n",
      "\t\t aut Dev epoch 12, average loss 0.196,average accuracy 0.940,auc 0.962,f1_pos 0.965,f1_neg 0.784,f1_avg 0.875\n",
      "\t\t\t\t    Time taken for 12 epochs =  908.0996277332306\n",
      "Train epoch 14, average loss 0.104924, average accuracy 0.959857,\n",
      "\t\t aut Dev epoch 14, average loss 0.204,average accuracy 0.940,auc 0.962,f1_pos 0.965,f1_neg 0.785,f1_avg 0.875\n",
      "Training on target sample of size: 300000 with average certainty 0.850\n",
      "(300000, 150) (300000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 2343\n",
      "Train epoch 0, average loss 0.311401, average accuracy 0.880075,\n",
      "\t\t aut Dev epoch 0, average loss 0.164,average accuracy 0.936,auc 0.961,f1_pos 0.963,f1_neg 0.768,f1_avg 0.866\n",
      "\t\t\t\t    Time taken for 0 epochs =  107.00715160369873\n",
      "Train epoch 2, average loss 0.206689, average accuracy 0.918194,\n",
      "\t\t aut Dev epoch 2, average loss 0.157,average accuracy 0.940,auc 0.966,f1_pos 0.966,f1_neg 0.773,f1_avg 0.870\n",
      "Train epoch 4, average loss 0.170079, average accuracy 0.933149,\n",
      "\t\t aut Dev epoch 4, average loss 0.158,average accuracy 0.942,auc 0.967,f1_pos 0.966,f1_neg 0.785,f1_avg 0.876\n",
      "\t\t\t\t    Time taken for 4 epochs =  510.4763021469116\n",
      "Train epoch 6, average loss 0.14307, average accuracy 0.944009,\n",
      "\t\t aut Dev epoch 6, average loss 0.165,average accuracy 0.942,auc 0.965,f1_pos 0.967,f1_neg 0.785,f1_avg 0.876\n",
      "Train epoch 8, average loss 0.122227, average accuracy 0.952365,\n",
      "\t\t aut Dev epoch 8, average loss 0.172,average accuracy 0.942,auc 0.964,f1_pos 0.967,f1_neg 0.789,f1_avg 0.878\n",
      "\t\t\t\t    Time taken for 8 epochs =  913.8869421482086\n",
      "Train epoch 10, average loss 0.106717, average accuracy 0.959174,\n",
      "\t\t aut Dev epoch 10, average loss 0.185,average accuracy 0.942,auc 0.962,f1_pos 0.967,f1_neg 0.784,f1_avg 0.875\n",
      "Train epoch 12, average loss 0.0932491, average accuracy 0.964715,\n",
      "\t\t aut Dev epoch 12, average loss 0.190,average accuracy 0.941,auc 0.963,f1_pos 0.966,f1_neg 0.786,f1_avg 0.876\n",
      "\t\t\t\t    Time taken for 12 epochs =  1317.673211812973\n",
      "Train epoch 14, average loss 0.0843752, average accuracy 0.968133,\n",
      "\t\t aut Dev epoch 14, average loss 0.197,average accuracy 0.940,auc 0.964,f1_pos 0.965,f1_neg 0.790,f1_avg 0.877\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>f1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.926985</td>\n",
       "      <td>0.937573</td>\n",
       "      <td>0.719973</td>\n",
       "      <td>0.95802</td>\n",
       "      <td>0.838997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.931976</td>\n",
       "      <td>0.947614</td>\n",
       "      <td>0.750269</td>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.855447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.933223</td>\n",
       "      <td>0.950772</td>\n",
       "      <td>0.758837</td>\n",
       "      <td>0.961246</td>\n",
       "      <td>0.860042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.933183</td>\n",
       "      <td>0.951433</td>\n",
       "      <td>0.755081</td>\n",
       "      <td>0.961315</td>\n",
       "      <td>0.858198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.933243</td>\n",
       "      <td>0.949445</td>\n",
       "      <td>0.751428</td>\n",
       "      <td>0.961445</td>\n",
       "      <td>0.856436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.933083</td>\n",
       "      <td>0.948457</td>\n",
       "      <td>0.740398</td>\n",
       "      <td>0.961591</td>\n",
       "      <td>0.850995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.93281</td>\n",
       "      <td>0.951831</td>\n",
       "      <td>0.753687</td>\n",
       "      <td>0.961099</td>\n",
       "      <td>0.857393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.931996</td>\n",
       "      <td>0.951241</td>\n",
       "      <td>0.756597</td>\n",
       "      <td>0.960477</td>\n",
       "      <td>0.858537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.928934</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.727208</td>\n",
       "      <td>0.959145</td>\n",
       "      <td>0.843176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.935072</td>\n",
       "      <td>0.951474</td>\n",
       "      <td>0.755882</td>\n",
       "      <td>0.962556</td>\n",
       "      <td>0.859219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.934645</td>\n",
       "      <td>0.955604</td>\n",
       "      <td>0.769766</td>\n",
       "      <td>0.961917</td>\n",
       "      <td>0.865841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.936786</td>\n",
       "      <td>0.952617</td>\n",
       "      <td>0.760084</td>\n",
       "      <td>0.963597</td>\n",
       "      <td>0.861841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.935552</td>\n",
       "      <td>0.952692</td>\n",
       "      <td>0.752435</td>\n",
       "      <td>0.962954</td>\n",
       "      <td>0.857694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.933924</td>\n",
       "      <td>0.954706</td>\n",
       "      <td>0.768111</td>\n",
       "      <td>0.961473</td>\n",
       "      <td>0.864792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.936106</td>\n",
       "      <td>0.955029</td>\n",
       "      <td>0.7688</td>\n",
       "      <td>0.962931</td>\n",
       "      <td>0.865865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.92912</td>\n",
       "      <td>0.955944</td>\n",
       "      <td>0.765568</td>\n",
       "      <td>0.958249</td>\n",
       "      <td>0.861908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.932603</td>\n",
       "      <td>0.952803</td>\n",
       "      <td>0.745695</td>\n",
       "      <td>0.961154</td>\n",
       "      <td>0.853425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.938087</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>0.769693</td>\n",
       "      <td>0.964236</td>\n",
       "      <td>0.866965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.938788</td>\n",
       "      <td>0.959263</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.964681</td>\n",
       "      <td>0.867661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.938447</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.782354</td>\n",
       "      <td>0.964155</td>\n",
       "      <td>0.873255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.938581</td>\n",
       "      <td>0.958994</td>\n",
       "      <td>0.768937</td>\n",
       "      <td>0.964583</td>\n",
       "      <td>0.86676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.938734</td>\n",
       "      <td>0.958595</td>\n",
       "      <td>0.778354</td>\n",
       "      <td>0.964455</td>\n",
       "      <td>0.871404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.938968</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.772675</td>\n",
       "      <td>0.964752</td>\n",
       "      <td>0.868714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.938434</td>\n",
       "      <td>0.957482</td>\n",
       "      <td>0.778173</td>\n",
       "      <td>0.964257</td>\n",
       "      <td>0.871215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935438</td>\n",
       "      <td>0.955957</td>\n",
       "      <td>0.757036</td>\n",
       "      <td>0.962773</td>\n",
       "      <td>0.859905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.939155</td>\n",
       "      <td>0.961483</td>\n",
       "      <td>0.768575</td>\n",
       "      <td>0.964973</td>\n",
       "      <td>0.866774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.93814</td>\n",
       "      <td>0.964828</td>\n",
       "      <td>0.787456</td>\n",
       "      <td>0.963803</td>\n",
       "      <td>0.87563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.940822</td>\n",
       "      <td>0.963433</td>\n",
       "      <td>0.782939</td>\n",
       "      <td>0.965741</td>\n",
       "      <td>0.87434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.940522</td>\n",
       "      <td>0.962892</td>\n",
       "      <td>0.787338</td>\n",
       "      <td>0.965426</td>\n",
       "      <td>0.876382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.940782</td>\n",
       "      <td>0.961405</td>\n",
       "      <td>0.777209</td>\n",
       "      <td>0.965853</td>\n",
       "      <td>0.871531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.940042</td>\n",
       "      <td>0.962616</td>\n",
       "      <td>0.787365</td>\n",
       "      <td>0.965101</td>\n",
       "      <td>0.876233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935145</td>\n",
       "      <td>0.962309</td>\n",
       "      <td>0.783762</td>\n",
       "      <td>0.961852</td>\n",
       "      <td>0.872807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.934978</td>\n",
       "      <td>0.959398</td>\n",
       "      <td>0.748646</td>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.855653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.941069</td>\n",
       "      <td>0.964271</td>\n",
       "      <td>0.780672</td>\n",
       "      <td>0.965962</td>\n",
       "      <td>0.873317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.940636</td>\n",
       "      <td>0.965876</td>\n",
       "      <td>0.789943</td>\n",
       "      <td>0.965433</td>\n",
       "      <td>0.877688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.940636</td>\n",
       "      <td>0.961649</td>\n",
       "      <td>0.773288</td>\n",
       "      <td>0.965846</td>\n",
       "      <td>0.869567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.940202</td>\n",
       "      <td>0.964262</td>\n",
       "      <td>0.788414</td>\n",
       "      <td>0.965181</td>\n",
       "      <td>0.876797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.940616</td>\n",
       "      <td>0.96268</td>\n",
       "      <td>0.785761</td>\n",
       "      <td>0.965531</td>\n",
       "      <td>0.875646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.939815</td>\n",
       "      <td>0.96249</td>\n",
       "      <td>0.78447</td>\n",
       "      <td>0.965024</td>\n",
       "      <td>0.874747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.939508</td>\n",
       "      <td>0.962286</td>\n",
       "      <td>0.784709</td>\n",
       "      <td>0.96481</td>\n",
       "      <td>0.874759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.936192</td>\n",
       "      <td>0.961328</td>\n",
       "      <td>0.768213</td>\n",
       "      <td>0.963004</td>\n",
       "      <td>0.865608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.965534</td>\n",
       "      <td>0.773356</td>\n",
       "      <td>0.96565</td>\n",
       "      <td>0.869503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.941716</td>\n",
       "      <td>0.966559</td>\n",
       "      <td>0.784955</td>\n",
       "      <td>0.96629</td>\n",
       "      <td>0.875622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.94211</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.785377</td>\n",
       "      <td>0.966543</td>\n",
       "      <td>0.87596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.94241</td>\n",
       "      <td>0.963788</td>\n",
       "      <td>0.788794</td>\n",
       "      <td>0.96666</td>\n",
       "      <td>0.877727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.942177</td>\n",
       "      <td>0.962366</td>\n",
       "      <td>0.784269</td>\n",
       "      <td>0.966614</td>\n",
       "      <td>0.875441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.941203</td>\n",
       "      <td>0.962724</td>\n",
       "      <td>0.785744</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.875835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.939862</td>\n",
       "      <td>0.963564</td>\n",
       "      <td>0.789609</td>\n",
       "      <td>0.964917</td>\n",
       "      <td>0.877263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size       acc       auc    f1_neg    f1_pos    f1_avg\n",
       "0    20000  0.926985  0.937573  0.719973   0.95802  0.838997\n",
       "2    20000  0.931976  0.947614  0.750269  0.960625  0.855447\n",
       "4    20000  0.933223  0.950772  0.758837  0.961246  0.860042\n",
       "6    20000  0.933183  0.951433  0.755081  0.961315  0.858198\n",
       "8    20000  0.933243  0.949445  0.751428  0.961445  0.856436\n",
       "10   20000  0.933083  0.948457  0.740398  0.961591  0.850995\n",
       "12   20000   0.93281  0.951831  0.753687  0.961099  0.857393\n",
       "14   20000  0.931996  0.951241  0.756597  0.960477  0.858537\n",
       "0    50000  0.928934  0.942116  0.727208  0.959145  0.843176\n",
       "2    50000  0.935072  0.951474  0.755882  0.962556  0.859219\n",
       "4    50000  0.934645  0.955604  0.769766  0.961917  0.865841\n",
       "6    50000  0.936786  0.952617  0.760084  0.963597  0.861841\n",
       "8    50000  0.935552  0.952692  0.752435  0.962954  0.857694\n",
       "10   50000  0.933924  0.954706  0.768111  0.961473  0.864792\n",
       "12   50000  0.936106  0.955029    0.7688  0.962931  0.865865\n",
       "14   50000   0.92912  0.955944  0.765568  0.958249  0.861908\n",
       "0   100000  0.932603  0.952803  0.745695  0.961154  0.853425\n",
       "2   100000  0.938087  0.959602  0.769693  0.964236  0.866965\n",
       "4   100000  0.938788  0.959263  0.770642  0.964681  0.867661\n",
       "6   100000  0.938447  0.960563  0.782354  0.964155  0.873255\n",
       "8   100000  0.938581  0.958994  0.768937  0.964583   0.86676\n",
       "10  100000  0.938734  0.958595  0.778354  0.964455  0.871404\n",
       "12  100000  0.938968  0.956835  0.772675  0.964752  0.868714\n",
       "14  100000  0.938434  0.957482  0.778173  0.964257  0.871215\n",
       "0   150000  0.935438  0.955957  0.757036  0.962773  0.859905\n",
       "2   150000  0.939155  0.961483  0.768575  0.964973  0.866774\n",
       "4   150000   0.93814  0.964828  0.787456  0.963803   0.87563\n",
       "6   150000  0.940822  0.963433  0.782939  0.965741   0.87434\n",
       "8   150000  0.940522  0.962892  0.787338  0.965426  0.876382\n",
       "10  150000  0.940782  0.961405  0.777209  0.965853  0.871531\n",
       "12  150000  0.940042  0.962616  0.787365  0.965101  0.876233\n",
       "14  150000  0.935145  0.962309  0.783762  0.961852  0.872807\n",
       "0   200000  0.934978  0.959398  0.748646  0.962659  0.855653\n",
       "2   200000  0.941069  0.964271  0.780672  0.965962  0.873317\n",
       "4   200000  0.940636  0.965876  0.789943  0.965433  0.877688\n",
       "6   200000  0.940636  0.961649  0.773288  0.965846  0.869567\n",
       "8   200000  0.940202  0.964262  0.788414  0.965181  0.876797\n",
       "10  200000  0.940616   0.96268  0.785761  0.965531  0.875646\n",
       "12  200000  0.939815   0.96249   0.78447  0.965024  0.874747\n",
       "14  200000  0.939508  0.962286  0.784709   0.96481  0.874759\n",
       "0   300000  0.936192  0.961328  0.768213  0.963004  0.865608\n",
       "2   300000  0.940342  0.965534  0.773356   0.96565  0.869503\n",
       "4   300000  0.941716  0.966559  0.784955   0.96629  0.875622\n",
       "6   300000   0.94211  0.965333  0.785377  0.966543   0.87596\n",
       "8   300000   0.94241  0.963788  0.788794   0.96666  0.877727\n",
       "10  300000  0.942177  0.962366  0.784269  0.966614  0.875441\n",
       "12  300000  0.941203  0.962724  0.785744  0.965926  0.875835\n",
       "14  300000  0.939862  0.963564  0.789609  0.964917  0.877263"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Active transfer learning : Continue training with adding selected samples from target domain\n",
    "#In this cell, samples where we have the least absolute difference in predicted probability of positive and negative class are added first.\n",
    "\n",
    "\n",
    "size_model = size_initial\n",
    "src_key = s_key\n",
    "tgt_key = t_key\n",
    "\n",
    "#Create a sorted version of the certainty, and correspondingly sorted target train set ids, and labels.\n",
    "sort_ids = np.argsort(u_train_target_abs)\n",
    "certainty_sorted = u_train_target_abs[sort_ids]\n",
    "#print(sort_ids)\n",
    "df_target_ids_pre = dict_transfer_train_ids[tgt_key][src_key]\n",
    "df_target_labels_pre = dict_train_y[tgt_key]\n",
    "print('Target labels pre sort',df_target_labels_pre[-20:])\n",
    "print(type(df_target_labels_pre))\n",
    "#df_target_ids_pre = df_target_ids_pre.iloc([sort_ids])\n",
    "df_target_ids = df_target_ids_pre[sort_ids]\n",
    "df_target_labels = df_target_labels_pre[sort_ids]\n",
    "print('\\n Target labels post sort',df_target_labels[-20:])\n",
    "print('\\n Certainty sorted','\\n First 20',certainty_sorted[:20],'\\n Last 20',certainty_sorted[-20:])\n",
    "results_least_certain = pd.DataFrame()\n",
    "\n",
    "\n",
    "print('\\nTraining on least certain first')\n",
    "size_list = size_list\n",
    "for size in size_list:\n",
    "    avg_certainty = np.average(certainty_sorted[:size])\n",
    "    print('Training on target sample of size:',size,'with average certainty %0.3f'%avg_certainty)\n",
    "    tgt_train_df = df_target_ids[:size]\n",
    "    tgt_train_y = df_target_labels[:size]\n",
    "    avg_certainty = np.average(certainty_sorted[:size])\n",
    "    print(tgt_train_df.shape,tgt_train_y.shape)\n",
    "    results = continue_transfer_train(src_key,size_model,tgt_key,tgt_train_df,tgt_train_y)\n",
    "    results['size'] = size\n",
    "    results_least_certain = pd.concat([results_least_certain,results])\n",
    "    \n",
    "results_least_certain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on most certain first\n",
      "Training on target sample of size: 20000 with average certainty 1.000\n",
      "(20000, 150) (20000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 156\n",
      "Train epoch 0, average loss 0.0172226, average accuracy 0.998998,\n",
      "\t\t aut Dev epoch 0, average loss 0.820,average accuracy 0.761,auc 0.938,f1_pos 0.839,f1_neg 0.536,f1_avg 0.687\n",
      "\t\t\t\t    Time taken for 0 epochs =  18.788691997528076\n",
      "Train epoch 2, average loss 0.00348746, average accuracy 0.999199,\n",
      "\t\t aut Dev epoch 2, average loss 0.439,average accuracy 0.844,auc 0.944,f1_pos 0.902,f1_neg 0.628,f1_avg 0.765\n",
      "Train epoch 4, average loss 0.000485411, average accuracy 0.99985,\n",
      "\t\t aut Dev epoch 4, average loss 0.348,average accuracy 0.872,auc 0.943,f1_pos 0.921,f1_neg 0.663,f1_avg 0.792\n",
      "\t\t\t\t    Time taken for 4 epochs =  68.37358212471008\n",
      "Train epoch 6, average loss 0.000231606, average accuracy 0.99995,\n",
      "\t\t aut Dev epoch 6, average loss 0.271,average accuracy 0.899,auc 0.942,f1_pos 0.939,f1_neg 0.702,f1_avg 0.821\n",
      "Train epoch 8, average loss 6.21613e-05, average accuracy 1,\n",
      "\t\t aut Dev epoch 8, average loss 0.233,average accuracy 0.915,auc 0.941,f1_pos 0.950,f1_neg 0.722,f1_avg 0.836\n",
      "\t\t\t\t    Time taken for 8 epochs =  117.95770907402039\n",
      "Train epoch 10, average loss 4.75878e-05, average accuracy 1,\n",
      "\t\t aut Dev epoch 10, average loss 0.251,average accuracy 0.907,auc 0.942,f1_pos 0.945,f1_neg 0.712,f1_avg 0.828\n",
      "Train epoch 12, average loss 3.03094e-05, average accuracy 1,\n",
      "\t\t aut Dev epoch 12, average loss 0.235,average accuracy 0.914,auc 0.941,f1_pos 0.949,f1_neg 0.722,f1_avg 0.836\n",
      "\t\t\t\t    Time taken for 12 epochs =  167.60118174552917\n",
      "Train epoch 14, average loss 3.65176e-05, average accuracy 1,\n",
      "\t\t aut Dev epoch 14, average loss 0.240,average accuracy 0.912,auc 0.942,f1_pos 0.948,f1_neg 0.719,f1_avg 0.833\n",
      "Training on target sample of size: 50000 with average certainty 1.000\n",
      "(50000, 150) (50000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 390\n",
      "Train epoch 0, average loss 0.0201585, average accuracy 0.998277,\n",
      "\t\t aut Dev epoch 0, average loss 0.364,average accuracy 0.869,auc 0.943,f1_pos 0.919,f1_neg 0.659,f1_avg 0.789\n",
      "\t\t\t\t    Time taken for 0 epochs =  28.032621145248413\n",
      "Train epoch 2, average loss 0.00335708, average accuracy 0.999239,\n",
      "\t\t aut Dev epoch 2, average loss 0.232,average accuracy 0.913,auc 0.935,f1_pos 0.949,f1_neg 0.707,f1_avg 0.828\n",
      "Train epoch 4, average loss 0.0010833, average accuracy 0.99974,\n",
      "\t\t aut Dev epoch 4, average loss 0.258,average accuracy 0.902,auc 0.936,f1_pos 0.941,f1_neg 0.697,f1_avg 0.819\n",
      "\t\t\t\t    Time taken for 4 epochs =  115.50200533866882\n",
      "Train epoch 6, average loss 0.000748729, average accuracy 0.99984,\n",
      "\t\t aut Dev epoch 6, average loss 0.229,average accuracy 0.915,auc 0.937,f1_pos 0.950,f1_neg 0.712,f1_avg 0.831\n",
      "Train epoch 8, average loss 0.000391808, average accuracy 0.99992,\n",
      "\t\t aut Dev epoch 8, average loss 0.221,average accuracy 0.921,auc 0.936,f1_pos 0.955,f1_neg 0.711,f1_avg 0.833\n",
      "\t\t\t\t    Time taken for 8 epochs =  203.0519998073578\n",
      "Train epoch 10, average loss 0.000279292, average accuracy 0.99996,\n",
      "\t\t aut Dev epoch 10, average loss 0.220,average accuracy 0.921,auc 0.938,f1_pos 0.954,f1_neg 0.714,f1_avg 0.834\n",
      "Train epoch 12, average loss 0.000272748, average accuracy 0.99992,\n",
      "\t\t aut Dev epoch 12, average loss 0.229,average accuracy 0.916,auc 0.941,f1_pos 0.950,f1_neg 0.719,f1_avg 0.835\n",
      "\t\t\t\t    Time taken for 12 epochs =  290.53723764419556\n",
      "Train epoch 14, average loss 0.000155835, average accuracy 0.99998,\n",
      "\t\t aut Dev epoch 14, average loss 0.220,average accuracy 0.923,auc 0.939,f1_pos 0.956,f1_neg 0.715,f1_avg 0.835\n",
      "Training on target sample of size: 100000 with average certainty 1.000\n",
      "(100000, 150) (100000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.0228525, average accuracy 0.997699,\n",
      "\t\t aut Dev epoch 0, average loss 0.226,average accuracy 0.917,auc 0.934,f1_pos 0.952,f1_neg 0.686,f1_avg 0.819\n",
      "\t\t\t\t    Time taken for 0 epochs =  43.76810574531555\n",
      "Train epoch 2, average loss 0.00495139, average accuracy 0.99882,\n",
      "\t\t aut Dev epoch 2, average loss 0.231,average accuracy 0.919,auc 0.934,f1_pos 0.954,f1_neg 0.668,f1_avg 0.811\n",
      "Train epoch 4, average loss 0.00217616, average accuracy 0.99945,\n",
      "\t\t aut Dev epoch 4, average loss 0.237,average accuracy 0.910,auc 0.940,f1_pos 0.947,f1_neg 0.710,f1_avg 0.828\n",
      "\t\t\t\t    Time taken for 4 epochs =  194.37090492248535\n",
      "Train epoch 6, average loss 0.00148665, average accuracy 0.99958,\n",
      "\t\t aut Dev epoch 6, average loss 0.229,average accuracy 0.915,auc 0.941,f1_pos 0.950,f1_neg 0.717,f1_avg 0.834\n",
      "Train epoch 8, average loss 0.000853468, average accuracy 0.99982,\n",
      "\t\t aut Dev epoch 8, average loss 0.223,average accuracy 0.925,auc 0.938,f1_pos 0.957,f1_neg 0.709,f1_avg 0.833\n",
      "\t\t\t\t    Time taken for 8 epochs =  344.949835062027\n",
      "Train epoch 10, average loss 0.000659343, average accuracy 0.99985,\n",
      "\t\t aut Dev epoch 10, average loss 0.219,average accuracy 0.924,auc 0.941,f1_pos 0.956,f1_neg 0.720,f1_avg 0.838\n",
      "Train epoch 12, average loss 0.000566516, average accuracy 0.99986,\n",
      "\t\t aut Dev epoch 12, average loss 0.219,average accuracy 0.923,auc 0.942,f1_pos 0.955,f1_neg 0.723,f1_avg 0.839\n",
      "\t\t\t\t    Time taken for 12 epochs =  495.61558961868286\n",
      "Train epoch 14, average loss 0.000457592, average accuracy 0.99993,\n",
      "\t\t aut Dev epoch 14, average loss 0.222,average accuracy 0.922,auc 0.944,f1_pos 0.954,f1_neg 0.726,f1_avg 0.840\n",
      "Training on target sample of size: 150000 with average certainty 1.000\n",
      "(150000, 150) (150000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1171\n",
      "Train epoch 0, average loss 0.0298301, average accuracy 0.996424,\n",
      "\t\t aut Dev epoch 0, average loss 0.248,average accuracy 0.916,auc 0.932,f1_pos 0.953,f1_neg 0.627,f1_avg 0.790\n",
      "\t\t\t\t    Time taken for 0 epochs =  59.487099170684814\n",
      "Train epoch 2, average loss 0.00852008, average accuracy 0.997985,\n",
      "\t\t aut Dev epoch 2, average loss 0.230,average accuracy 0.912,auc 0.941,f1_pos 0.948,f1_neg 0.711,f1_avg 0.829\n",
      "Train epoch 4, average loss 0.00417241, average accuracy 0.998939,\n",
      "\t\t aut Dev epoch 4, average loss 0.212,average accuracy 0.922,auc 0.943,f1_pos 0.954,f1_neg 0.720,f1_avg 0.837\n",
      "\t\t\t\t    Time taken for 4 epochs =  273.1118896007538\n",
      "Train epoch 6, average loss 0.0024431, average accuracy 0.9994,\n",
      "\t\t aut Dev epoch 6, average loss 0.228,average accuracy 0.925,auc 0.940,f1_pos 0.957,f1_neg 0.696,f1_avg 0.827\n",
      "Train epoch 8, average loss 0.00159878, average accuracy 0.99964,\n",
      "\t\t aut Dev epoch 8, average loss 0.216,average accuracy 0.924,auc 0.943,f1_pos 0.956,f1_neg 0.724,f1_avg 0.840\n",
      "\t\t\t\t    Time taken for 8 epochs =  486.7107710838318\n",
      "Train epoch 10, average loss 0.00130834, average accuracy 0.999713,\n",
      "\t\t aut Dev epoch 10, average loss 0.220,average accuracy 0.925,auc 0.943,f1_pos 0.957,f1_neg 0.720,f1_avg 0.838\n",
      "Train epoch 12, average loss 0.00104245, average accuracy 0.999793,\n",
      "\t\t aut Dev epoch 12, average loss 0.221,average accuracy 0.926,auc 0.944,f1_pos 0.957,f1_neg 0.724,f1_avg 0.841\n",
      "\t\t\t\t    Time taken for 12 epochs =  700.2278609275818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 14, average loss 0.000783066, average accuracy 0.999853,\n",
      "\t\t aut Dev epoch 14, average loss 0.222,average accuracy 0.926,auc 0.944,f1_pos 0.957,f1_neg 0.727,f1_avg 0.842\n",
      "Training on target sample of size: 200000 with average certainty 1.000\n",
      "(200000, 150) (200000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1562\n",
      "Train epoch 0, average loss 0.0385199, average accuracy 0.994578,\n",
      "\t\t aut Dev epoch 0, average loss 0.206,average accuracy 0.921,auc 0.943,f1_pos 0.954,f1_neg 0.704,f1_avg 0.829\n",
      "\t\t\t\t    Time taken for 0 epochs =  75.30522727966309\n",
      "Train epoch 2, average loss 0.0131158, average accuracy 0.996814,\n",
      "\t\t aut Dev epoch 2, average loss 0.207,average accuracy 0.922,auc 0.945,f1_pos 0.955,f1_neg 0.703,f1_avg 0.829\n",
      "Train epoch 4, average loss 0.00714225, average accuracy 0.998174,\n",
      "\t\t aut Dev epoch 4, average loss 0.205,average accuracy 0.925,auc 0.946,f1_pos 0.956,f1_neg 0.730,f1_avg 0.843\n",
      "\t\t\t\t    Time taken for 4 epochs =  351.86354207992554\n",
      "Train epoch 6, average loss 0.00456917, average accuracy 0.998845,\n",
      "\t\t aut Dev epoch 6, average loss 0.218,average accuracy 0.927,auc 0.945,f1_pos 0.958,f1_neg 0.710,f1_avg 0.834\n",
      "Train epoch 8, average loss 0.00312426, average accuracy 0.999285,\n",
      "\t\t aut Dev epoch 8, average loss 0.220,average accuracy 0.927,auc 0.945,f1_pos 0.958,f1_neg 0.714,f1_avg 0.836\n",
      "\t\t\t\t    Time taken for 8 epochs =  628.4560222625732\n",
      "Train epoch 10, average loss 0.00222801, average accuracy 0.999495,\n",
      "\t\t aut Dev epoch 10, average loss 0.216,average accuracy 0.926,auc 0.948,f1_pos 0.957,f1_neg 0.732,f1_avg 0.844\n",
      "Train epoch 12, average loss 0.00185026, average accuracy 0.99958,\n",
      "\t\t aut Dev epoch 12, average loss 0.223,average accuracy 0.928,auc 0.947,f1_pos 0.958,f1_neg 0.726,f1_avg 0.842\n",
      "\t\t\t\t    Time taken for 12 epochs =  905.2368876934052\n",
      "Train epoch 14, average loss 0.00155432, average accuracy 0.99965,\n",
      "\t\t aut Dev epoch 14, average loss 0.228,average accuracy 0.928,auc 0.944,f1_pos 0.959,f1_neg 0.725,f1_avg 0.842\n",
      "Training on target sample of size: 300000 with average certainty 0.999\n",
      "(300000, 150) (300000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 2343\n",
      "Train epoch 0, average loss 0.0649023, average accuracy 0.987643,\n",
      "\t\t aut Dev epoch 0, average loss 0.195,average accuracy 0.926,auc 0.950,f1_pos 0.958,f1_neg 0.705,f1_avg 0.831\n",
      "\t\t\t\t    Time taken for 0 epochs =  106.8288357257843\n",
      "Train epoch 2, average loss 0.0301675, average accuracy 0.991927,\n",
      "\t\t aut Dev epoch 2, average loss 0.198,average accuracy 0.924,auc 0.952,f1_pos 0.955,f1_neg 0.744,f1_avg 0.850\n",
      "Train epoch 4, average loss 0.0191807, average accuracy 0.994605,\n",
      "\t\t aut Dev epoch 4, average loss 0.194,average accuracy 0.931,auc 0.952,f1_pos 0.960,f1_neg 0.740,f1_avg 0.850\n",
      "\t\t\t\t    Time taken for 4 epochs =  509.8251438140869\n",
      "Train epoch 6, average loss 0.0127813, average accuracy 0.996325,\n",
      "\t\t aut Dev epoch 6, average loss 0.201,average accuracy 0.928,auc 0.952,f1_pos 0.958,f1_neg 0.748,f1_avg 0.853\n",
      "Train epoch 8, average loss 0.00932498, average accuracy 0.997366,\n",
      "\t\t aut Dev epoch 8, average loss 0.209,average accuracy 0.930,auc 0.952,f1_pos 0.960,f1_neg 0.743,f1_avg 0.851\n",
      "\t\t\t\t    Time taken for 8 epochs =  912.963091135025\n",
      "Train epoch 10, average loss 0.00740063, average accuracy 0.997959,\n",
      "\t\t aut Dev epoch 10, average loss 0.213,average accuracy 0.930,auc 0.952,f1_pos 0.959,f1_neg 0.751,f1_avg 0.855\n",
      "Train epoch 12, average loss 0.00561995, average accuracy 0.99856,\n",
      "\t\t aut Dev epoch 12, average loss 0.218,average accuracy 0.931,auc 0.952,f1_pos 0.960,f1_neg 0.749,f1_avg 0.854\n",
      "\t\t\t\t    Time taken for 12 epochs =  1316.4035918712616\n",
      "Train epoch 14, average loss 0.00452015, average accuracy 0.998793,\n",
      "\t\t aut Dev epoch 14, average loss 0.226,average accuracy 0.931,auc 0.952,f1_pos 0.960,f1_neg 0.748,f1_avg 0.854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>f1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.760661</td>\n",
       "      <td>0.938208</td>\n",
       "      <td>0.535732</td>\n",
       "      <td>0.838773</td>\n",
       "      <td>0.687252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.844491</td>\n",
       "      <td>0.943555</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>0.901707</td>\n",
       "      <td>0.76479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.871958</td>\n",
       "      <td>0.942971</td>\n",
       "      <td>0.663475</td>\n",
       "      <td>0.920938</td>\n",
       "      <td>0.792207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.899365</td>\n",
       "      <td>0.942397</td>\n",
       "      <td>0.701614</td>\n",
       "      <td>0.939476</td>\n",
       "      <td>0.820545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.915357</td>\n",
       "      <td>0.940976</td>\n",
       "      <td>0.721978</td>\n",
       "      <td>0.950079</td>\n",
       "      <td>0.836028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.907257</td>\n",
       "      <td>0.941884</td>\n",
       "      <td>0.71226</td>\n",
       "      <td>0.94472</td>\n",
       "      <td>0.82849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.914496</td>\n",
       "      <td>0.94138</td>\n",
       "      <td>0.72167</td>\n",
       "      <td>0.94949</td>\n",
       "      <td>0.83558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.912114</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>0.719012</td>\n",
       "      <td>0.947911</td>\n",
       "      <td>0.833462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.869336</td>\n",
       "      <td>0.942574</td>\n",
       "      <td>0.659374</td>\n",
       "      <td>0.919163</td>\n",
       "      <td>0.789268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.913075</td>\n",
       "      <td>0.93477</td>\n",
       "      <td>0.70664</td>\n",
       "      <td>0.948979</td>\n",
       "      <td>0.827809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.901647</td>\n",
       "      <td>0.936201</td>\n",
       "      <td>0.696692</td>\n",
       "      <td>0.941307</td>\n",
       "      <td>0.818999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.915317</td>\n",
       "      <td>0.937081</td>\n",
       "      <td>0.712431</td>\n",
       "      <td>0.950348</td>\n",
       "      <td>0.831389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.921428</td>\n",
       "      <td>0.936223</td>\n",
       "      <td>0.711029</td>\n",
       "      <td>0.954533</td>\n",
       "      <td>0.832781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.921295</td>\n",
       "      <td>0.938123</td>\n",
       "      <td>0.714407</td>\n",
       "      <td>0.954358</td>\n",
       "      <td>0.834382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.91577</td>\n",
       "      <td>0.94051</td>\n",
       "      <td>0.7186</td>\n",
       "      <td>0.950473</td>\n",
       "      <td>0.834537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.923229</td>\n",
       "      <td>0.939112</td>\n",
       "      <td>0.715082</td>\n",
       "      <td>0.955638</td>\n",
       "      <td>0.83536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.917205</td>\n",
       "      <td>0.93363</td>\n",
       "      <td>0.686442</td>\n",
       "      <td>0.952306</td>\n",
       "      <td>0.819374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.918799</td>\n",
       "      <td>0.933881</td>\n",
       "      <td>0.667831</td>\n",
       "      <td>0.953746</td>\n",
       "      <td>0.810789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.91022</td>\n",
       "      <td>0.940074</td>\n",
       "      <td>0.70986</td>\n",
       "      <td>0.946893</td>\n",
       "      <td>0.828376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.914883</td>\n",
       "      <td>0.941041</td>\n",
       "      <td>0.717406</td>\n",
       "      <td>0.949896</td>\n",
       "      <td>0.833651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.92453</td>\n",
       "      <td>0.937952</td>\n",
       "      <td>0.708514</td>\n",
       "      <td>0.956654</td>\n",
       "      <td>0.832584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.924457</td>\n",
       "      <td>0.940996</td>\n",
       "      <td>0.71954</td>\n",
       "      <td>0.95635</td>\n",
       "      <td>0.837945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.922822</td>\n",
       "      <td>0.942074</td>\n",
       "      <td>0.723373</td>\n",
       "      <td>0.955155</td>\n",
       "      <td>0.839264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.921908</td>\n",
       "      <td>0.943535</td>\n",
       "      <td>0.726077</td>\n",
       "      <td>0.954463</td>\n",
       "      <td>0.84027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.915784</td>\n",
       "      <td>0.932378</td>\n",
       "      <td>0.627189</td>\n",
       "      <td>0.95253</td>\n",
       "      <td>0.78986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.911848</td>\n",
       "      <td>0.941368</td>\n",
       "      <td>0.710932</td>\n",
       "      <td>0.947994</td>\n",
       "      <td>0.829463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.921688</td>\n",
       "      <td>0.943189</td>\n",
       "      <td>0.719522</td>\n",
       "      <td>0.954491</td>\n",
       "      <td>0.837006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.924637</td>\n",
       "      <td>0.939944</td>\n",
       "      <td>0.696393</td>\n",
       "      <td>0.956979</td>\n",
       "      <td>0.826686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.923836</td>\n",
       "      <td>0.942683</td>\n",
       "      <td>0.72361</td>\n",
       "      <td>0.955833</td>\n",
       "      <td>0.839722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.925338</td>\n",
       "      <td>0.942978</td>\n",
       "      <td>0.719938</td>\n",
       "      <td>0.956927</td>\n",
       "      <td>0.838433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.926025</td>\n",
       "      <td>0.944078</td>\n",
       "      <td>0.723946</td>\n",
       "      <td>0.95729</td>\n",
       "      <td>0.840618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.925845</td>\n",
       "      <td>0.94414</td>\n",
       "      <td>0.726803</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>0.841952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.920527</td>\n",
       "      <td>0.943167</td>\n",
       "      <td>0.704109</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.829104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.922262</td>\n",
       "      <td>0.945346</td>\n",
       "      <td>0.70336</td>\n",
       "      <td>0.95527</td>\n",
       "      <td>0.829315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.924577</td>\n",
       "      <td>0.945915</td>\n",
       "      <td>0.730378</td>\n",
       "      <td>0.956156</td>\n",
       "      <td>0.843267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>0.944768</td>\n",
       "      <td>0.710447</td>\n",
       "      <td>0.95792</td>\n",
       "      <td>0.834184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.926885</td>\n",
       "      <td>0.945158</td>\n",
       "      <td>0.713782</td>\n",
       "      <td>0.95809</td>\n",
       "      <td>0.835936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.925998</td>\n",
       "      <td>0.947758</td>\n",
       "      <td>0.731857</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.844467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.927786</td>\n",
       "      <td>0.946563</td>\n",
       "      <td>0.72578</td>\n",
       "      <td>0.958418</td>\n",
       "      <td>0.842099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.944462</td>\n",
       "      <td>0.725412</td>\n",
       "      <td>0.958833</td>\n",
       "      <td>0.842122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.925845</td>\n",
       "      <td>0.950229</td>\n",
       "      <td>0.704804</td>\n",
       "      <td>0.957596</td>\n",
       "      <td>0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.924103</td>\n",
       "      <td>0.952377</td>\n",
       "      <td>0.744107</td>\n",
       "      <td>0.955444</td>\n",
       "      <td>0.849775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.930568</td>\n",
       "      <td>0.952193</td>\n",
       "      <td>0.739532</td>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.849739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.92814</td>\n",
       "      <td>0.952037</td>\n",
       "      <td>0.747533</td>\n",
       "      <td>0.958108</td>\n",
       "      <td>0.85282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.930275</td>\n",
       "      <td>0.951607</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>0.959674</td>\n",
       "      <td>0.851177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.929761</td>\n",
       "      <td>0.952277</td>\n",
       "      <td>0.750545</td>\n",
       "      <td>0.959126</td>\n",
       "      <td>0.854835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.930588</td>\n",
       "      <td>0.951906</td>\n",
       "      <td>0.749205</td>\n",
       "      <td>0.95972</td>\n",
       "      <td>0.854462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.930568</td>\n",
       "      <td>0.951857</td>\n",
       "      <td>0.748082</td>\n",
       "      <td>0.959735</td>\n",
       "      <td>0.853908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size       acc       auc    f1_neg    f1_pos    f1_avg\n",
       "0    20000  0.760661  0.938208  0.535732  0.838773  0.687252\n",
       "2    20000  0.844491  0.943555  0.627872  0.901707   0.76479\n",
       "4    20000  0.871958  0.942971  0.663475  0.920938  0.792207\n",
       "6    20000  0.899365  0.942397  0.701614  0.939476  0.820545\n",
       "8    20000  0.915357  0.940976  0.721978  0.950079  0.836028\n",
       "10   20000  0.907257  0.941884   0.71226   0.94472   0.82849\n",
       "12   20000  0.914496   0.94138   0.72167   0.94949   0.83558\n",
       "14   20000  0.912114  0.941799  0.719012  0.947911  0.833462\n",
       "0    50000  0.869336  0.942574  0.659374  0.919163  0.789268\n",
       "2    50000  0.913075   0.93477   0.70664  0.948979  0.827809\n",
       "4    50000  0.901647  0.936201  0.696692  0.941307  0.818999\n",
       "6    50000  0.915317  0.937081  0.712431  0.950348  0.831389\n",
       "8    50000  0.921428  0.936223  0.711029  0.954533  0.832781\n",
       "10   50000  0.921295  0.938123  0.714407  0.954358  0.834382\n",
       "12   50000   0.91577   0.94051    0.7186  0.950473  0.834537\n",
       "14   50000  0.923229  0.939112  0.715082  0.955638   0.83536\n",
       "0   100000  0.917205   0.93363  0.686442  0.952306  0.819374\n",
       "2   100000  0.918799  0.933881  0.667831  0.953746  0.810789\n",
       "4   100000   0.91022  0.940074   0.70986  0.946893  0.828376\n",
       "6   100000  0.914883  0.941041  0.717406  0.949896  0.833651\n",
       "8   100000   0.92453  0.937952  0.708514  0.956654  0.832584\n",
       "10  100000  0.924457  0.940996   0.71954   0.95635  0.837945\n",
       "12  100000  0.922822  0.942074  0.723373  0.955155  0.839264\n",
       "14  100000  0.921908  0.943535  0.726077  0.954463   0.84027\n",
       "0   150000  0.915784  0.932378  0.627189   0.95253   0.78986\n",
       "2   150000  0.911848  0.941368  0.710932  0.947994  0.829463\n",
       "4   150000  0.921688  0.943189  0.719522  0.954491  0.837006\n",
       "6   150000  0.924637  0.939944  0.696393  0.956979  0.826686\n",
       "8   150000  0.923836  0.942683   0.72361  0.955833  0.839722\n",
       "10  150000  0.925338  0.942978  0.719938  0.956927  0.838433\n",
       "12  150000  0.926025  0.944078  0.723946   0.95729  0.840618\n",
       "14  150000  0.925845   0.94414  0.726803    0.9571  0.841952\n",
       "0   200000  0.920527  0.943167  0.704109    0.9541  0.829104\n",
       "2   200000  0.922262  0.945346   0.70336   0.95527  0.829315\n",
       "4   200000  0.924577  0.945915  0.730378  0.956156  0.843267\n",
       "6   200000  0.926518  0.944768  0.710447   0.95792  0.834184\n",
       "8   200000  0.926885  0.945158  0.713782   0.95809  0.835936\n",
       "10  200000  0.925998  0.947758  0.731857  0.957076  0.844467\n",
       "12  200000  0.927786  0.946563   0.72578  0.958418  0.842099\n",
       "14  200000    0.9284  0.944462  0.725412  0.958833  0.842122\n",
       "0   300000  0.925845  0.950229  0.704804  0.957596    0.8312\n",
       "2   300000  0.924103  0.952377  0.744107  0.955444  0.849775\n",
       "4   300000  0.930568  0.952193  0.739532  0.959946  0.849739\n",
       "6   300000   0.92814  0.952037  0.747533  0.958108   0.85282\n",
       "8   300000  0.930275  0.951607  0.742681  0.959674  0.851177\n",
       "10  300000  0.929761  0.952277  0.750545  0.959126  0.854835\n",
       "12  300000  0.930588  0.951906  0.749205   0.95972  0.854462\n",
       "14  300000  0.930568  0.951857  0.748082  0.959735  0.853908"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell, samples where we have the most absolute difference in predicted probability of positive and negative class are added first.\n",
    "size_model = size_initial\n",
    "print('Training on most certain first')\n",
    "size_list = size_list\n",
    "results_most_certain = pd.DataFrame()\n",
    "for size in size_list:\n",
    "    avg_certainty = np.average(certainty_sorted[-size:])\n",
    "    print('Training on target sample of size:',size,'with average certainty %0.3f'%avg_certainty)\n",
    "    tgt_train_df = df_target_ids[-size:]\n",
    "    tgt_train_y = df_target_labels[-size:]\n",
    "    print(tgt_train_df.shape,tgt_train_y.shape)\n",
    "    results = continue_transfer_train(src_key,size_model,tgt_key,tgt_train_df,tgt_train_y)\n",
    "    results['size'] = size\n",
    "    results_most_certain = pd.concat([results_most_certain,results])\n",
    "    \n",
    "results_most_certain\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target labels pre sort [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      " Target labels post sort [1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      " Certainty sorted \n",
      " First 20 [  2.93254852e-05   3.64184380e-05   2.38120556e-05   1.46538019e-04\n",
      "   1.17838383e-04   1.61826611e-04   3.12894583e-04   4.05132771e-04\n",
      "   4.24623489e-04   5.79833984e-04   5.28812408e-04   2.94387341e-04\n",
      "   1.44541264e-04   7.98702240e-05   2.49713659e-04   1.56641006e-04\n",
      "   7.81148672e-04   8.16792250e-04   4.39465046e-04   1.23530626e-04] \n",
      " Last 20 [ 0.59301013  0.59301013  0.59301013  0.59301013  0.59301013  0.59301013\n",
      "  0.59301013  0.59301013  0.59301013  0.59301013  0.59301013  0.59301013\n",
      "  0.59301013  0.59301013  0.59301013  0.59301013  0.59301013  0.59301013\n",
      "  0.59301013  0.59301013]\n",
      "\n",
      "Training on least certain first\n",
      "Training on target sample of size: 20000 with average certainty per word id 0.387551747995 with average certainty 0.250\n",
      "(20000, 150) (20000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 156\n",
      "Train epoch 0, average loss 0.898939, average accuracy 0.624249,\n",
      "\t\t aut Dev epoch 0, average loss 0.211,average accuracy 0.922,auc 0.934,f1_pos 0.955,f1_neg 0.700,f1_avg 0.828\n",
      "\t\t\t\t    Time taken for 0 epochs =  18.952993154525757\n",
      "Train epoch 2, average loss 0.378793, average accuracy 0.825771,\n",
      "\t\t aut Dev epoch 2, average loss 0.195,average accuracy 0.928,auc 0.939,f1_pos 0.959,f1_neg 0.717,f1_avg 0.838\n",
      "Train epoch 4, average loss 0.251939, average accuracy 0.903095,\n",
      "\t\t aut Dev epoch 4, average loss 0.191,average accuracy 0.929,auc 0.945,f1_pos 0.959,f1_neg 0.739,f1_avg 0.849\n",
      "\t\t\t\t    Time taken for 4 epochs =  69.0117347240448\n",
      "Train epoch 6, average loss 0.174188, average accuracy 0.94406,\n",
      "\t\t aut Dev epoch 6, average loss 0.195,average accuracy 0.930,auc 0.945,f1_pos 0.960,f1_neg 0.729,f1_avg 0.845\n",
      "Train epoch 8, average loss 0.131378, average accuracy 0.962891,\n",
      "\t\t aut Dev epoch 8, average loss 0.202,average accuracy 0.930,auc 0.943,f1_pos 0.960,f1_neg 0.731,f1_avg 0.845\n",
      "\t\t\t\t    Time taken for 8 epochs =  119.0948896408081\n",
      "Train epoch 10, average loss 0.100341, average accuracy 0.97506,\n",
      "\t\t aut Dev epoch 10, average loss 0.203,average accuracy 0.931,auc 0.944,f1_pos 0.960,f1_neg 0.739,f1_avg 0.850\n",
      "Train epoch 12, average loss 0.0765842, average accuracy 0.984575,\n",
      "\t\t aut Dev epoch 12, average loss 0.211,average accuracy 0.930,auc 0.945,f1_pos 0.960,f1_neg 0.730,f1_avg 0.845\n",
      "\t\t\t\t    Time taken for 12 epochs =  169.18201184272766\n",
      "Train epoch 14, average loss 0.0629851, average accuracy 0.988231,\n",
      "\t\t aut Dev epoch 14, average loss 0.218,average accuracy 0.931,auc 0.943,f1_pos 0.960,f1_neg 0.735,f1_avg 0.847\n",
      "Training on target sample of size: 50000 with average certainty per word id 0.720856812326 with average certainty 0.610\n",
      "(50000, 150) (50000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 390\n",
      "Train epoch 0, average loss 0.6199, average accuracy 0.740625,\n",
      "\t\t aut Dev epoch 0, average loss 0.224,average accuracy 0.923,auc 0.935,f1_pos 0.956,f1_neg 0.706,f1_avg 0.831\n",
      "\t\t\t\t    Time taken for 0 epochs =  28.327017068862915\n",
      "Train epoch 2, average loss 0.315364, average accuracy 0.860056,\n",
      "\t\t aut Dev epoch 2, average loss 0.193,average accuracy 0.930,auc 0.944,f1_pos 0.960,f1_neg 0.738,f1_avg 0.849\n",
      "Train epoch 4, average loss 0.224216, average accuracy 0.908554,\n",
      "\t\t aut Dev epoch 4, average loss 0.187,average accuracy 0.931,auc 0.947,f1_pos 0.960,f1_neg 0.747,f1_avg 0.854\n",
      "\t\t\t\t    Time taken for 4 epochs =  117.12881422042847\n",
      "Train epoch 6, average loss 0.164743, average accuracy 0.938301,\n",
      "\t\t aut Dev epoch 6, average loss 0.197,average accuracy 0.928,auc 0.946,f1_pos 0.958,f1_neg 0.750,f1_avg 0.854\n",
      "Train epoch 8, average loss 0.125456, average accuracy 0.95619,\n",
      "\t\t aut Dev epoch 8, average loss 0.193,average accuracy 0.930,auc 0.944,f1_pos 0.960,f1_neg 0.741,f1_avg 0.850\n",
      "\t\t\t\t    Time taken for 8 epochs =  205.9057698249817\n",
      "Train epoch 10, average loss 0.0967235, average accuracy 0.969812,\n",
      "\t\t aut Dev epoch 10, average loss 0.201,average accuracy 0.930,auc 0.943,f1_pos 0.960,f1_neg 0.737,f1_avg 0.848\n",
      "Train epoch 12, average loss 0.0782035, average accuracy 0.977003,\n",
      "\t\t aut Dev epoch 12, average loss 0.204,average accuracy 0.931,auc 0.943,f1_pos 0.960,f1_neg 0.746,f1_avg 0.853\n",
      "\t\t\t\t    Time taken for 12 epochs =  294.79552125930786\n",
      "Train epoch 14, average loss 0.064434, average accuracy 0.982252,\n",
      "\t\t aut Dev epoch 14, average loss 0.214,average accuracy 0.930,auc 0.940,f1_pos 0.960,f1_neg 0.736,f1_avg 0.848\n",
      "Training on target sample of size: 100000 with average certainty per word id 0.999097881564 with average certainty 0.743\n",
      "(100000, 150) (100000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 781\n",
      "Train epoch 0, average loss 0.450847, average accuracy 0.81195,\n",
      "\t\t aut Dev epoch 0, average loss 0.197,average accuracy 0.925,auc 0.943,f1_pos 0.957,f1_neg 0.693,f1_avg 0.825\n",
      "\t\t\t\t    Time taken for 0 epochs =  44.43828892707825\n",
      "Train epoch 2, average loss 0.254894, average accuracy 0.887824,\n",
      "\t\t aut Dev epoch 2, average loss 0.182,average accuracy 0.934,auc 0.951,f1_pos 0.962,f1_neg 0.754,f1_avg 0.858\n",
      "Train epoch 4, average loss 0.189969, average accuracy 0.921495,\n",
      "\t\t aut Dev epoch 4, average loss 0.182,average accuracy 0.933,auc 0.949,f1_pos 0.961,f1_neg 0.732,f1_avg 0.847\n",
      "\t\t\t\t    Time taken for 4 epochs =  197.71836733818054\n",
      "Train epoch 6, average loss 0.147094, average accuracy 0.941971,\n",
      "\t\t aut Dev epoch 6, average loss 0.181,average accuracy 0.934,auc 0.950,f1_pos 0.962,f1_neg 0.747,f1_avg 0.854\n",
      "Train epoch 8, average loss 0.114083, average accuracy 0.957256,\n",
      "\t\t aut Dev epoch 8, average loss 0.188,average accuracy 0.932,auc 0.952,f1_pos 0.961,f1_neg 0.764,f1_avg 0.862\n",
      "\t\t\t\t    Time taken for 8 epochs =  351.11082339286804\n",
      "Train epoch 10, average loss 0.0913507, average accuracy 0.966859,\n",
      "\t\t aut Dev epoch 10, average loss 0.194,average accuracy 0.934,auc 0.949,f1_pos 0.962,f1_neg 0.754,f1_avg 0.858\n",
      "Train epoch 12, average loss 0.0761126, average accuracy 0.974222,\n",
      "\t\t aut Dev epoch 12, average loss 0.199,average accuracy 0.933,auc 0.951,f1_pos 0.961,f1_neg 0.759,f1_avg 0.860\n",
      "\t\t\t\t    Time taken for 12 epochs =  504.37131428718567\n",
      "Train epoch 14, average loss 0.0627394, average accuracy 0.979203,\n",
      "\t\t aut Dev epoch 14, average loss 0.208,average accuracy 0.931,auc 0.951,f1_pos 0.960,f1_neg 0.761,f1_avg 0.860\n",
      "Training on target sample of size: 150000 with average certainty per word id 1.29461965807 with average certainty 0.797\n",
      "(150000, 150) (150000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1171\n",
      "Train epoch 0, average loss 0.37455, average accuracy 0.844944,\n",
      "\t\t aut Dev epoch 0, average loss 0.185,average accuracy 0.932,auc 0.949,f1_pos 0.961,f1_neg 0.743,f1_avg 0.852\n",
      "\t\t\t\t    Time taken for 0 epochs =  60.29289412498474\n",
      "Train epoch 2, average loss 0.224476, average accuracy 0.904822,\n",
      "\t\t aut Dev epoch 2, average loss 0.171,average accuracy 0.936,auc 0.956,f1_pos 0.963,f1_neg 0.761,f1_avg 0.862\n",
      "Train epoch 4, average loss 0.172962, average accuracy 0.92862,\n",
      "\t\t aut Dev epoch 4, average loss 0.179,average accuracy 0.935,auc 0.952,f1_pos 0.963,f1_neg 0.742,f1_avg 0.852\n",
      "\t\t\t\t    Time taken for 4 epochs =  277.04795932769775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 6, average loss 0.137506, average accuracy 0.944579,\n",
      "\t\t aut Dev epoch 6, average loss 0.174,average accuracy 0.937,auc 0.956,f1_pos 0.963,f1_neg 0.765,f1_avg 0.864\n",
      "Train epoch 8, average loss 0.111807, average accuracy 0.956221,\n",
      "\t\t aut Dev epoch 8, average loss 0.183,average accuracy 0.936,auc 0.953,f1_pos 0.963,f1_neg 0.759,f1_avg 0.861\n",
      "\t\t\t\t    Time taken for 8 epochs =  493.8971607685089\n",
      "Train epoch 10, average loss 0.0905362, average accuracy 0.966141,\n",
      "\t\t aut Dev epoch 10, average loss 0.187,average accuracy 0.937,auc 0.956,f1_pos 0.963,f1_neg 0.774,f1_avg 0.869\n",
      "Train epoch 12, average loss 0.0761937, average accuracy 0.972066,\n",
      "\t\t aut Dev epoch 12, average loss 0.195,average accuracy 0.936,auc 0.954,f1_pos 0.963,f1_neg 0.768,f1_avg 0.865\n",
      "\t\t\t\t    Time taken for 12 epochs =  710.7086460590363\n",
      "Train epoch 14, average loss 0.0646022, average accuracy 0.976903,\n",
      "\t\t aut Dev epoch 14, average loss 0.204,average accuracy 0.936,auc 0.953,f1_pos 0.963,f1_neg 0.768,f1_avg 0.865\n",
      "Training on target sample of size: 200000 with average certainty per word id 1.60249073767 with average certainty 0.828\n",
      "(200000, 150) (200000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 1562\n",
      "Train epoch 0, average loss 0.331438, average accuracy 0.864377,\n",
      "\t\t aut Dev epoch 0, average loss 0.178,average accuracy 0.932,auc 0.953,f1_pos 0.961,f1_neg 0.729,f1_avg 0.845\n",
      "\t\t\t\t    Time taken for 0 epochs =  76.23231506347656\n",
      "Train epoch 2, average loss 0.207349, average accuracy 0.912652,\n",
      "\t\t aut Dev epoch 2, average loss 0.166,average accuracy 0.937,auc 0.958,f1_pos 0.964,f1_neg 0.758,f1_avg 0.861\n",
      "Train epoch 4, average loss 0.162504, average accuracy 0.933019,\n",
      "\t\t aut Dev epoch 4, average loss 0.167,average accuracy 0.938,auc 0.959,f1_pos 0.964,f1_neg 0.779,f1_avg 0.871\n",
      "\t\t\t\t    Time taken for 4 epochs =  356.4174427986145\n",
      "Train epoch 6, average loss 0.133371, average accuracy 0.946653,\n",
      "\t\t aut Dev epoch 6, average loss 0.171,average accuracy 0.938,auc 0.958,f1_pos 0.964,f1_neg 0.776,f1_avg 0.870\n",
      "Train epoch 8, average loss 0.108248, average accuracy 0.957661,\n",
      "\t\t aut Dev epoch 8, average loss 0.178,average accuracy 0.938,auc 0.957,f1_pos 0.964,f1_neg 0.775,f1_avg 0.870\n",
      "\t\t\t\t    Time taken for 8 epochs =  636.6096963882446\n",
      "Train epoch 10, average loss 0.091937, average accuracy 0.964334,\n",
      "\t\t aut Dev epoch 10, average loss 0.184,average accuracy 0.937,auc 0.957,f1_pos 0.964,f1_neg 0.775,f1_avg 0.869\n",
      "Train epoch 12, average loss 0.0777089, average accuracy 0.970566,\n",
      "\t\t aut Dev epoch 12, average loss 0.204,average accuracy 0.937,auc 0.952,f1_pos 0.964,f1_neg 0.759,f1_avg 0.862\n",
      "\t\t\t\t    Time taken for 12 epochs =  916.8472599983215\n",
      "Train epoch 14, average loss 0.0676991, average accuracy 0.975002,\n",
      "\t\t aut Dev epoch 14, average loss 0.205,average accuracy 0.938,auc 0.955,f1_pos 0.964,f1_neg 0.769,f1_avg 0.866\n",
      "Training on target sample of size: 300000 with average certainty per word id 2.28118252703 with average certainty 0.867\n",
      "(300000, 150) (300000,)\n",
      "/newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints\n",
      " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
      "INFO:tensorflow:Restoring parameters from /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      " Model loaded from: /newvolume/W266Big/final_project/runs/hnk/aut/size_500000/checkpoints/hnkaut_model\n",
      "# batches = 2343\n",
      "Train epoch 0, average loss 0.274003, average accuracy 0.891302,\n",
      "\t\t aut Dev epoch 0, average loss 0.171,average accuracy 0.936,auc 0.958,f1_pos 0.963,f1_neg 0.765,f1_avg 0.864\n",
      "\t\t\t\t    Time taken for 0 epochs =  107.70446252822876\n",
      "Train epoch 2, average loss 0.178548, average accuracy 0.927363,\n",
      "\t\t aut Dev epoch 2, average loss 0.162,average accuracy 0.938,auc 0.962,f1_pos 0.964,f1_neg 0.758,f1_avg 0.861\n",
      "Train epoch 4, average loss 0.144343, average accuracy 0.942298,\n",
      "\t\t aut Dev epoch 4, average loss 0.160,average accuracy 0.941,auc 0.963,f1_pos 0.966,f1_neg 0.784,f1_avg 0.875\n",
      "\t\t\t\t    Time taken for 4 epochs =  513.5091598033905\n",
      "Train epoch 6, average loss 0.121157, average accuracy 0.951891,\n",
      "\t\t aut Dev epoch 6, average loss 0.170,average accuracy 0.940,auc 0.960,f1_pos 0.965,f1_neg 0.771,f1_avg 0.868\n",
      "Train epoch 8, average loss 0.102687, average accuracy 0.95979,\n",
      "\t\t aut Dev epoch 8, average loss 0.174,average accuracy 0.939,auc 0.962,f1_pos 0.964,f1_neg 0.786,f1_avg 0.875\n",
      "\t\t\t\t    Time taken for 8 epochs =  919.476071357727\n",
      "Train epoch 10, average loss 0.0879021, average accuracy 0.965862,\n",
      "\t\t aut Dev epoch 10, average loss 0.179,average accuracy 0.939,auc 0.961,f1_pos 0.964,f1_neg 0.786,f1_avg 0.875\n",
      "Train epoch 12, average loss 0.0767178, average accuracy 0.970791,\n",
      "\t\t aut Dev epoch 12, average loss 0.194,average accuracy 0.935,auc 0.961,f1_pos 0.962,f1_neg 0.781,f1_avg 0.872\n",
      "\t\t\t\t    Time taken for 12 epochs =  1325.5811002254486\n",
      "Train epoch 14, average loss 0.0663473, average accuracy 0.974939,\n",
      "\t\t aut Dev epoch 14, average loss 0.197,average accuracy 0.940,auc 0.960,f1_pos 0.965,f1_neg 0.782,f1_avg 0.874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>f1_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.921988</td>\n",
       "      <td>0.933922</td>\n",
       "      <td>0.700341</td>\n",
       "      <td>0.955157</td>\n",
       "      <td>0.827749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.928173</td>\n",
       "      <td>0.938866</td>\n",
       "      <td>0.716952</td>\n",
       "      <td>0.958868</td>\n",
       "      <td>0.83791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.929321</td>\n",
       "      <td>0.945052</td>\n",
       "      <td>0.738871</td>\n",
       "      <td>0.959129</td>\n",
       "      <td>0.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.930188</td>\n",
       "      <td>0.945041</td>\n",
       "      <td>0.729207</td>\n",
       "      <td>0.959929</td>\n",
       "      <td>0.844568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.929914</td>\n",
       "      <td>0.942704</td>\n",
       "      <td>0.73091</td>\n",
       "      <td>0.95971</td>\n",
       "      <td>0.84531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.930662</td>\n",
       "      <td>0.944424</td>\n",
       "      <td>0.738981</td>\n",
       "      <td>0.960021</td>\n",
       "      <td>0.849501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.929821</td>\n",
       "      <td>0.944517</td>\n",
       "      <td>0.730054</td>\n",
       "      <td>0.959668</td>\n",
       "      <td>0.844861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20000</td>\n",
       "      <td>0.930715</td>\n",
       "      <td>0.942695</td>\n",
       "      <td>0.734772</td>\n",
       "      <td>0.960153</td>\n",
       "      <td>0.847462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.923056</td>\n",
       "      <td>0.934978</td>\n",
       "      <td>0.706158</td>\n",
       "      <td>0.955732</td>\n",
       "      <td>0.830945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.930388</td>\n",
       "      <td>0.94416</td>\n",
       "      <td>0.737628</td>\n",
       "      <td>0.95987</td>\n",
       "      <td>0.848749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.930995</td>\n",
       "      <td>0.946874</td>\n",
       "      <td>0.747393</td>\n",
       "      <td>0.96004</td>\n",
       "      <td>0.853716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.927526</td>\n",
       "      <td>0.945805</td>\n",
       "      <td>0.749856</td>\n",
       "      <td>0.957624</td>\n",
       "      <td>0.85374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.930048</td>\n",
       "      <td>0.944285</td>\n",
       "      <td>0.741322</td>\n",
       "      <td>0.959555</td>\n",
       "      <td>0.850439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.930468</td>\n",
       "      <td>0.942558</td>\n",
       "      <td>0.736552</td>\n",
       "      <td>0.959949</td>\n",
       "      <td>0.84825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.930708</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.746126</td>\n",
       "      <td>0.959879</td>\n",
       "      <td>0.853002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.929848</td>\n",
       "      <td>0.94023</td>\n",
       "      <td>0.735558</td>\n",
       "      <td>0.95956</td>\n",
       "      <td>0.847559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.925258</td>\n",
       "      <td>0.942779</td>\n",
       "      <td>0.693463</td>\n",
       "      <td>0.95744</td>\n",
       "      <td>0.825452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.933837</td>\n",
       "      <td>0.950828</td>\n",
       "      <td>0.754073</td>\n",
       "      <td>0.961777</td>\n",
       "      <td>0.857925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.93267</td>\n",
       "      <td>0.948806</td>\n",
       "      <td>0.731952</td>\n",
       "      <td>0.961499</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.933664</td>\n",
       "      <td>0.950467</td>\n",
       "      <td>0.747133</td>\n",
       "      <td>0.961824</td>\n",
       "      <td>0.854479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.932349</td>\n",
       "      <td>0.952496</td>\n",
       "      <td>0.764372</td>\n",
       "      <td>0.960505</td>\n",
       "      <td>0.862439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.933737</td>\n",
       "      <td>0.949145</td>\n",
       "      <td>0.753768</td>\n",
       "      <td>0.961718</td>\n",
       "      <td>0.857743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.933163</td>\n",
       "      <td>0.950851</td>\n",
       "      <td>0.758905</td>\n",
       "      <td>0.961204</td>\n",
       "      <td>0.860054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.931355</td>\n",
       "      <td>0.950929</td>\n",
       "      <td>0.760949</td>\n",
       "      <td>0.959924</td>\n",
       "      <td>0.860436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.932296</td>\n",
       "      <td>0.94927</td>\n",
       "      <td>0.742541</td>\n",
       "      <td>0.961023</td>\n",
       "      <td>0.851782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935879</td>\n",
       "      <td>0.95637</td>\n",
       "      <td>0.760772</td>\n",
       "      <td>0.962978</td>\n",
       "      <td>0.861875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.934998</td>\n",
       "      <td>0.95201</td>\n",
       "      <td>0.741586</td>\n",
       "      <td>0.962823</td>\n",
       "      <td>0.852204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.936653</td>\n",
       "      <td>0.955865</td>\n",
       "      <td>0.764946</td>\n",
       "      <td>0.963394</td>\n",
       "      <td>0.86417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.936146</td>\n",
       "      <td>0.953448</td>\n",
       "      <td>0.759287</td>\n",
       "      <td>0.963191</td>\n",
       "      <td>0.861239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.936546</td>\n",
       "      <td>0.955522</td>\n",
       "      <td>0.774402</td>\n",
       "      <td>0.963081</td>\n",
       "      <td>0.868741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935512</td>\n",
       "      <td>0.954088</td>\n",
       "      <td>0.767957</td>\n",
       "      <td>0.962552</td>\n",
       "      <td>0.865254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150000</td>\n",
       "      <td>0.935512</td>\n",
       "      <td>0.953367</td>\n",
       "      <td>0.768346</td>\n",
       "      <td>0.962542</td>\n",
       "      <td>0.865444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.931609</td>\n",
       "      <td>0.95287</td>\n",
       "      <td>0.728716</td>\n",
       "      <td>0.960872</td>\n",
       "      <td>0.844794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.937153</td>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.757616</td>\n",
       "      <td>0.963896</td>\n",
       "      <td>0.860756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.958954</td>\n",
       "      <td>0.778729</td>\n",
       "      <td>0.964013</td>\n",
       "      <td>0.871371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.937687</td>\n",
       "      <td>0.958274</td>\n",
       "      <td>0.775621</td>\n",
       "      <td>0.963819</td>\n",
       "      <td>0.86972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.937553</td>\n",
       "      <td>0.956538</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>0.963735</td>\n",
       "      <td>0.869567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.93738</td>\n",
       "      <td>0.957352</td>\n",
       "      <td>0.774678</td>\n",
       "      <td>0.963637</td>\n",
       "      <td>0.869158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.93698</td>\n",
       "      <td>0.952055</td>\n",
       "      <td>0.759264</td>\n",
       "      <td>0.963744</td>\n",
       "      <td>0.861504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200000</td>\n",
       "      <td>0.937593</td>\n",
       "      <td>0.954598</td>\n",
       "      <td>0.768694</td>\n",
       "      <td>0.963931</td>\n",
       "      <td>0.866313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.935905</td>\n",
       "      <td>0.958013</td>\n",
       "      <td>0.764575</td>\n",
       "      <td>0.962903</td>\n",
       "      <td>0.863739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.938007</td>\n",
       "      <td>0.961913</td>\n",
       "      <td>0.757642</td>\n",
       "      <td>0.964458</td>\n",
       "      <td>0.86105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.940796</td>\n",
       "      <td>0.962591</td>\n",
       "      <td>0.783972</td>\n",
       "      <td>0.965697</td>\n",
       "      <td>0.874835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.940015</td>\n",
       "      <td>0.960082</td>\n",
       "      <td>0.770573</td>\n",
       "      <td>0.965497</td>\n",
       "      <td>0.868035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.938521</td>\n",
       "      <td>0.962227</td>\n",
       "      <td>0.785852</td>\n",
       "      <td>0.964108</td>\n",
       "      <td>0.87498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.939101</td>\n",
       "      <td>0.961487</td>\n",
       "      <td>0.78633</td>\n",
       "      <td>0.96449</td>\n",
       "      <td>0.87541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.935025</td>\n",
       "      <td>0.961292</td>\n",
       "      <td>0.781377</td>\n",
       "      <td>0.961842</td>\n",
       "      <td>0.87161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.939942</td>\n",
       "      <td>0.959528</td>\n",
       "      <td>0.781865</td>\n",
       "      <td>0.965177</td>\n",
       "      <td>0.873521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      size       acc       auc    f1_neg    f1_pos    f1_avg\n",
       "0    20000  0.921988  0.933922  0.700341  0.955157  0.827749\n",
       "2    20000  0.928173  0.938866  0.716952  0.958868   0.83791\n",
       "4    20000  0.929321  0.945052  0.738871  0.959129     0.849\n",
       "6    20000  0.930188  0.945041  0.729207  0.959929  0.844568\n",
       "8    20000  0.929914  0.942704   0.73091   0.95971   0.84531\n",
       "10   20000  0.930662  0.944424  0.738981  0.960021  0.849501\n",
       "12   20000  0.929821  0.944517  0.730054  0.959668  0.844861\n",
       "14   20000  0.930715  0.942695  0.734772  0.960153  0.847462\n",
       "0    50000  0.923056  0.934978  0.706158  0.955732  0.830945\n",
       "2    50000  0.930388   0.94416  0.737628   0.95987  0.848749\n",
       "4    50000  0.930995  0.946874  0.747393   0.96004  0.853716\n",
       "6    50000  0.927526  0.945805  0.749856  0.957624   0.85374\n",
       "8    50000  0.930048  0.944285  0.741322  0.959555  0.850439\n",
       "10   50000  0.930468  0.942558  0.736552  0.959949   0.84825\n",
       "12   50000  0.930708  0.943254  0.746126  0.959879  0.853002\n",
       "14   50000  0.929848   0.94023  0.735558   0.95956  0.847559\n",
       "0   100000  0.925258  0.942779  0.693463   0.95744  0.825452\n",
       "2   100000  0.933837  0.950828  0.754073  0.961777  0.857925\n",
       "4   100000   0.93267  0.948806  0.731952  0.961499  0.846726\n",
       "6   100000  0.933664  0.950467  0.747133  0.961824  0.854479\n",
       "8   100000  0.932349  0.952496  0.764372  0.960505  0.862439\n",
       "10  100000  0.933737  0.949145  0.753768  0.961718  0.857743\n",
       "12  100000  0.933163  0.950851  0.758905  0.961204  0.860054\n",
       "14  100000  0.931355  0.950929  0.760949  0.959924  0.860436\n",
       "0   150000  0.932296   0.94927  0.742541  0.961023  0.851782\n",
       "2   150000  0.935879   0.95637  0.760772  0.962978  0.861875\n",
       "4   150000  0.934998   0.95201  0.741586  0.962823  0.852204\n",
       "6   150000  0.936653  0.955865  0.764946  0.963394   0.86417\n",
       "8   150000  0.936146  0.953448  0.759287  0.963191  0.861239\n",
       "10  150000  0.936546  0.955522  0.774402  0.963081  0.868741\n",
       "12  150000  0.935512  0.954088  0.767957  0.962552  0.865254\n",
       "14  150000  0.935512  0.953367  0.768346  0.962542  0.865444\n",
       "0   200000  0.931609   0.95287  0.728716  0.960872  0.844794\n",
       "2   200000  0.937153  0.958491  0.757616  0.963896  0.860756\n",
       "4   200000  0.938094  0.958954  0.778729  0.964013  0.871371\n",
       "6   200000  0.937687  0.958274  0.775621  0.963819   0.86972\n",
       "8   200000  0.937553  0.956538    0.7754  0.963735  0.869567\n",
       "10  200000   0.93738  0.957352  0.774678  0.963637  0.869158\n",
       "12  200000   0.93698  0.952055  0.759264  0.963744  0.861504\n",
       "14  200000  0.937593  0.954598  0.768694  0.963931  0.866313\n",
       "0   300000  0.935905  0.958013  0.764575  0.962903  0.863739\n",
       "2   300000  0.938007  0.961913  0.757642  0.964458   0.86105\n",
       "4   300000  0.940796  0.962591  0.783972  0.965697  0.874835\n",
       "6   300000  0.940015  0.960082  0.770573  0.965497  0.868035\n",
       "8   300000  0.938521  0.962227  0.785852  0.964108   0.87498\n",
       "10  300000  0.939101  0.961487   0.78633   0.96449   0.87541\n",
       "12  300000  0.935025  0.961292  0.781377  0.961842   0.87161\n",
       "14  300000  0.939942  0.959528  0.781865  0.965177  0.873521"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell, we add samples with the lowest certainty per word id first.\n",
    "size_model = size_initial\n",
    "src_key = s_key\n",
    "tgt_key = t_key\n",
    "\n",
    "#Create a sorted version of the certainty, and correspondingly sorted target train set ids, and labels.\n",
    "sort_ids = np.argsort(c_div_len_target)\n",
    "c_div_len_sorted = c_div_len_target[sort_ids]\n",
    "certainty_sorted = u_train_target_abs[sort_ids]\n",
    "#print(sort_ids)\n",
    "df_target_ids_pre = dict_transfer_train_ids[tgt_key][src_key]\n",
    "df_target_labels_pre = dict_train_y[tgt_key]\n",
    "print('Target labels pre sort',df_target_labels_pre[-20:])\n",
    "print(type(df_target_labels_pre))\n",
    "#df_target_ids_pre = df_target_ids_pre.iloc([sort_ids])\n",
    "df_target_ids = df_target_ids_pre[sort_ids]\n",
    "df_target_labels = df_target_labels_pre[sort_ids]\n",
    "print('\\n Target labels post sort',df_target_labels[-20:])\n",
    "print('\\n Certainty sorted','\\n First 20',certainty_sorted[:20],'\\n Last 20',certainty_sorted[-20:])\n",
    "\n",
    "results_cperlen = pd.DataFrame()\n",
    "\n",
    "\n",
    "print('\\nTraining on least certain first')\n",
    "size_list = size_list\n",
    "for size in size_list:\n",
    "    avg_certainty = np.average(certainty_sorted[:size])\n",
    "    avg_c_div_len = np.average(c_div_len_sorted[:size])\n",
    "    print('Training on target sample of size:',size,'with average certainty per word id',avg_c_div_len,'with average certainty %0.3f'%avg_certainty)\n",
    "    tgt_train_df = df_target_ids[:size]\n",
    "    tgt_train_y = df_target_labels[:size]\n",
    "    avg_certainty = np.average(certainty_sorted[:size])\n",
    "    print(tgt_train_df.shape,tgt_train_y.shape)\n",
    "    results = continue_transfer_train(src_key,size_model,tgt_key,tgt_train_df,tgt_train_y)\n",
    "    results['size'] = size\n",
    "    results_cperlen = pd.concat([results_cperlen,results])\n",
    "    \n",
    "results_cperlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old runs of CNN for 1 domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train results \n",
    "\n",
    "toys(10000)\n",
    "completed cnn creation\n",
    "# batches = 78\n",
    "Train epoch 0, average loss 0.410732, average accuracy 0.84986,\n",
    "\t\tDev epoch 0, average loss 0.384446, average accuracy 0.857337,\n",
    "\t\tDev epoch 0, auc 0.761469, new accuracy 0.857337, right accuracy 0.857337,\n",
    "\t\t\t\t    Time taken for 0 epochs =  85.97571444511414\n",
    "Train epoch 3, average loss 0.278746, average accuracy 0.882512,\n",
    "Train epoch 6, average loss 0.190353, average accuracy 0.92508,\n",
    "\t\tDev epoch 6, average loss 0.267068, average accuracy 0.892323,\n",
    "\t\tDev epoch 6, auc 0.884168, new accuracy 0.892323, right accuracy 0.892323,\n",
    "Train epoch 9, average loss 0.120366, average accuracy 0.963241,\n",
    "Train epoch 12, average loss 0.0750643, average accuracy 0.983874,\n",
    "\t\tDev epoch 12, average loss 0.250142, average accuracy 0.90591,\n",
    "\t\tDev epoch 12, auc 0.898789, new accuracy 0.90591, right accuracy 0.90591,\n",
    "\t\t\t\t    Time taken for 12 epochs =  1057.8321163654327\n",
    "Train epoch 15, average loss 0.0461413, average accuracy 0.995292,\n",
    "Saved model toys /home/reachanamikasinha/project/testruns/toys/checkpoints/toys01_model\n",
    "\n",
    "Continue train \n",
    "toys(2000)\n",
    "# batches = 15\n",
    "Train epoch 0, average loss 0.0328055, average accuracy 0.998958,\n",
    "\t\tDev epoch 0, average loss 0.253235, average accuracy 0.900391,\n",
    "\t\tDev epoch 0, auc 0.902401, new accuracy 0.900391, right accuracy 0.900391,\n",
    "\t\t\t\t    Time taken for 0 epochs =  15.97208309173584\n",
    "Train epoch 3, average loss 0.0209501, average accuracy 1,\n",
    "Train epoch 6, average loss 0.0157637, average accuracy 1,\n",
    "\t\tDev epoch 6, average loss 0.246794, average accuracy 0.910156,\n",
    "\t\tDev epoch 6, auc 0.904086, new accuracy 0.910156, right accuracy 0.910156,\n",
    "Train epoch 9, average loss 0.0133948, average accuracy 0.999479,\n",
    "Train epoch 12, average loss 0.0110164, average accuracy 1,\n",
    "\t\tDev epoch 12, average loss 0.268596, average accuracy 0.900391,\n",
    "\t\tDev epoch 12, auc 0.903477, new accuracy 0.900391, right accuracy 0.900391,\n",
    "\t\t\t\t    Time taken for 12 epochs =  203.32078433036804\n",
    "Train epoch 15, average loss 0.00984509, average accuracy 1,\n",
    "\n",
    "\n",
    "Continue train \n",
    "toys(4000)\n",
    "/home/reachanamikasinha/project/testruns/toys/checkpoints\n",
    " RESTORING SESSION FOR WEIGHTS INITIALIZATION\n",
    "INFO:tensorflow:Restoring parameters from /home/reachanamikasinha/project/testruns/toys/checkpoints/toys01_model\n",
    " Model loaded from: /home/reachanamikasinha/project/testruns/toys/checkpoints/toys01_model\n",
    "# batches = 31\n",
    "Train epoch 0, average loss 0.0316445, average accuracy 0.997732,\n",
    "\t\tDev epoch 0, average loss 0.238046, average accuracy 0.911458,\n",
    "\t\tDev epoch 0, auc 0.915253, new accuracy 0.911458, right accuracy 0.911458,\n",
    "\t\t\t\t    Time taken for 0 epochs =  33.795907497406006\n",
    "Train epoch 3, average loss 0.021633, average accuracy 0.999748,\n",
    "Train epoch 6, average loss 0.0158767, average accuracy 0.999496,\n",
    "\t\tDev epoch 6, average loss 0.272812, average accuracy 0.903646,\n",
    "\t\tDev epoch 6, auc 0.915281, new accuracy 0.903646, right accuracy 0.903646,\n",
    "Train epoch 9, average loss 0.0130432, average accuracy 0.999748,\n",
    "Train epoch 12, average loss 0.0109889, average accuracy 1,\n",
    "\t\tDev epoch 12, average loss 0.275246, average accuracy 0.908854,\n",
    "\t\tDev epoch 12, auc 0.91456, new accuracy 0.908854, right accuracy 0.908854,\n",
    "\t\t\t\t    Time taken for 12 epochs =  418.0527718067169\n",
    "Train epoch 15, average loss 0.0100661, average accuracy 0.999748,\n",
    "Train epoch 18, average loss 0.00892393, average accuracy 1,\n",
    "\t\tDev epoch 18, average loss 0.276631, average accuracy 0.907986,\n",
    "\t\tDev epoch 18, auc 0.915397, new accuracy 0.907986, right accuracy 0.907986,\n",
    "Train epoch 21, average loss 0.00748347, average accuracy 1,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of transfer learning testing\n",
    "\n",
    "Comparison\n",
    "target vid\n",
    "/home/reachanamikasinha/project/runs/toys/checkpoints\n",
    "INFO:tensorflow:Restoring parameters from /home/reachanamikasinha/project/runs/toys/checkpoints/toys01_model\n",
    "0.814630681818\n",
    "toys vid AUC 81.24%\n",
    "toys vid accuracy 81.46%\n",
    "\n",
    "Transfer accuracy source toys, target vid(source trained on 10,000 and \n",
    "auc 0.893548, new accuracy 0.898438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving output of model saved run to be able to compare dev accuracy\n",
    "\n",
    "# toys\n",
    "\n",
    "completed cnn creation\n",
    "#batches = 1562\n",
    "Train epoch 0, average loss 0.281697, average accuracy 0.886964,\n",
    "\t\tDev epoch 0, average loss 0.244123, average accuracy 0.908854,\n",
    "\t\t\t\t    Time taken for 0 epochs =  37.60847544670105\n",
    "Train epoch 3, average loss 0.142607, average accuracy 0.944032,\n",
    "Train epoch 6, average loss 0.0771984, average accuracy 0.971111,\n",
    "\t\tDev epoch 6, average loss 0.234148, average accuracy 0.925581,\n",
    "Train epoch 9, average loss 0.0413356, average accuracy 0.985665,\n",
    "Train epoch 12, average loss 0.0262069, average accuracy 0.991207,\n",
    "\t\tDev epoch 12, average loss 0.259911, average accuracy 0.931858,\n",
    "\t\t\t\t    Time taken for 12 epochs =  458.23175573349\n",
    "Train epoch 15, average loss 0.0191853, average accuracy 0.994008,\n",
    "Train epoch 18, average loss 0.0141925, average accuracy 0.995569,\n",
    "\t\tDev epoch 18, average loss 0.297451, average accuracy 0.932759,\n",
    "Train epoch 21, average loss 0.0111091, average accuracy 0.996669,\n",
    "Train epoch 24, average loss 0.00874389, average accuracy 0.997289,\n",
    "\t\tDev epoch 24, average loss 0.37409, average accuracy 0.930889,\n",
    "\t\t\t\t    Time taken for 24 epochs =  879.0003838539124\n",
    "Train epoch 27, average loss 0.00864632, average accuracy 0.997309,\n",
    "Train epoch 30, average loss 0.00784798, average accuracy 0.997459,\n",
    "\t\tDev epoch 30, average loss 0.358449, average accuracy 0.932192,\n",
    "Train epoch 33, average loss 0.00659365, average accuracy 0.997819,\n",
    "Train epoch 36, average loss 0.00578367, average accuracy 0.998349,\n",
    "\t\tDev epoch 36, average loss 0.373084, average accuracy 0.931958,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1299.6440062522888\n",
    "Train epoch 39, average loss 0.0064537, average accuracy 0.998089,\n",
    "Train epoch 42, average loss 0.00580202, average accuracy 0.998259,\n",
    "\t\tDev epoch 42, average loss 0.391404, average accuracy 0.933393,\n",
    "Train epoch 45, average loss 0.00514404, average accuracy 0.99845,\n",
    "Train epoch 48, average loss 0.00371194, average accuracy 0.99892,\n",
    "\t\tDev epoch 48, average loss 0.469131, average accuracy 0.931457,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1720.3404235839844\n",
    "Train epoch 51, average loss 0.0041625, average accuracy 0.99878,\n",
    "Train epoch 54, average loss 0.00460097, average accuracy 0.99856,\n",
    "\t\tDev epoch 54, average loss 0.412365, average accuracy 0.934195,\n",
    "Train epoch 57, average loss 0.00364978, average accuracy 0.99895,\n",
    "Saved model toys /home/ubuntu/project/runs/cnn/checkpoints/toys_model\n",
    "\n",
    "# vid\n",
    "completed cnn creation\n",
    "#batches = 1562\n",
    "Train epoch 0, average loss 0.364666, average accuracy 0.84355,\n",
    "\t\tDev epoch 0, average loss 0.319497, average accuracy 0.86071,\n",
    "\t\t\t\t    Time taken for 0 epochs =  37.799813985824585\n",
    "Train epoch 3, average loss 0.205366, average accuracy 0.917043,\n",
    "Train epoch 6, average loss 0.121604, average accuracy 0.952835,\n",
    "\t\tDev epoch 6, average loss 0.270975, average accuracy 0.899272,\n",
    "Train epoch 9, average loss 0.07385, average accuracy 0.972371,\n",
    "Train epoch 12, average loss 0.0478919, average accuracy 0.982955,\n",
    "\t\tDev epoch 12, average loss 0.35926, average accuracy 0.8959,\n",
    "\t\t\t\t    Time taken for 12 epochs =  459.7377371788025\n",
    "Train epoch 15, average loss 0.0352903, average accuracy 0.987636,\n",
    "Train epoch 18, average loss 0.0294105, average accuracy 0.989997,\n",
    "\t\tDev epoch 18, average loss 0.453399, average accuracy 0.899439,\n",
    "Train epoch 21, average loss 0.0230395, average accuracy 0.992167,\n",
    "Train epoch 24, average loss 0.021058, average accuracy 0.992928,\n",
    "\t\tDev epoch 24, average loss 0.537794, average accuracy 0.899773,\n",
    "\t\t\t\t    Time taken for 24 epochs =  881.6988339424133\n",
    "Train epoch 27, average loss 0.0175359, average accuracy 0.994248,\n",
    "Train epoch 30, average loss 0.0139743, average accuracy 0.995549,\n",
    "\t\tDev epoch 30, average loss 0.571489, average accuracy 0.899673,\n",
    "Train epoch 33, average loss 0.0134842, average accuracy 0.995739,\n",
    "Train epoch 36, average loss 0.0106022, average accuracy 0.996829,\n",
    "\t\tDev epoch 36, average loss 0.609015, average accuracy 0.900407,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1303.694475889206\n",
    "Train epoch 39, average loss 0.0102687, average accuracy 0.996589,\n",
    "Train epoch 42, average loss 0.00967124, average accuracy 0.997099,\n",
    "\t\tDev epoch 42, average loss 0.639956, average accuracy 0.900174,\n",
    "Train epoch 45, average loss 0.00792713, average accuracy 0.997689,\n",
    "Train epoch 48, average loss 0.00804649, average accuracy 0.997559,\n",
    "\t\tDev epoch 48, average loss 0.696189, average accuracy 0.899272,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1725.6383044719696\n",
    "Train epoch 51, average loss 0.00929602, average accuracy 0.997259,\n",
    "Train epoch 54, average loss 0.0067116, average accuracy 0.998039,\n",
    "\t\tDev epoch 54, average loss 0.606182, average accuracy 0.900007,\n",
    "Train epoch 57, average loss 0.00869572, average accuracy 0.997289,\n",
    "Saved model vid /home/ubuntu/project/runs/cnn/checkpoints/vid_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 100,000 rows\n",
    "## Output of predict on source domain toys\n",
    "Target toys\n",
    "\n",
    "\n",
    "## Output of predict on source domainvid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KEEPING TRACK OF RESULTS FROM DIFFERENT RUNS\n",
    "#### Number samples = 10000, Number batches = 156, Without pre-trained embeddings, no dropout\n",
    "Train epoch 0, loss 0.357085, average loss 0.440941, acc 0.84375, average acc 0.845152,\n",
    "\tDev epoch 0, loss 0.494501, average loss 0.394619, acc 0.78125, average acc 0.854959,\n",
    "\t\tTime taken for 0 epochs =  36.18872332572937\n",
    "Train epoch 2, loss 0.25934, average loss 0.335786, acc 0.875, average acc 0.862079,\n",
    "Train epoch 4, loss 0.214457, average loss 0.263726, acc 0.875, average acc 0.891827,\n",
    "Train epoch 6, loss 0.161232, average loss 0.194851, acc 0.890625, average acc 0.92528,\n",
    "Train epoch 8, loss 0.0968393, average loss 0.132971, acc 0.984375, average acc 0.958133,\n",
    "Train epoch 10, loss 0.0598382, average loss 0.0935878, acc 1, average acc 0.978766,\n",
    "\tDev epoch 10, loss 0.318434, average loss 0.279314, acc 0.875, average acc 0.891304,\n",
    "\t\tTime taken for 10 epochs =  366.54717350006104\n",
    "Train epoch 12, loss 0.0432213, average loss 0.089715, acc 1, average acc 0.979768,\n",
    "Train epoch 14, loss 0.0724975, average loss 0.299487, acc 1, average acc 0.957933,\n",
    "Train epoch 16, loss 0.0388074, average loss 0.0520482, acc 1, average acc 0.991987,\n",
    "Train epoch 18, loss 0.0239645, average loss 0.0351604, acc 1, average acc 0.997196,\n",
    "Train epoch 20, loss 0.0157139, average loss 0.0272624, acc 1, average acc 0.996595,\n",
    "\tDev epoch 20, loss 0.304895, average loss 0.283551, acc 0.921875, average acc 0.902853,\n",
    "\t\tTime taken for 20 epochs =  697.680163860321\n",
    "Train epoch 22, loss 0.0131277, average loss 0.017179, acc 1, average acc 0.999299,\n",
    "Train epoch 24, loss 0.0104588, average loss 0.0121853, acc 1, average acc 0.9999,\n",
    "Train epoch 26, loss 0.0072446, average loss 0.00969622, acc 1, average acc 0.9999,\n",
    "Train epoch 28, loss 0.00628954, average loss 0.00805781, acc 1, average acc 0.9999,\n",
    "Train epoch 30, loss 0.00585206, average loss 0.00689346, acc 1, average acc 0.9999,\n",
    "\tDev epoch 30, loss 0.37002, average loss 0.327092, acc 0.875, average acc 0.902514,\n",
    "\t\tTime taken for 30 epochs =  1029.1201057434082\n",
    "Train epoch 32, loss 0.00559655, average loss 0.00594074, acc 1, average acc 0.9999,\n",
    "Train epoch 34, loss 0.0053231, average loss 0.00518374, acc 1, average acc 1,\n",
    "Train epoch 36, loss 0.00504235, average loss 0.00461033, acc 1, average acc 1,\n",
    "Train epoch 38, loss 0.00477842, average loss 0.00416377, acc 1, average acc 1,\n",
    "Train epoch 40, loss 0.00451324, average loss 0.00380536, acc 1, average acc 1,\n",
    "\tDev epoch 40, loss 0.451459, average loss 0.382435, acc 0.859375, average acc 0.899796,\n",
    "\t\tTime taken for 40 epochs =  1360.2103555202484\n",
    "        \n",
    "        \n",
    "#### Number samples = 10000, Number batches = 156, With pre-trained embeddings(Trainable = False), dropout = 0.8\n",
    "Train epoch 0, average loss 0.819034, average acc 0.802784,\n",
    "\tDev epoch 0, average loss 0.415172, average acc 0.853601,\n",
    "\t\tTime taken for 0 epochs =  35.559093713760376\n",
    "Train epoch 2, average loss 0.403757, average acc 0.841046,\n",
    "Train epoch 4, average loss 0.340479, average acc 0.860777,\n",
    "\tDev epoch 5, average loss 0.329067, average acc 0.867188,\n",
    "Train epoch 6, average loss 0.289147, average acc 0.882312,\n",
    "Train epoch 8, average loss 0.237817, average acc 0.904948,\n",
    "Train epoch 10, average loss 0.194272, average acc 0.923978,\n",
    "\tDev epoch 10, average loss 0.330927, average acc 0.876698,\n",
    "\t\tTime taken for 10 epochs =  363.92726016044617\n",
    "Train epoch 12, average loss 0.149883, average acc 0.940405,\n",
    "Train epoch 14, average loss 0.128152, average acc 0.951322,\n",
    "\tDev epoch 15, average loss 0.349508, average acc 0.877717,\n",
    "Train epoch 16, average loss 0.101319, average acc 0.961639,\n",
    "Train epoch 18, average loss 0.079585, average acc 0.970052,\n",
    "Train epoch 20, average loss 0.0705579, average acc 0.97516,\n",
    "\tDev epoch 20, average loss 0.364253, average acc 0.878057,\n",
    "\t\tTime taken for 20 epochs =  692.3398864269257\n",
    "Train epoch 22, average loss 0.0631964, average acc 0.978466,\n",
    "Train epoch 24, average loss 0.0484077, average acc 0.984876,\n",
    "\tDev epoch 25, average loss 0.435054, average acc 0.877717,\n",
    "Train epoch 26, average loss 0.0433892, average acc 0.985377,\n",
    "Train epoch 28, average loss 0.0368327, average acc 0.988381,\n",
    "Train epoch 30, average loss 0.0308169, average acc 0.990385,\n",
    "\tDev epoch 30, average loss 0.570798, average acc 0.875679,\n",
    "\t\tTime taken for 30 epochs =  1052.273297548294\n",
    "Train epoch 32, average loss 0.0291807, average acc 0.991086,\n",
    "Train epoch 34, average loss 0.0271599, average acc 0.991987,\n",
    "\tDev epoch 35, average loss 0.661539, average acc 0.87534,\n",
    "Train epoch 36, average loss 0.029594, average acc 0.991486,\n",
    "Train epoch 38, average loss 0.0236557, average acc 0.99359,\n",
    "Train epoch 40, average loss 0.018746, average acc 0.995292,\n",
    "\tDev epoch 40, average loss 0.506544, average acc 0.878397,\n",
    "\t\tTime taken for 40 epochs =  1466.0729427337646\n",
    "        \n",
    "        \n",
    "#### Changes. Changed convolutional layer weights to xavier initialization. Added random see = 42 to train-test split. Dropped learning rate initial to 0.007\n",
    "\n",
    "Train epoch 0, average loss 0.399899, average accuracy 0.858273,\n",
    "\tDev epoch 0, average loss 0.374428, average accuracy 0.857337,\n",
    "\t\tTime taken for 0 epochs =  34.83389401435852\n",
    "Train epoch 2, average loss 0.326706, average accuracy 0.869391,\n",
    "Train epoch 4, average loss 0.269826, average accuracy 0.891126,\n",
    "\tDev epoch 5, average loss 0.303238, average accuracy 0.88519,\n",
    "Train epoch 6, average loss 0.219368, average accuracy 0.911659,\n",
    "Train epoch 8, average loss 0.171234, average accuracy 0.935296,\n",
    "Train epoch 10, average loss 0.13296, average accuracy 0.953325,\n",
    "\tDev epoch 10, average loss 0.293018, average accuracy 0.887568,\n",
    "\t\tTime taken for 10 epochs =  370.47870922088623\n",
    "Train epoch 12, average loss 0.100562, average accuracy 0.967348,\n",
    "Train epoch 14, average loss 0.0793127, average accuracy 0.977063,\n",
    "\tDev epoch 15, average loss 0.320119, average accuracy 0.886209,\n",
    "Train epoch 16, average loss 0.0582729, average accuracy 0.988482,\n",
    "Train epoch 18, average loss 0.0456755, average accuracy 0.990385,\n",
    "Train epoch 20, average loss 0.0405185, average accuracy 0.992788,\n",
    "\tDev epoch 20, average loss 0.321604, average accuracy 0.886889,\n",
    "\t\tTime taken for 20 epochs =  705.0958936214447\n",
    "Train epoch 22, average loss 0.0351258, average accuracy 0.993089,\n",
    "Train epoch 24, average loss 0.0270392, average accuracy 0.996194,\n",
    "\tDev epoch 25, average loss 0.399808, average accuracy 0.884171,\n",
    "Train epoch 26, average loss 0.0262923, average accuracy 0.995994,\n",
    "Train epoch 28, average loss 0.0242657, average accuracy 0.995994,\n",
    "Train epoch 30, average loss 0.0208821, average accuracy 0.996394,\n",
    "\tDev epoch 30, average loss 0.413923, average accuracy 0.886889,\n",
    "\t\tTime taken for 30 epochs =  1039.4113600254059\n",
    "Train epoch 32, average loss 0.017492, average accuracy 0.997696,\n",
    "Train epoch 34, average loss 0.0146527, average accuracy 0.998097,\n",
    "\tDev epoch 35, average loss 0.386267, average accuracy 0.884851,\n",
    "Train epoch 36, average loss 0.0168233, average accuracy 0.997396,\n",
    "Train epoch 38, average loss 0.0142984, average accuracy 0.997796,\n",
    "Train epoch 40, average loss 0.0110543, average accuracy 0.998998,\n",
    "\tDev epoch 40, average loss 0.478341, average accuracy 0.884171,\n",
    "\t\tTime taken for 40 epochs =  1374.086744070053\n",
    "Train epoch 42, average loss 0.012298, average accuracy 0.998397,\n",
    "Train epoch 44, average loss 0.0116889, average accuracy 0.998197,\n",
    "\tDev epoch 45, average loss 0.448394, average accuracy 0.88587,\n",
    "Train epoch 46, average loss 0.0107089, average accuracy 0.998197,\n",
    "Train epoch 48, average loss 0.00953887, average accuracy 0.998898,\n",
    "Train epoch 50, average loss 0.0097256, average accuracy 0.998898,\n",
    "\tDev epoch 50, average loss 0.424627, average accuracy 0.886209,\n",
    "\t\tTime taken for 50 epochs =  1708.131004333496\n",
    "Train epoch 52, average loss 0.00792942, average accuracy 0.999099,\n",
    "Train epoch 54, average loss 0.00777054, average accuracy 0.999099,\n",
    "\tDev epoch 55, average loss 0.434766, average accuracy 0.887228,\n",
    "Train epoch 56, average loss 0.00812112, average accuracy 0.999099,\n",
    "Train epoch 58, average loss 0.00817043, average accuracy 0.998798,\n",
    "Train epoch 60, average loss 0.00776972, average accuracy 0.998498,\n",
    "\tDev epoch 60, average loss 0.447535, average accuracy 0.886889,\n",
    "\t\tTime taken for 60 epochs =  2042.1303217411041\n",
    "Train epoch 62, average loss 0.00759579, average accuracy 0.998998,\n",
    "Train epoch 64, average loss 0.00697335, average accuracy 0.998798,\n",
    "\tDev epoch 65, average loss 0.514295, average accuracy 0.88519,\n",
    "Train epoch 66, average loss 0.00579109, average accuracy 0.999199,\n",
    "Train epoch 68, average loss 0.00583337, average accuracy 0.999499,\n",
    "\n",
    "#### Changes. set trainable = True in glove embeddings. Changed learning rate back to 0.01 initial.\n",
    "# batches = 156\n",
    "Train epoch 0, average loss 0.399899, average accuracy 0.858273,\n",
    "\tDev epoch 0, average loss 0.374428, average accuracy 0.857337,\n",
    "\t\tTime taken for 0 epochs =  34.83389401435852\n",
    "Train epoch 2, average loss 0.326706, average accuracy 0.869391,\n",
    "Train epoch 4, average loss 0.269826, average accuracy 0.891126,\n",
    "\tDev epoch 5, average loss 0.303238, average accuracy 0.88519,\n",
    "Train epoch 6, average loss 0.219368, average accuracy 0.911659,\n",
    "Train epoch 8, average loss 0.171234, average accuracy 0.935296,\n",
    "Train epoch 10, average loss 0.13296, average accuracy 0.953325,\n",
    "\tDev epoch 10, average loss 0.293018, average accuracy 0.887568,\n",
    "\t\tTime taken for 10 epochs =  370.47870922088623\n",
    "Train epoch 12, average loss 0.100562, average accuracy 0.967348,\n",
    "Train epoch 14, average loss 0.0793127, average accuracy 0.977063,\n",
    "\tDev epoch 15, average loss 0.320119, average accuracy 0.886209,\n",
    "Train epoch 16, average loss 0.0582729, average accuracy 0.988482,\n",
    "Train epoch 18, average loss 0.0456755, average accuracy 0.990385,\n",
    "Train epoch 20, average loss 0.0405185, average accuracy 0.992788,\n",
    "\tDev epoch 20, average loss 0.321604, average accuracy 0.886889,\n",
    "\t\tTime taken for 20 epochs =  705.0958936214447\n",
    "Train epoch 22, average loss 0.0351258, average accuracy 0.993089,\n",
    "Train epoch 24, average loss 0.0270392, average accuracy 0.996194,\n",
    "\tDev epoch 25, average loss 0.399808, average accuracy 0.884171,\n",
    "Train epoch 26, average loss 0.0262923, average accuracy 0.995994,\n",
    "Train epoch 28, average loss 0.0242657, average accuracy 0.995994,\n",
    "Train epoch 30, average loss 0.0208821, average accuracy 0.996394,\n",
    "\tDev epoch 30, average loss 0.413923, average accuracy 0.886889,\n",
    "\t\tTime taken for 30 epochs =  1039.4113600254059\n",
    "Train epoch 32, average loss 0.017492, average accuracy 0.997696,\n",
    "Train epoch 34, average loss 0.0146527, average accuracy 0.998097,\n",
    "\tDev epoch 35, average loss 0.386267, average accuracy 0.884851,\n",
    "Train epoch 36, average loss 0.0168233, average accuracy 0.997396,\n",
    "Train epoch 38, average loss 0.0142984, average accuracy 0.997796,\n",
    "Train epoch 40, average loss 0.0110543, average accuracy 0.998998,\n",
    "\tDev epoch 40, average loss 0.478341, average accuracy 0.884171,\n",
    "\t\tTime taken for 40 epochs =  1374.086744070053\n",
    "Train epoch 42, average loss 0.012298, average accuracy 0.998397,\n",
    "Train epoch 44, average loss 0.0116889, average accuracy 0.998197,\n",
    "\tDev epoch 45, average loss 0.448394, average accuracy 0.88587,\n",
    "Train epoch 46, average loss 0.0107089, average accuracy 0.998197,\n",
    "Train epoch 48, average loss 0.00953887, average accuracy 0.998898,\n",
    "Train epoch 50, average loss 0.0097256, average accuracy 0.998898,\n",
    "\tDev epoch 50, average loss 0.424627, average accuracy 0.886209,\n",
    "\t\tTime taken for 50 epochs =  1708.131004333496\n",
    "Train epoch 52, average loss 0.00792942, average accuracy 0.999099,\n",
    "Train epoch 54, average loss 0.00777054, average accuracy 0.999099,\n",
    "\tDev epoch 55, average loss 0.434766, average accuracy 0.887228,\n",
    "Train epoch 56, average loss 0.00812112, average accuracy 0.999099,\n",
    "Train epoch 58, average loss 0.00817043, average accuracy 0.998798,\n",
    "Train epoch 60, average loss 0.00776972, average accuracy 0.998498,\n",
    "\tDev epoch 60, average loss 0.447535, average accuracy 0.886889,\n",
    "\t\tTime taken for 60 epochs =  2042.1303217411041\n",
    "Train epoch 62, average loss 0.00759579, average accuracy 0.998998,\n",
    "Train epoch 64, average loss 0.00697335, average accuracy 0.998798,\n",
    "\tDev epoch 65, average loss 0.514295, average accuracy 0.88519,\n",
    "Train epoch 66, average loss 0.00579109, average accuracy 0.999199,\n",
    "Train epoch 68, average loss 0.00583337, average accuracy 0.999499,\n",
    "\n",
    "\n",
    "#### Changes : increased sample size to 20000. increased filter number to 256 per filter size. Both together slowed it down 4 times. Ran 150 epochs.\n",
    "\n",
    "Result - get to accuracy of about 90.5% on dev set. First saw it in about 80 epochs.\n",
    "\n",
    "number of batches = 312\n",
    "Train epoch 0, average loss 0.399409, average accuracy 0.851763,\n",
    "\tDev epoch 0, average loss 0.390935, average accuracy 0.849798,\n",
    "\t\tTime taken for 0 epochs =  126.17049622535706\n",
    "Train epoch 2, average loss 0.310082, average accuracy 0.877955,\n",
    "Train epoch 4, average loss 0.240321, average accuracy 0.905298,\n",
    "\tDev epoch 5, average loss 0.309063, average accuracy 0.879872,\n",
    "Train epoch 6, average loss 0.183422, average accuracy 0.929137,\n",
    "Train epoch 8, average loss 0.132305, average accuracy 0.950871,\n",
    "Train epoch 10, average loss 0.091186, average accuracy 0.96855,\n",
    "\tDev epoch 10, average loss 0.359275, average accuracy 0.887769,\n",
    "\t\tTime taken for 10 epochs =  1301.3605210781097\n",
    "Train epoch 12, average loss 0.0655771, average accuracy 0.978966,\n",
    "Train epoch 14, average loss 0.0487824, average accuracy 0.986579,\n",
    "\tDev epoch 15, average loss 0.31907, average accuracy 0.901546,\n",
    "Train epoch 16, average loss 0.0353836, average accuracy 0.991136,\n",
    "Train epoch 18, average loss 0.0272109, average accuracy 0.993389,\n",
    "Train epoch 20, average loss 0.0209386, average accuracy 0.995843,\n",
    "\tDev epoch 20, average loss 0.473887, average accuracy 0.888609,\n",
    "\t\tTime taken for 20 epochs =  2475.8890883922577\n",
    "Train epoch 22, average loss 0.0169513, average accuracy 0.996444,\n",
    "Train epoch 24, average loss 0.0144857, average accuracy 0.997045,\n",
    "\tDev epoch 25, average loss 0.52256, average accuracy 0.886929,\n",
    "Train epoch 26, average loss 0.0115876, average accuracy 0.998147,\n",
    "Train epoch 28, average loss 0.00961356, average accuracy 0.998347,\n",
    "Train epoch 30, average loss 0.00915859, average accuracy 0.998297,\n",
    "\tDev epoch 30, average loss 0.458756, average accuracy 0.895665,\n",
    "\t\tTime taken for 30 epochs =  3649.31303191185\n",
    "Train epoch 32, average loss 0.00898325, average accuracy 0.998498,\n",
    "Train epoch 34, average loss 0.00841926, average accuracy 0.998448,\n",
    "\tDev epoch 35, average loss 0.457308, average accuracy 0.897681,\n",
    "Train epoch 36, average loss 0.00646681, average accuracy 0.999149,\n",
    "Train epoch 38, average loss 0.00662382, average accuracy 0.998598,\n",
    "Train epoch 40, average loss 0.00595506, average accuracy 0.999149,\n",
    "\tDev epoch 40, average loss 0.378182, average accuracy 0.901546,\n",
    "\t\tTime taken for 40 epochs =  4823.336989402771\n",
    "Train epoch 42, average loss 0.00593351, average accuracy 0.999149,\n",
    "Train epoch 44, average loss 0.00464219, average accuracy 0.999249,\n",
    "\tDev epoch 45, average loss 0.431081, average accuracy 0.90121,\n",
    "Train epoch 46, average loss 0.00444085, average accuracy 0.999499,\n",
    "Train epoch 48, average loss 0.00461485, average accuracy 0.999349,\n",
    "Train epoch 50, average loss 0.00466378, average accuracy 0.999199,\n",
    "\tDev epoch 50, average loss 0.380632, average accuracy 0.90289,\n",
    "\t\tTime taken for 50 epochs =  5997.558866024017\n",
    "Train epoch 52, average loss 0.00401276, average accuracy 0.999299,\n",
    "Train epoch 54, average loss 0.00360064, average accuracy 0.999549,\n",
    "\tDev epoch 55, average loss 0.472261, average accuracy 0.900706,\n",
    "Train epoch 56, average loss 0.00390259, average accuracy 0.999449,\n",
    "Train epoch 58, average loss 0.00343323, average accuracy 0.999499,\n",
    "Train epoch 60, average loss 0.00328182, average accuracy 0.999549,\n",
    "\tDev epoch 60, average loss 0.405813, average accuracy 0.901714,\n",
    "\t\tTime taken for 60 epochs =  7171.330280542374\n",
    "Train epoch 62, average loss 0.00357674, average accuracy 0.999499,\n",
    "Train epoch 64, average loss 0.00316356, average accuracy 0.999449,\n",
    "\tDev epoch 65, average loss 0.484432, average accuracy 0.899698,\n",
    "Train epoch 66, average loss 0.00242786, average accuracy 0.99975,\n",
    "Train epoch 68, average loss 0.0029979, average accuracy 0.999399,\n",
    "Train epoch 70, average loss 0.00219736, average accuracy 0.999599,\n",
    "\tDev epoch 70, average loss 0.522188, average accuracy 0.89953,\n",
    "\t\tTime taken for 70 epochs =  8345.40755033493\n",
    "Train epoch 72, average loss 0.00263028, average accuracy 0.999599,\n",
    "Train epoch 74, average loss 0.00262097, average accuracy 0.999599,\n",
    "\tDev epoch 75, average loss 0.501381, average accuracy 0.90037,\n",
    "Train epoch 76, average loss 0.00184087, average accuracy 0.99975,\n",
    "Train epoch 78, average loss 0.00261343, average accuracy 0.999399,\n",
    "Train epoch 80, average loss 0.00210662, average accuracy 0.9997,\n",
    "\tDev epoch 80, average loss 0.437249, average accuracy 0.90457,\n",
    "\t\tTime taken for 80 epochs =  9519.476462364197\n",
    "Train epoch 82, average loss 0.00218873, average accuracy 0.999599,\n",
    "Train epoch 84, average loss 0.00204953, average accuracy 0.9997,\n",
    "\tDev epoch 85, average loss 0.440843, average accuracy 0.90457,\n",
    "Train epoch 86, average loss 0.00178851, average accuracy 0.99975,\n",
    "Train epoch 88, average loss 0.00177724, average accuracy 0.999599,\n",
    "Train epoch 90, average loss 0.0018953, average accuracy 0.999599,\n",
    "\tDev epoch 90, average loss 0.465653, average accuracy 0.905074,\n",
    "\t\tTime taken for 90 epochs =  10693.68774318695\n",
    "Train epoch 92, average loss 0.00145395, average accuracy 0.9998,\n",
    "Train epoch 94, average loss 0.00158429, average accuracy 0.999649,\n",
    "\tDev epoch 95, average loss 0.472749, average accuracy 0.90541,\n",
    "Train epoch 96, average loss 0.00238694, average accuracy 0.999499,\n",
    "Train epoch 98, average loss 0.00175795, average accuracy 0.9997,\n",
    "Train epoch 100, average loss 0.00153946, average accuracy 0.9998,\n",
    "\tDev epoch 100, average loss 0.440989, average accuracy 0.906754,\n",
    "\t\tTime taken for 100 epochs =  11867.341850280762\n",
    "Train epoch 102, average loss 0.00144569, average accuracy 0.9998,\n",
    "Train epoch 104, average loss 0.00135836, average accuracy 0.99975,\n",
    "\tDev epoch 105, average loss 0.450465, average accuracy 0.90457,\n",
    "Train epoch 106, average loss 0.00134604, average accuracy 0.99985,\n",
    "Train epoch 108, average loss 0.00198454, average accuracy 0.999549,\n",
    "Train epoch 110, average loss 0.0016289, average accuracy 0.99975,\n",
    "\tDev epoch 110, average loss 0.43462, average accuracy 0.905242,\n",
    "\t\tTime taken for 110 epochs =  13040.53886771202\n",
    "Train epoch 112, average loss 0.00116808, average accuracy 0.99975,\n",
    "Train epoch 114, average loss 0.00163431, average accuracy 0.999649,\n",
    "\tDev epoch 115, average loss 0.544521, average accuracy 0.901714,\n",
    "Train epoch 116, average loss 0.00107182, average accuracy 0.9999,\n",
    "Train epoch 118, average loss 0.00118616, average accuracy 0.99985,\n",
    "Train epoch 120, average loss 0.00116875, average accuracy 0.9998,\n",
    "\tDev epoch 120, average loss 0.456846, average accuracy 0.906082,\n",
    "\t\tTime taken for 120 epochs =  14214.848599672318\n",
    "Train epoch 122, average loss 0.00144058, average accuracy 0.999649,\n",
    "Train epoch 124, average loss 0.00139588, average accuracy 0.999649,\n",
    "\tDev epoch 125, average loss 0.456731, average accuracy 0.90709,\n",
    "Train epoch 126, average loss 0.00129419, average accuracy 0.99975,\n",
    "Train epoch 128, average loss 0.000993939, average accuracy 0.9998,\n",
    "Train epoch 130, average loss 0.00110859, average accuracy 0.99975,\n",
    "\tDev epoch 130, average loss 0.440627, average accuracy 0.905242,\n",
    "\t\tTime taken for 130 epochs =  15387.949309825897\n",
    "Train epoch 132, average loss 0.000869354, average accuracy 0.9998,\n",
    "Train epoch 134, average loss 0.0010678, average accuracy 0.99975,\n",
    "\tDev epoch 135, average loss 0.662642, average accuracy 0.895497,\n",
    "Train epoch 136, average loss 0.00121623, average accuracy 0.99985,\n",
    "Train epoch 138, average loss 0.00106557, average accuracy 0.9998,\n",
    "Train epoch 140, average loss 0.0012005, average accuracy 0.9997,\n",
    "\tDev epoch 140, average loss 0.48323, average accuracy 0.905578,\n",
    "\t\tTime taken for 140 epochs =  16560.915422201157\n",
    "Train epoch 142, average loss 0.00142349, average accuracy 0.999649,\n",
    "Train epoch 144, average loss 0.00100832, average accuracy 0.9998,\n",
    "\tDev epoch 145, average loss 0.469864, average accuracy 0.906082,\n",
    "Train epoch 146, average loss 0.000867766, average accuracy 0.99985,\n",
    "Train epoch 148, average loss 0.000895252, average accuracy 0.9998,\n",
    "Train epoch 150, average loss 0.00128643, average accuracy 0.99975,\n",
    "\tDev epoch 150, average loss 0.504558, average accuracy 0.904738,\n",
    "\t\tTime taken for 150 epochs =  17732.689709424973\n",
    "Train epoch 152, average loss 0.00106975, average accuracy 0.99975,\n",
    "Train epoch 154, average loss 0.000923771, average accuracy 0.9998,\n",
    "\tDev epoch 155, average loss 0.46343, average accuracy 0.904066,\n",
    "    \n",
    "    \n",
    "#### Home and Kitchen, 100000 reviews. 200 epochs, min-documents = 0, embedding size = 100, embeddings trainable = True.\n",
    "\n",
    "completed cnn creation\n",
    "Number batches = 1562\n",
    "Train epoch 0, average loss 0.304591, average accuracy 0.87457,\n",
    "\tDev epoch 0, average loss 0.237596, average accuracy 0.904013,\n",
    "\t\tTime taken for 0 epochs =  36.92328929901123\n",
    "Train epoch 1, average loss 0.223893, average accuracy 0.910071,\n",
    "Train epoch 2, average loss 0.183924, average accuracy 0.927187,\n",
    "Train epoch 3, average loss 0.150811, average accuracy 0.941301,\n",
    "Train epoch 4, average loss 0.123611, average accuracy 0.952775,\n",
    "Train epoch 5, average loss 0.101681, average accuracy 0.961138,\n",
    "\tDev epoch 5, average loss 0.215108, average accuracy 0.917234,\n",
    "Train epoch 6, average loss 0.0824821, average accuracy 0.9694,\n",
    "Train epoch 7, average loss 0.0682877, average accuracy 0.975272,\n",
    "Train epoch 8, average loss 0.0581098, average accuracy 0.978353,\n",
    "Train epoch 9, average loss 0.0481609, average accuracy 0.982815,\n",
    "Train epoch 10, average loss 0.0426059, average accuracy 0.984625,\n",
    "\tDev epoch 10, average loss 0.258906, average accuracy 0.918336,\n",
    "\t\tTime taken for 10 epochs =  381.81759333610535\n",
    "Train epoch 11, average loss 0.0369901, average accuracy 0.986686,\n",
    "Train epoch 12, average loss 0.0348868, average accuracy 0.986946,\n",
    "Train epoch 13, average loss 0.0291087, average accuracy 0.989937,\n",
    "Train epoch 14, average loss 0.0271577, average accuracy 0.990807,\n",
    "Train epoch 15, average loss 0.0248202, average accuracy 0.991487,\n",
    "\tDev epoch 15, average loss 0.317684, average accuracy 0.925114,\n",
    "Train epoch 16, average loss 0.0232966, average accuracy 0.992037,\n",
    "Train epoch 17, average loss 0.0218823, average accuracy 0.992578,\n",
    "Train epoch 18, average loss 0.0189234, average accuracy 0.993878,\n",
    "Train epoch 19, average loss 0.0175714, average accuracy 0.993978,\n",
    "Train epoch 20, average loss 0.0175559, average accuracy 0.994108,\n",
    "\tDev epoch 20, average loss 0.322537, average accuracy 0.924746,\n",
    "\t\tTime taken for 20 epochs =  727.1127679347992\n",
    "Train epoch 21, average loss 0.0159045, average accuracy 0.994638,\n",
    "Train epoch 22, average loss 0.0141158, average accuracy 0.995409,\n",
    "Train epoch 23, average loss 0.0130852, average accuracy 0.995809,\n",
    "Train epoch 24, average loss 0.0131137, average accuracy 0.995709,\n",
    "Train epoch 25, average loss 0.0123618, average accuracy 0.995899,\n",
    "\tDev epoch 25, average loss 0.403685, average accuracy 0.924646,\n",
    "Train epoch 26, average loss 0.0112836, average accuracy 0.996369,\n",
    "Train epoch 27, average loss 0.0111362, average accuracy 0.996449,\n",
    "Train epoch 28, average loss 0.00865663, average accuracy 0.997299,\n",
    "Train epoch 29, average loss 0.00935199, average accuracy 0.996959,\n",
    "Train epoch 30, average loss 0.00935717, average accuracy 0.996699,\n",
    "\tDev epoch 30, average loss 0.367405, average accuracy 0.924579,\n",
    "\t\tTime taken for 30 epochs =  1072.1994183063507\n",
    "Train epoch 31, average loss 0.00909225, average accuracy 0.997149,\n",
    "Train epoch 32, average loss 0.00754316, average accuracy 0.997819,\n",
    "Train epoch 33, average loss 0.0079119, average accuracy 0.997379,\n",
    "Train epoch 34, average loss 0.00705012, average accuracy 0.997719,\n",
    "Train epoch 35, average loss 0.00730037, average accuracy 0.997829,\n",
    "\tDev epoch 35, average loss 0.370859, average accuracy 0.926749,\n",
    "Train epoch 36, average loss 0.00705196, average accuracy 0.997799,\n",
    "Train epoch 37, average loss 0.00669642, average accuracy 0.998039,\n",
    "Train epoch 38, average loss 0.00627199, average accuracy 0.998009,\n",
    "Train epoch 39, average loss 0.00528379, average accuracy 0.998309,\n",
    "Train epoch 40, average loss 0.00593793, average accuracy 0.998229,\n",
    "\tDev epoch 40, average loss 0.383177, average accuracy 0.927618,\n",
    "\t\tTime taken for 40 epochs =  1416.9269080162048\n",
    "Train epoch 41, average loss 0.00519099, average accuracy 0.998289,\n",
    "Train epoch 42, average loss 0.00574083, average accuracy 0.998259,\n",
    "Train epoch 43, average loss 0.00573397, average accuracy 0.998269,\n",
    "Train epoch 44, average loss 0.00478373, average accuracy 0.99844,\n",
    "Train epoch 45, average loss 0.00476654, average accuracy 0.99864,\n",
    "\tDev epoch 45, average loss 0.401872, average accuracy 0.927651,\n",
    "Train epoch 46, average loss 0.00546603, average accuracy 0.998079,\n",
    "Train epoch 47, average loss 0.00552262, average accuracy 0.998299,\n",
    "Train epoch 48, average loss 0.0044039, average accuracy 0.9986,\n",
    "Train epoch 49, average loss 0.00444202, average accuracy 0.99858,\n",
    "Train epoch 50, average loss 0.00553655, average accuracy 0.998239,\n",
    "\tDev epoch 50, average loss 0.410369, average accuracy 0.926182,\n",
    "\t\tTime taken for 50 epochs =  1761.8077738285065\n",
    "Train epoch 51, average loss 0.00446012, average accuracy 0.99862,\n",
    "Train epoch 52, average loss 0.00399219, average accuracy 0.9988,\n",
    "Train epoch 53, average loss 0.00413133, average accuracy 0.99876,\n",
    "Train epoch 54, average loss 0.00465115, average accuracy 0.99857,\n",
    "Train epoch 55, average loss 0.00390704, average accuracy 0.99883,\n",
    "\tDev epoch 55, average loss 0.523764, average accuracy 0.924212,\n",
    "Train epoch 56, average loss 0.00380121, average accuracy 0.99894,\n",
    "Train epoch 57, average loss 0.0041114, average accuracy 0.99863,\n",
    "Train epoch 58, average loss 0.00400388, average accuracy 0.99874,\n",
    "Train epoch 59, average loss 0.00436616, average accuracy 0.99868,\n",
    "Train epoch 60, average loss 0.00410136, average accuracy 0.99879,\n",
    "\tDev epoch 60, average loss 0.465152, average accuracy 0.926115,\n",
    "\t\tTime taken for 60 epochs =  2106.424416542053\n",
    "Train epoch 61, average loss 0.00331209, average accuracy 0.99906,\n",
    "Train epoch 62, average loss 0.00366131, average accuracy 0.99892,\n",
    "Train epoch 63, average loss 0.00425752, average accuracy 0.99884,\n",
    "Train epoch 64, average loss 0.00341706, average accuracy 0.99892,\n",
    "Train epoch 65, average loss 0.00352085, average accuracy 0.99884,\n",
    "\tDev epoch 65, average loss 0.443976, average accuracy 0.919404,\n",
    "Train epoch 66, average loss 0.00392861, average accuracy 0.99874,\n",
    "Train epoch 67, average loss 0.00390108, average accuracy 0.99879,\n",
    "Train epoch 68, average loss 0.00344137, average accuracy 0.99892,\n",
    "Train epoch 69, average loss 0.00282472, average accuracy 0.99918,\n",
    "Train epoch 70, average loss 0.00305406, average accuracy 0.99906,\n",
    "\tDev epoch 70, average loss 0.497239, average accuracy 0.926783,\n",
    "\t\tTime taken for 70 epochs =  2451.336544752121\n",
    "Train epoch 71, average loss 0.00335245, average accuracy 0.99887,\n",
    "Train epoch 72, average loss 0.00321827, average accuracy 0.99912,\n",
    "Train epoch 73, average loss 0.0030572, average accuracy 0.99906,\n",
    "Train epoch 74, average loss 0.00308252, average accuracy 0.99905,\n",
    "Train epoch 75, average loss 0.00312562, average accuracy 0.99909,\n",
    "\tDev epoch 75, average loss 0.454947, average accuracy 0.927818,\n",
    "Train epoch 76, average loss 0.00308124, average accuracy 0.99912,\n",
    "Train epoch 77, average loss 0.00282977, average accuracy 0.9991,\n",
    "Train epoch 78, average loss 0.00250926, average accuracy 0.99929,\n",
    "Train epoch 79, average loss 0.00278992, average accuracy 0.99917,\n",
    "Train epoch 80, average loss 0.00226384, average accuracy 0.99932,\n",
    "\tDev epoch 80, average loss 0.524143, average accuracy 0.925314,\n",
    "\t\tTime taken for 80 epochs =  2796.155880212784\n",
    "Train epoch 81, average loss 0.00289398, average accuracy 0.99907,\n",
    "Train epoch 82, average loss 0.00267882, average accuracy 0.99915,\n",
    "Train epoch 83, average loss 0.00251234, average accuracy 0.99917,\n",
    "Train epoch 84, average loss 0.00212931, average accuracy 0.99929,\n",
    "Train epoch 85, average loss 0.00204477, average accuracy 0.99936,\n",
    "\tDev epoch 85, average loss 0.533493, average accuracy 0.926382,\n",
    "Train epoch 86, average loss 0.00236821, average accuracy 0.99926,\n",
    "Train epoch 87, average loss 0.00237569, average accuracy 0.99921,\n",
    "Train epoch 88, average loss 0.00245643, average accuracy 0.99923,\n",
    "Train epoch 89, average loss 0.00226378, average accuracy 0.99937,\n",
    "Train epoch 90, average loss 0.00233121, average accuracy 0.99925,\n",
    "\tDev epoch 90, average loss 0.58426, average accuracy 0.924112,\n",
    "\t\tTime taken for 90 epochs =  3140.9629440307617\n",
    "Train epoch 91, average loss 0.00239393, average accuracy 0.99934,\n",
    "Train epoch 92, average loss 0.00168514, average accuracy 0.99947,\n",
    "Train epoch 93, average loss 0.00218618, average accuracy 0.99934,\n",
    "Train epoch 94, average loss 0.00201177, average accuracy 0.99939,\n",
    "Train epoch 95, average loss 0.00265143, average accuracy 0.99903,\n",
    "\n",
    "\tDev epoch 95, average loss 0.522781, average accuracy 0.927284,\n",
    "Train epoch 96, average loss 0.00200737, average accuracy 0.99945,\n",
    "Train epoch 97, average loss 0.00167531, average accuracy 0.99956,\n",
    "Train epoch 98, average loss 0.00197691, average accuracy 0.99943,\n",
    "Train epoch 99, average loss 0.00189404, average accuracy 0.99943,\n",
    "Train epoch 100, average loss 0.00217102, average accuracy 0.99935,\n",
    "\tDev epoch 100, average loss 0.509596, average accuracy 0.927417,\n",
    "\t\tTime taken for 100 epochs =  3485.5287368297577\n",
    "Train epoch 101, average loss 0.00214391, average accuracy 0.99932,\n",
    "Train epoch 102, average loss 0.00166687, average accuracy 0.99949,\n",
    "Train epoch 103, average loss 0.00193214, average accuracy 0.99941,\n",
    "Train epoch 104, average loss 0.00230417, average accuracy 0.99928,\n",
    "Train epoch 105, average loss 0.00262318, average accuracy 0.99917,\n",
    "\tDev epoch 105, average loss 0.580702, average accuracy 0.924379,\n",
    "Train epoch 106, average loss 0.00217951, average accuracy 0.99936,\n",
    "Train epoch 107, average loss 0.00196965, average accuracy 0.9994,\n",
    "Train epoch 108, average loss 0.00169252, average accuracy 0.99945,\n",
    "Train epoch 109, average loss 0.00184972, average accuracy 0.99937,\n",
    "Train epoch 110, average loss 0.00203432, average accuracy 0.99938,\n",
    "\tDev epoch 110, average loss 0.580674, average accuracy 0.925214,\n",
    "\t\tTime taken for 110 epochs =  3830.0551614761353\n",
    "Train epoch 111, average loss 0.0018848, average accuracy 0.99941,\n",
    "Train epoch 112, average loss 0.001956, average accuracy 0.99934,\n",
    "Train epoch 113, average loss 0.00164951, average accuracy 0.99948,\n",
    "Train epoch 114, average loss 0.00189435, average accuracy 0.99941,\n",
    "Train epoch 115, average loss 0.00179166, average accuracy 0.99939,\n",
    "\tDev epoch 115, average loss 0.541616, average accuracy 0.926282,\n",
    "Train epoch 116, average loss 0.0018286, average accuracy 0.99944,\n",
    "Train epoch 117, average loss 0.00176589, average accuracy 0.99943,\n",
    "Train epoch 118, average loss 0.00170349, average accuracy 0.99947,\n",
    "Train epoch 119, average loss 0.00222146, average accuracy 0.99928,\n",
    "Train epoch 120, average loss 0.00133639, average accuracy 0.99959,\n",
    "\tDev epoch 120, average loss 0.587092, average accuracy 0.926482,\n",
    "\t\tTime taken for 120 epochs =  4174.599865913391\n",
    "Train epoch 121, average loss 0.00179675, average accuracy 0.99939,\n",
    "Train epoch 122, average loss 0.00170493, average accuracy 0.99948,\n",
    "Train epoch 123, average loss 0.00196213, average accuracy 0.99939,\n",
    "Train epoch 124, average loss 0.00148926, average accuracy 0.99953,\n",
    "Train epoch 125, average loss 0.00146297, average accuracy 0.99951,\n",
    "\tDev epoch 125, average loss 0.555345, average accuracy 0.926516,\n",
    "Train epoch 126, average loss 0.00200696, average accuracy 0.99936,\n",
    "Train epoch 127, average loss 0.00152734, average accuracy 0.99952,\n",
    "Train epoch 128, average loss 0.00232658, average accuracy 0.9993,\n",
    "Train epoch 129, average loss 0.00197241, average accuracy 0.99939,\n",
    "Train epoch 130, average loss 0.00210397, average accuracy 0.99924,\n",
    "\tDev epoch 130, average loss 0.670168, average accuracy 0.92291,\n",
    "\t\tTime taken for 130 epochs =  4519.105709552765\n",
    "Train epoch 131, average loss 0.00184804, average accuracy 0.99943,\n",
    "Train epoch 132, average loss 0.00178672, average accuracy 0.99941,\n",
    "Train epoch 133, average loss 0.00175419, average accuracy 0.9994,\n",
    "Train epoch 134, average loss 0.0019224, average accuracy 0.99934,\n",
    "Train epoch 135, average loss 0.00222945, average accuracy 0.99931,\n",
    "\tDev epoch 135, average loss 0.657096, average accuracy 0.923377,\n",
    "Train epoch 136, average loss 0.00175209, average accuracy 0.99934,\n",
    "Train epoch 137, average loss 0.00214912, average accuracy 0.99925,\n",
    "Train epoch 138, average loss 0.00162636, average accuracy 0.99941,\n",
    "Train epoch 139, average loss 0.00180691, average accuracy 0.99946,\n",
    "Train epoch 140, average loss 0.00118666, average accuracy 0.99959,\n",
    "\tDev epoch 140, average loss 0.575778, average accuracy 0.926015,\n",
    "\t\tTime taken for 140 epochs =  4863.487067222595\n",
    "        \n",
    "\n",
    "#### Same as above, with 60 epochs.\n",
    "\n",
    "completed cnn creation\n",
    "Number batches = 1562\n",
    "Train epoch 0, average loss 0.30547, average accuracy 0.87393,\n",
    "\tDev epoch 0, average loss 0.237115, average accuracy 0.904915,\n",
    "\t\tTime taken for 0 epochs =  36.875508308410645\n",
    "Train epoch 3, average loss 0.152626, average accuracy 0.940681,\n",
    "Train epoch 6, average loss 0.0826888, average accuracy 0.96937,\n",
    "\tDev epoch 6, average loss 0.237618, average accuracy 0.921307,\n",
    "Train epoch 9, average loss 0.0498599, average accuracy 0.982274,\n",
    "Train epoch 12, average loss 0.0340667, average accuracy 0.987906,\n",
    "\tDev epoch 12, average loss 0.290549, average accuracy 0.922075,\n",
    "\t\tTime taken for 12 epochs =  449.51883339881897\n",
    "Train epoch 15, average loss 0.0254497, average accuracy 0.991217,\n",
    "Train epoch 18, average loss 0.0187158, average accuracy 0.993648,\n",
    "\tDev epoch 18, average loss 0.306756, average accuracy 0.923945,\n",
    "Train epoch 21, average loss 0.0152883, average accuracy 0.995038,\n",
    "Train epoch 24, average loss 0.0124834, average accuracy 0.995999,\n",
    "\tDev epoch 24, average loss 0.329978, average accuracy 0.926716,\n",
    "\t\tTime taken for 24 epochs =  862.4385898113251\n",
    "Train epoch 27, average loss 0.0112456, average accuracy 0.996409,\n",
    "Train epoch 30, average loss 0.00972575, average accuracy 0.996939,\n",
    "\tDev epoch 30, average loss 0.361886, average accuracy 0.92695,\n",
    "Train epoch 33, average loss 0.00892223, average accuracy 0.997189,\n",
    "Train epoch 36, average loss 0.00712946, average accuracy 0.997789,\n",
    "\tDev epoch 36, average loss 0.381359, average accuracy 0.92685,\n",
    "\t\tTime taken for 36 epochs =  1275.2902917861938\n",
    "Train epoch 39, average loss 0.00628213, average accuracy 0.998139,\n",
    "Train epoch 42, average loss 0.00596454, average accuracy 0.998159,\n",
    "\tDev epoch 42, average loss 0.47203, average accuracy 0.924446,\n",
    "Train epoch 45, average loss 0.00500223, average accuracy 0.9985,\n",
    "Train epoch 48, average loss 0.00469857, average accuracy 0.99864,\n",
    "\tDev epoch 48, average loss 0.401148, average accuracy 0.926749,\n",
    "\t\tTime taken for 48 epochs =  1688.264419078827\n",
    "Train epoch 51, average loss 0.00402232, average accuracy 0.99886,\n",
    "Train epoch 54, average loss 0.00421826, average accuracy 0.99865,\n",
    "\tDev epoch 54, average loss 0.416046, average accuracy 0.928385,\n",
    "Train epoch 57, average loss 0.00368313, average accuracy 0.99893,\n",
    "Train epoch 60, average loss 0.00335348, average accuracy 0.99901,\n",
    "\tDev epoch 60, average loss 0.438822, average accuracy 0.927918,\n",
    "\t\tTime taken for 60 epochs =  2101.384346008301\n",
    "\n",
    "#### With the embeddings set to trainable = false.\n",
    "completed cnn creation\n",
    "# batches = 1562\n",
    "Train epoch 0, average loss 0.304837, average accuracy 0.87436,\n",
    "\t\tDev epoch 0, average loss 0.239171, average accuracy 0.905649,\n",
    "\t\t\t\t    Time taken for 0 epochs =  33.351370334625244\n",
    "Train epoch 3, average loss 0.159725, average accuracy 0.93797,\n",
    "Train epoch 6, average loss 0.0951332, average accuracy 0.963478,\n",
    "\t\tDev epoch 6, average loss 0.222475, average accuracy 0.916299,\n",
    "Train epoch 9, average loss 0.0597436, average accuracy 0.978053,\n",
    "Train epoch 12, average loss 0.0414887, average accuracy 0.985045,\n",
    "\t\tDev epoch 12, average loss 0.258621, average accuracy 0.921708,\n",
    "\t\t\t\t    Time taken for 12 epochs =  405.9028522968292\n",
    "Train epoch 15, average loss 0.03174, average accuracy 0.988536,\n",
    "Train epoch 18, average loss 0.0268379, average accuracy 0.990747,\n",
    "\t\tDev epoch 18, average loss 0.308509, average accuracy 0.922242,\n",
    "Train epoch 21, average loss 0.0237158, average accuracy 0.991737,\n",
    "Train epoch 24, average loss 0.0182942, average accuracy 0.993528,\n",
    "\t\tDev epoch 24, average loss 0.330288, average accuracy 0.922643,\n",
    "\t\t\t\t    Time taken for 24 epochs =  778.5845618247986\n",
    "Train epoch 27, average loss 0.0170312, average accuracy 0.994198,\n",
    "Train epoch 30, average loss 0.0140965, average accuracy 0.994978,\n",
    "\t\tDev epoch 30, average loss 0.389294, average accuracy 0.922476,\n",
    "Train epoch 33, average loss 0.0119405, average accuracy 0.996029,\n",
    "Train epoch 36, average loss 0.0102918, average accuracy 0.996929,\n",
    "\t\tDev epoch 36, average loss 0.390921, average accuracy 0.922943,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1150.900290966034\n",
    "Train epoch 39, average loss 0.00885309, average accuracy 0.997279,\n",
    "Train epoch 42, average loss 0.0098332, average accuracy 0.996869,\n",
    "\t\tDev epoch 42, average loss 0.408098, average accuracy 0.922476,\n",
    "Train epoch 45, average loss 0.00801163, average accuracy 0.997559,\n",
    "Train epoch 48, average loss 0.0075703, average accuracy 0.997559,\n",
    "\t\tDev epoch 48, average loss 0.405061, average accuracy 0.920339,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1523.076869726181\n",
    "Train epoch 51, average loss 0.00815841, average accuracy 0.997429,\n",
    "Train epoch 54, average loss 0.00750207, average accuracy 0.997439,\n",
    "\t\tDev epoch 54, average loss 0.411605, average accuracy 0.922109,\n",
    "Train epoch 57, average loss 0.00687906, average accuracy 0.997739,\n",
    "Train epoch 60, average loss 0.00724441, average accuracy 0.997749,\n",
    "\t\tDev epoch 60, average loss 0.513384, average accuracy 0.920039,\n",
    "\t\t\t\t    Time taken for 60 epochs =  1895.2125108242035\n",
    "                    \n",
    " #### embedding dim = 50. trainable = tur\n",
    " Writing to /home/ubuntu/W266Project/final_project/runs/cnn\n",
    "\n",
    "completed cnn creation\n",
    "# batches = 1562\n",
    "Train epoch 0, average loss 0.344391, average accuracy 0.857604,\n",
    "\t\tDev epoch 0, average loss 0.289542, average accuracy 0.875501,\n",
    "\t\t\t\t    Time taken for 0 epochs =  32.877453088760376\n",
    "Train epoch 3, average loss 0.205036, average accuracy 0.915813,\n",
    "Train epoch 6, average loss 0.143437, average accuracy 0.943792,\n",
    "\t\tDev epoch 6, average loss 0.245589, average accuracy 0.913261,\n",
    "Train epoch 9, average loss 0.10241, average accuracy 0.960037,\n",
    "Train epoch 12, average loss 0.0766644, average accuracy 0.970851,\n",
    "\t\tDev epoch 12, average loss 0.256715, average accuracy 0.918636,\n",
    "\t\t\t\t    Time taken for 12 epochs =  357.13569045066833\n",
    "Train epoch 15, average loss 0.0596088, average accuracy 0.978213,\n",
    "Train epoch 18, average loss 0.0488154, average accuracy 0.982314,\n",
    "\t\tDev epoch 18, average loss 0.298308, average accuracy 0.917835,\n",
    "Train epoch 21, average loss 0.0426194, average accuracy 0.984715,\n",
    "Train epoch 24, average loss 0.0340587, average accuracy 0.988276,\n",
    "\t\tDev epoch 24, average loss 0.324277, average accuracy 0.920339,\n",
    "\t\t\t\t    Time taken for 24 epochs =  681.0641686916351\n",
    "Train epoch 27, average loss 0.0312987, average accuracy 0.989157,\n",
    "Train epoch 30, average loss 0.0283847, average accuracy 0.990167,\n",
    "\t\tDev epoch 30, average loss 0.374785, average accuracy 0.92261,\n",
    "Train epoch 33, average loss 0.0240973, average accuracy 0.991917,\n",
    "Train epoch 36, average loss 0.0231575, average accuracy 0.992087,\n",
    "\t\tDev epoch 36, average loss 0.372793, average accuracy 0.922175,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1004.7895133495331\n",
    "Train epoch 39, average loss 0.0181793, average accuracy 0.993778,\n",
    "Train epoch 42, average loss 0.0158069, average accuracy 0.994878,\n",
    "\t\tDev epoch 42, average loss 0.394058, average accuracy 0.917535,\n",
    "Train epoch 45, average loss 0.0152652, average accuracy 0.994888,\n",
    "Train epoch 48, average loss 0.0122295, average accuracy 0.995979,\n",
    "\t\tDev epoch 48, average loss 0.415253, average accuracy 0.917601,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1328.6486732959747\n",
    "Train epoch 51, average loss 0.0120298, average accuracy 0.996009,\n",
    "Train epoch 54, average loss 0.0118266, average accuracy 0.996119,\n",
    "\t\tDev epoch 54, average loss 0.413061, average accuracy 0.922443,\n",
    "        \n",
    "#### increased embedding size to 200\n",
    "\n",
    "Train epoch 0, average loss 0.286025, average accuracy 0.882512,\n",
    "\t\tDev epoch 0, average loss 0.238953, average accuracy 0.901142,\n",
    "\t\t\t\t    Time taken for 0 epochs =  110.49707412719727\n",
    "Train epoch 3, average loss 0.115594, average accuracy 0.956656,\n",
    "Train epoch 6, average loss 0.0497285, average accuracy 0.982724,\n",
    "\t\tDev epoch 6, average loss 0.225743, average accuracy 0.929988,\n",
    "Train epoch 9, average loss 0.0273755, average accuracy 0.990967,\n",
    "Train epoch 12, average loss 0.0186573, average accuracy 0.993748,\n",
    "\t\tDev epoch 12, average loss 0.281195, average accuracy 0.931424,\n",
    "\t\t\t\t    Time taken for 12 epochs =  803.1010024547577\n",
    "Train epoch 15, average loss 0.0134854, average accuracy 0.995819,\n",
    "Train epoch 18, average loss 0.0100261, average accuracy 0.997069,\n",
    "\t\tDev epoch 18, average loss 0.315512, average accuracy 0.930188,\n",
    "Train epoch 21, average loss 0.00782281, average accuracy 0.997709,\n",
    "Train epoch 24, average loss 0.00664231, average accuracy 0.998049,\n",
    "\t\tDev epoch 24, average loss 0.325848, average accuracy 0.930288,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1495.02197265625\n",
    "Train epoch 27, average loss 0.0047185, average accuracy 0.9988,\n",
    "Train epoch 30, average loss 0.00426745, average accuracy 0.99881,\n",
    "\t\tDev epoch 30, average loss 0.402758, average accuracy 0.92892,\n",
    "Train epoch 33, average loss 0.00427015, average accuracy 0.99867,\n",
    "Train epoch 36, average loss 0.00313919, average accuracy 0.99917,\n",
    "\t\tDev epoch 36, average loss 0.364247, average accuracy 0.931858,\n",
    "\t\t\t\t    Time taken for 36 epochs =  2186.8154296875\n",
    "Train epoch 39, average loss 0.00310154, average accuracy 0.99915,\n",
    "Train epoch 42, average loss 0.00245393, average accuracy 0.99941,\n",
    "\t\tDev epoch 42, average loss 0.430721, average accuracy 0.930255,\n",
    "        \n",
    "#### decreased embedding size to 100, and reduced number of filters to 128 per filter size.\n",
    "\n",
    "# batches = 1562\n",
    "Train epoch 0, average loss 0.324282, average accuracy 0.864767,\n",
    "\t\tDev epoch 0, average loss 0.247642, average accuracy 0.896368,\n",
    "\t\t\t\t    Time taken for 0 epochs =  31.22071099281311\n",
    "Train epoch 3, average loss 0.170937, average accuracy 0.932518,\n",
    "Train epoch 6, average loss 0.111375, average accuracy 0.956436,\n",
    "\t\tDev epoch 6, average loss 0.215396, average accuracy 0.916533,\n",
    "Train epoch 9, average loss 0.0755983, average accuracy 0.971181,\n",
    "Train epoch 12, average loss 0.0536806, average accuracy 0.980444,\n",
    "\t\tDev epoch 12, average loss 0.272522, average accuracy 0.921541,\n",
    "\t\t\t\t    Time taken for 12 epochs =  300.37999510765076\n",
    "Train epoch 15, average loss 0.0438895, average accuracy 0.983705,\n",
    "Train epoch 18, average loss 0.0348257, average accuracy 0.987456,\n",
    "\t\tDev epoch 18, average loss 0.311513, average accuracy 0.922676,\n",
    "Train epoch 21, average loss 0.0279689, average accuracy 0.990087,\n",
    "Train epoch 24, average loss 0.025247, average accuracy 0.990957,\n",
    "\t\tDev epoch 24, average loss 0.341999, average accuracy 0.923811,\n",
    "\t\t\t\t    Time taken for 24 epochs =  569.6881365776062\n",
    "Train epoch 27, average loss 0.0203997, average accuracy 0.992968,\n",
    "Train epoch 30, average loss 0.0187122, average accuracy 0.993508,\n",
    "\t\tDev epoch 30, average loss 0.357159, average accuracy 0.923811,\n",
    "Train epoch 33, average loss 0.0158869, average accuracy 0.994488,\n",
    "Train epoch 36, average loss 0.0158628, average accuracy 0.994568,\n",
    "\t\tDev epoch 36, average loss 0.371735, average accuracy 0.92311,\n",
    "\t\t\t\t    Time taken for 36 epochs =  838.69158244133\n",
    "Train epoch 39, average loss 0.0133922, average accuracy 0.995659,\n",
    "Train epoch 42, average loss 0.0127672, average accuracy 0.995709,\n",
    "\t\tDev epoch 42, average loss 0.402635, average accuracy 0.92498,\n",
    "Train epoch 45, average loss 0.0119068, average accuracy 0.996049,\n",
    "Train epoch 48, average loss 0.0107565, average accuracy 0.996499,\n",
    "\t\tDev epoch 48, average loss 0.419966, average accuracy 0.92478,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1107.9437527656555\n",
    "Train epoch 51, average loss 0.0100834, average accuracy 0.996689,\n",
    "Train epoch 54, average loss 0.00994073, average accuracy 0.996889,\n",
    "\t\tDev epoch 54, average loss 0.41175, average accuracy 0.924245,\n",
    "Train epoch 57, average loss 0.00979135, average accuracy 0.996649,\n",
    "Train epoch 60, average loss 0.00821928, average accuracy 0.997469,\n",
    "\t\tDev epoch 60, average loss 0.469267, average accuracy 0.926115,\n",
    "\t\t\t\t    Time taken for 60 epochs =  1377.0541887283325\n",
    "                    \n",
    " #### increased number of filters to 512 per filter size.\n",
    " \n",
    " Train epoch 0, average loss 0.311692, average accuracy 0.870288,\n",
    "\t\tDev epoch 0, average loss 0.242969, average accuracy 0.896701,\n",
    "\t\t\t\t    Time taken for 0 epochs =  84.6077299118042\n",
    "Train epoch 3, average loss 0.142796, average accuracy 0.944482,\n",
    "Train epoch 6, average loss 0.0668666, average accuracy 0.975692,\n",
    "\t\tDev epoch 6, average loss 0.210706, average accuracy 0.924913,\n",
    "Train epoch 9, average loss 0.0342145, average accuracy 0.988336,\n",
    "Train epoch 12, average loss 0.0224968, average accuracy 0.992708,\n",
    "\t\tDev epoch 12, average loss 0.274663, average accuracy 0.926916,\n",
    "\t\t\t\t    Time taken for 12 epochs =  809.0257966518402\n",
    "Train epoch 15, average loss 0.0171242, average accuracy 0.994098,\n",
    "Train epoch 18, average loss 0.0118646, average accuracy 0.996329,\n",
    "\t\tDev epoch 18, average loss 0.302414, average accuracy 0.928218,\n",
    "Train epoch 21, average loss 0.0098251, average accuracy 0.996879,\n",
    "Train epoch 24, average loss 0.0067338, average accuracy 0.998029,\n",
    "\t\tDev epoch 24, average loss 0.331184, average accuracy 0.927985,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1532.959394454956\n",
    "Train epoch 27, average loss 0.00506558, average accuracy 0.99858,\n",
    "Train epoch 30, average loss 0.00396653, average accuracy 0.99893,\n",
    "\t\tDev epoch 30, average loss 0.343347, average accuracy 0.928352,\n",
    "Train epoch 33, average loss 0.00384556, average accuracy 0.99898,\n",
    "Train epoch 36, average loss 0.0030804, average accuracy 0.99932,\n",
    "\t\tDev epoch 36, average loss 0.373929, average accuracy 0.928552,\n",
    "\t\t\t\t    Time taken for 36 epochs =  2256.9254744052887\n",
    "Train epoch 39, average loss 0.00246744, average accuracy 0.99933,\n",
    "Train epoch 42, average loss 0.00211266, average accuracy 0.9996,\n",
    "\t\tDev epoch 42, average loss 0.361598, average accuracy 0.929053,\n",
    "Train epoch 45, average loss 0.00217611, average accuracy 0.99941,\n",
    "Train epoch 48, average loss 0.00197936, average accuracy 0.99955,\n",
    "\t\tDev epoch 48, average loss 0.391054, average accuracy 0.929754,\n",
    "\t\t\t\t    Time taken for 48 epochs =  2980.909019947052\n",
    "Train epoch 51, average loss 0.00187027, average accuracy 0.99957,\n",
    "Train epoch 54, average loss 0.00191055, average accuracy 0.99958,\n",
    "\t\tDev epoch 54, average loss 0.378678, average accuracy 0.92685,\n",
    "Train epoch 57, average loss 0.00153142, average accuracy 0.99968,\n",
    "Train epoch 60, average loss 0.00134926, average accuracy 0.99974,\n",
    "\t\tDev epoch 60, average loss 0.405928, average accuracy 0.929854,\n",
    "\t\t\t\t    Time taken for 60 epochs =  3704.6175475120544\n",
    "                    \n",
    "completed cnn creation\n",
    "#### added a filter for length 6. so filter sizes became (3,4,5,6). \n",
    "Train epoch 0, average loss 0.315134, average accuracy 0.868868,\n",
    "\t\tDev epoch 0, average loss 0.248855, average accuracy 0.89353,\n",
    "\t\t\t\t    Time taken for 0 epochs =  69.76286554336548\n",
    "Train epoch 3, average loss 0.149292, average accuracy 0.942482,\n",
    "Train epoch 6, average loss 0.072978, average accuracy 0.973211,\n",
    "\t\tDev epoch 6, average loss 0.220149, average accuracy 0.921908,\n",
    "Train epoch 9, average loss 0.0399216, average accuracy 0.985855,\n",
    "Train epoch 12, average loss 0.0274265, average accuracy 0.990367,\n",
    "\t\tDev epoch 12, average loss 0.321294, average accuracy 0.922342,\n",
    "\t\t\t\t    Time taken for 12 epochs =  666.9912831783295\n",
    "Train epoch 15, average loss 0.0199664, average accuracy 0.993398,\n",
    "Train epoch 18, average loss 0.0145588, average accuracy 0.995429,\n",
    "\t\tDev epoch 18, average loss 0.30958, average accuracy 0.921341,\n",
    "Train epoch 21, average loss 0.011635, average accuracy 0.996449,\n",
    "Train epoch 24, average loss 0.00927037, average accuracy 0.997119,\n",
    "\t\tDev epoch 24, average loss 0.352559, average accuracy 0.926449,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1264.2059795856476\n",
    "Train epoch 27, average loss 0.00758558, average accuracy 0.997789,\n",
    "Train epoch 30, average loss 0.0056179, average accuracy 0.998409,\n",
    "\t\tDev epoch 30, average loss 0.385125, average accuracy 0.926749,\n",
    "Train epoch 33, average loss 0.0049369, average accuracy 0.99856,\n",
    "Train epoch 36, average loss 0.00391196, average accuracy 0.99882,\n",
    "\t\tDev epoch 36, average loss 0.369655, average accuracy 0.926482,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1861.2735829353333\n",
    "Train epoch 39, average loss 0.00425983, average accuracy 0.99884,\n",
    "Train epoch 42, average loss 0.00378442, average accuracy 0.99898,\n",
    "\t\tDev epoch 42, average loss 0.386586, average accuracy 0.926883,\n",
    "Train epoch 45, average loss 0.00346757, average accuracy 0.99902,\n",
    "Train epoch 48, average loss 0.00338043, average accuracy 0.99902,\n",
    "\t\tDev epoch 48, average loss 0.395295, average accuracy 0.927784,\n",
    "\t\t\t\t    Time taken for 48 epochs =  2458.481989145279\n",
    "Train epoch 51, average loss 0.00368297, average accuracy 0.99901,\n",
    "Train epoch 54, average loss 0.00253086, average accuracy 0.99935,\n",
    "\t\tDev epoch 54, average loss 0.410479, average accuracy 0.92685,\n",
    "Train epoch 57, average loss 0.00307247, average accuracy 0.99915,\n",
    "Train epoch 60, average loss 0.00267205, average accuracy 0.99934,\n",
    "\t\tDev epoch 60, average loss 0.449313, average accuracy 0.926215,\n",
    "\t\t\t\t    Time taken for 60 epochs =  3055.6355838775635 \n",
    "                    \n",
    "                    \n",
    "#### With random shuffle added for batches.\n",
    "Train epoch 0, average loss 0.315134, average accuracy 0.868868,\n",
    "\t\tDev epoch 0, average loss 0.248855, average accuracy 0.89353,\n",
    "\t\t\t\t    Time taken for 0 epochs =  69.76286554336548\n",
    "Train epoch 3, average loss 0.149292, average accuracy 0.942482,\n",
    "Train epoch 6, average loss 0.072978, average accuracy 0.973211,\n",
    "\t\tDev epoch 6, average loss 0.220149, average accuracy 0.921908,\n",
    "Train epoch 9, average loss 0.0399216, average accuracy 0.985855,\n",
    "Train epoch 12, average loss 0.0274265, average accuracy 0.990367,\n",
    "\t\tDev epoch 12, average loss 0.321294, average accuracy 0.922342,\n",
    "\t\t\t\t    Time taken for 12 epochs =  666.9912831783295\n",
    "Train epoch 15, average loss 0.0199664, average accuracy 0.993398,\n",
    "Train epoch 18, average loss 0.0145588, average accuracy 0.995429,\n",
    "\t\tDev epoch 18, average loss 0.30958, average accuracy 0.921341,\n",
    "Train epoch 21, average loss 0.011635, average accuracy 0.996449,\n",
    "Train epoch 24, average loss 0.00927037, average accuracy 0.997119,\n",
    "\t\tDev epoch 24, average loss 0.352559, average accuracy 0.926449,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1264.2059795856476\n",
    "Train epoch 27, average loss 0.00758558, average accuracy 0.997789,\n",
    "Train epoch 30, average loss 0.0056179, average accuracy 0.998409,\n",
    "\t\tDev epoch 30, average loss 0.385125, average accuracy 0.926749,\n",
    "Train epoch 33, average loss 0.0049369, average accuracy 0.99856,\n",
    "Train epoch 36, average loss 0.00391196, average accuracy 0.99882,\n",
    "\t\tDev epoch 36, average loss 0.369655, average accuracy 0.926482,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1861.2735829353333\n",
    "Train epoch 39, average loss 0.00425983, average accuracy 0.99884,\n",
    "Train epoch 42, average loss 0.00378442, average accuracy 0.99898,\n",
    "\t\tDev epoch 42, average loss 0.386586, average accuracy 0.926883,\n",
    "Train epoch 45, average loss 0.00346757, average accuracy 0.99902,\n",
    "Train epoch 48, average loss 0.00338043, average accuracy 0.99902,\n",
    "\t\tDev epoch 48, average loss 0.395295, average accuracy 0.927784,\n",
    "\t\t\t\t    Time taken for 48 epochs =  2458.481989145279\n",
    "Train epoch 51, average loss 0.00368297, average accuracy 0.99901,\n",
    "Train epoch 54, average loss 0.00253086, average accuracy 0.99935,\n",
    "\t\tDev epoch 54, average loss 0.410479, average accuracy 0.92685,\n",
    "Train epoch 57, average loss 0.00307247, average accuracy 0.99915,\n",
    "Train epoch 60, average loss 0.00267205, average accuracy 0.99934,\n",
    "\t\tDev epoch 60, average loss 0.449313, average accuracy 0.926215,\n",
    "\t\t\t\t    Time taken for 60 epochs =  3055.6355838775635"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
