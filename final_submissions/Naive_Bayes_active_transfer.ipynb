{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import time\n",
    "# Install a few python packages using pip\n",
    "from common import utils\n",
    "utils.require_package('nltk')\n",
    "utils.require_package(\"wget\")      # for fetching dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/arunima/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys, time\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "# Numerical manipulation libraries.\n",
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Helper libraries\n",
    "from common import utils, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to read the amazon review data files\n",
    "def parse(path):\n",
    "  print('start parse')\n",
    "  start_parse = time.time()\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "  end_parse = time.time()\n",
    "  print('end parse with time for parse',end_parse - start_parse)\n",
    "\n",
    "def getDF(path):\n",
    "  print('start getDF')\n",
    "  start = time.time()\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  print('end getDF')\n",
    "  end = time.time()\n",
    "  print('time taken to load data = ',end-start)\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "#df = getDF('reviews_Toys_and_Games.json.gz') #old def function corresponding to the step bt step vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 73.59540629386902\n",
      "end getDF\n",
      "time taken to load data =  73.5960955619812\n",
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 110.84520721435547\n",
      "end getDF\n",
      "time taken to load data =  110.8455376625061\n"
     ]
    }
   ],
   "source": [
    "df_vid = getDF('reviews_Video_Games.json.gz')\n",
    "df_toys = getDF('reviews_Toys_and_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 63.26358103752136\n",
      "end getDF\n",
      "time taken to load data =  63.26383972167969\n"
     ]
    }
   ],
   "source": [
    "df_aut = getDF('reviews_Automotive.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 213.63618445396423\n",
      "end getDF\n",
      "time taken to load data =  213.63676929473877\n"
     ]
    }
   ],
   "source": [
    "df_hnk = getDF('reviews_Home_and_Kitchen.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Looking at a few exampls of the data.\n",
    "# print('\\n Toys reviews summary')\n",
    "# print(df_toys.shape)\n",
    "# print(df_toys.columns)\n",
    "# print(df_toys.head(3))\n",
    "# print('\\n Video games reviews summary')\n",
    "# print(df_vid.shape)\n",
    "# print(df_vid.columns)\n",
    "# print(df_vid.head(3))\n",
    "# print('\\n Auto reviews summary')\n",
    "# print(df_aut.shape)\n",
    "# print(df_aut.columns)\n",
    "# print(df_aut.head(3))\n",
    "# print('\\n Home and Kitchen reviews summary')\n",
    "# print(df_hnk.shape)\n",
    "# print(df_hnk.columns)\n",
    "# print(df_hnk.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings distribution for toys          reviewerID     asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                    \n",
      "1.0          192993   192993        192435   192993      192993   192993   \n",
      "2.0          115801   115801        115416   115801      115801   115801   \n",
      "3.0          193941   193941        193195   193941      193941   193941   \n",
      "4.0          407884   407884        406255   407884      407884   407884   \n",
      "5.0         1342152  1342152       1333623  1342152     1342152  1342152   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              192993      192993  \n",
      "2.0              115801      115801  \n",
      "3.0              193941      193941  \n",
      "4.0              407884      407884  \n",
      "5.0             1342152     1342152  \n",
      "\n",
      " Ratings distribution for video games          reviewerID    asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                   \n",
      "1.0          152840  152840        149509   152840      152840   152840   \n",
      "2.0           77513   77513         76692    77513       77513    77513   \n",
      "3.0          124370  124370        122959   124370      124370   124370   \n",
      "4.0          260260  260260        256782   260260      260260   260260   \n",
      "5.0          709770  709770        692626   709770      709770   709770   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              152840      152840  \n",
      "2.0               77513       77513  \n",
      "3.0              124370      124370  \n",
      "4.0              260260      260260  \n",
      "5.0              709770      709770  \n",
      "\n",
      " Ratings distribution for automobiles          reviewerID    asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                   \n",
      "1.0          122160  122160        121495   122160      122160   122160   \n",
      "2.0           64112   64112         63784    64112       64112    64112   \n",
      "3.0          103857  103857        103222   103857      103857   103857   \n",
      "4.0          230293  230293        228871   230293      230293   230293   \n",
      "5.0          853346  853346        847959   853346      853346   853346   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              122160      122160  \n",
      "2.0               64112       64112  \n",
      "3.0              103857      103857  \n",
      "4.0              230293      230293  \n",
      "5.0              853346      853346  \n",
      "\n",
      " Ratings distribution for home and kitchen          reviewerID     asin  reviewerName  helpful  reviewText  summary  \\\n",
      "overall                                                                    \n",
      "1.0          418381   418381        416013   418381      418381   418381   \n",
      "2.0          242048   242048        240272   242048      242048   242048   \n",
      "3.0          345094   345094        342420   345094      345094   345094   \n",
      "4.0          740864   740864        734679   740864      740864   740864   \n",
      "5.0         2507539  2507539       2487340  2507539     2507539  2507539   \n",
      "\n",
      "         unixReviewTime  reviewTime  \n",
      "overall                              \n",
      "1.0              418381      418381  \n",
      "2.0              242048      242048  \n",
      "3.0              345094      345094  \n",
      "4.0              740864      740864  \n",
      "5.0             2507539     2507539  \n"
     ]
    }
   ],
   "source": [
    "#Count by ratings to determine skew in sample.\n",
    "print('Ratings distribution for toys',df_toys.groupby('overall').count())\n",
    "print('\\n Ratings distribution for video games',df_vid.groupby('overall').count())\n",
    "print('\\n Ratings distribution for automobiles',df_aut.groupby('overall').count())\n",
    "print('\\n Ratings distribution for home and kitchen',df_hnk.groupby('overall').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toys reviews examples\n",
      "\n",
      "AMEVO2LY6VEJA\n",
      "Great product, thank you! Our son loved the puzzles.  They have large pieces yet they are still challenging for a 4 year old.\n",
      "\n",
      " Video games reviews examples\n",
      "\n",
      "AB9S9279OZ3QO\n",
      "I haven't gotten around to playing the campaign but the multiplayer is solid and pretty fun. Includes Zero Dark Thirty pack, an Online Pass, and the all powerful Battlefield 4 Beta access.\n",
      "A24SSUT5CSW8BH\n",
      "I want to start off by saying I have never played the Call of Duty games. This is only the second first person shooter game that I have own. I think it is a lot of fun. Has good graphics and nice story line. It does take some skill to get through the levels. I think all players can enjoy this game. There are three levels to choose from based on your skill level. If your looking for first person shooter game that has current military type play than this is a good buy.\n",
      "AK3V0HEBJMQ7J\n",
      "this will be my second medal of honor I love how the incorporate real life military stories in the game great\n",
      "\n",
      " Automobile reviews examples\n",
      "\n",
      "A108J5O7DG2WIM\n",
      "I loved the look and the great improvement at night drivingA bit expensive but work great.Installation took me about 3 hours.\n",
      "A1QBLUSZW281TA\n",
      "Put these on my 2011 can am outlander 800xt, easy to install, and being oem everything just plugged right in , even like the power switch they came with\n",
      "A3B40ZIZJ3HEP7\n",
      "Don't buy this item  , its not a 4 window roll up , its look nothing like the picture , they sent me some crap,  and the seller is charging me 20 % restocking fee plus I have to pay for shipping , I will never buy from them again , YOU HAVE BEEN WARNED ...\n",
      "\n",
      " Home and Kitchen reviews examples\n",
      "\n",
      "A210NOCSTBT4OD\n",
      "Have you ever thought about how you met your best friend? Was it normal, or was it wacky - like how Elias met Shohei? Pulling a boa constrictor snake named Mathilda out of your backpack can make a remarkable first impression! This book is about three best friends Elias, Honoria, and Shohei, who are united against \"That Which Is The Peshtigo School\". Their goal is to make it through the annual school science fair, but things don't always go as planned.Elias is part of a family made up of science fanatics who would do anything to win a science fair. Elias isn't exactly what you'd call the ambitious type, especially when it comes to science fairs. So he becomes like Galileo and \"retests\" one of his sibling's past projects. Honoria loves to be ambitious, especially when it comes to being a legal counsel extraordinaire. But when she faces a bigger challenge than beating Goliath Reed or getting a piranha to become vegetarian, she doesn't know if she can make it. Shohei is an all around slacker who tries to mooch off Elias instead of creating something on his own. His adoptive parents are constantly encouraging him to start \"hearing\" his ancestors. His mom has even turned Shohei's room into what looks like a walk-in Japanese museum exhibit!This book is laugh out loud hilarious and the more you read, the more exciting and unexpected it gets. I love the title on this book because it really made me laugh and want to read the book. I also like how people so different from one another can be such close friends. There is not much excitement in the beginning, but it builds up very quickly. So if you like that type of story, then this is the book for you.\n",
      "A28ILV4TOG8BH2\n",
      "The butter dish is serving us well, and keeping the butter fresh and healthy. Couldn't be happier with it, and the color is a pleasing green.\n",
      "A31B4D7URW4DNZ\n",
      "I anxiously waited for the book I had pre ordered.  Pics were beautiful, but...If you don't want a cake with fondant your pretty much out of luck. As most guests want something yummy to eat as well as pleasing to the eye, fondant just doesn't do it.  Sure it holds color better and makes a great presentation, it just isn't a pleaseing thing to eat.We did take away some ideas, we did use some fondant flowers on the lower layers (least likely to be eaten), and used butterccream for the really good and most enjoyed layers.Good Job Martha, maybe next time you could show how to make butter cream just as attractive as fondant.MOTB\n"
     ]
    }
   ],
   "source": [
    "#Looking at a few examples of review text\n",
    "print('Toys reviews examples\\n')\n",
    "for i in range(1):\n",
    "    print(df_toys['reviewerID'].iloc[i])\n",
    "    print(df_toys['reviewText'].iloc[i])\n",
    "\n",
    "print('\\n Video games reviews examples\\n')\n",
    "for i in range(3):\n",
    "    print(df_vid['reviewerID'].iloc[i])\n",
    "    print(df_vid['reviewText'].iloc[i])\n",
    "    \n",
    "print('\\n Automobile reviews examples\\n')\n",
    "for i in range(3):\n",
    "    print(df_aut['reviewerID'].iloc[i])\n",
    "    print(df_aut['reviewText'].iloc[i])\n",
    "    \n",
    "print('\\n Home and Kitchen reviews examples\\n')\n",
    "for i in range(3):\n",
    "    print(df_hnk['reviewerID'].iloc[i])\n",
    "    print(df_hnk['reviewText'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Summary metrics for Toy reviews\n",
      "Total \n",
      "\tCount of unique products: 327698 \n",
      "\tSum of their reviews 2252771\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 68782 Percentage of total 21%\n",
      "\tSum of their reviews 1775109 Percentage of total 79%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 19992 Percentage of total 6%\n",
      "\tSum of their reviews 1275698 Percentage of total 57%\n",
      "\n",
      "Additional Summary metrics for Video Games reviews\n",
      "Total \n",
      "\tCount of unique products: 50210 \n",
      "\tSum of their reviews 1324753\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 23866 Percentage of total 48%\n",
      "\tSum of their reviews 1266698 Percentage of total 96%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 10904 Percentage of total 22%\n",
      "\tSum of their reviews 1124236 Percentage of total 85%\n",
      "\n",
      "Additional Summary metrics for Auto reviews\n",
      "Total \n",
      "\tCount of unique products: 320112 \n",
      "\tSum of their reviews 1373768\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 42052 Percentage of total 13%\n",
      "\tSum of their reviews 912369 Percentage of total 66%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 10218 Percentage of total 3%\n",
      "\tSum of their reviews 593687 Percentage of total 43%\n",
      "\n",
      "Additional Summary metrics for Home and Kitchen reviews\n",
      "Total \n",
      "\tCount of unique products: 410243 \n",
      "\tSum of their reviews 4253926\n",
      "Total with at least 5 reviews \n",
      "\tCount of unique products: 94181 Percentage of total 23%\n",
      "\tSum of their reviews 3688295 Percentage of total 87%\n",
      "Total with at least 20 reviews \n",
      "\tCount of unique products: 34140 Percentage of total 8%\n",
      "\tSum of their reviews 3061647 Percentage of total 72%\n"
     ]
    }
   ],
   "source": [
    "#Get the count by unique product id, and % of products and reviews left if we limit to products with at least X reviews\n",
    "def product_skew(df):\n",
    "    tempcnt = df.groupby('asin').size().reset_index()\n",
    "    cnt_total = tempcnt.count()[1]\n",
    "    sum_total = tempcnt.iloc[:,1].sum()\n",
    "    cnt_5 = tempcnt[tempcnt.iloc[:,1] > 5].count()[1]\n",
    "    sum_5 = tempcnt[tempcnt.iloc[:,1] > 5].sum()[1]\n",
    "    cnt_20 = tempcnt[tempcnt.iloc[:,1] > 20].count()[1]\n",
    "    sum_20 = tempcnt[tempcnt.iloc[:,1] > 20].sum()[1]\n",
    "    print('Total','\\n\\tCount of unique products:',cnt_total,'\\n\\tSum of their reviews',sum_total)\n",
    "    print('Total with at least 5 reviews','\\n\\tCount of unique products:',cnt_5,'Percentage of total {0:.0f}%'.format(cnt_5*100/cnt_total))\n",
    "    print('\\tSum of their reviews',sum_5,'Percentage of total {0:.0f}%'.format(sum_5*100/sum_total))\n",
    "    print('Total with at least 20 reviews','\\n\\tCount of unique products:',cnt_20,'Percentage of total {0:.0f}%'.format(cnt_20*100/cnt_total))\n",
    "    print('\\tSum of their reviews',sum_20,'Percentage of total {0:.0f}%'.format(sum_20*100/sum_total))\n",
    "    return\n",
    "\n",
    "print('Additional Summary metrics for Toy reviews')\n",
    "product_skew(df_toys)\n",
    "\n",
    "print('\\nAdditional Summary metrics for Video Games reviews')\n",
    "product_skew(df_vid)\n",
    "\n",
    "print('\\nAdditional Summary metrics for Auto reviews')\n",
    "product_skew(df_aut)\n",
    "\n",
    "print('\\nAdditional Summary metrics for Home and Kitchen reviews')\n",
    "product_skew(df_hnk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy reviews train, dev and test set dataframe shape: (1351662, 9) (450554, 9) (450555, 9)\n",
      "Video games reviews train, dev and test set dataframe shape: (794851, 9) (264951, 9) (264951, 9)\n",
      "Auto reviews train, dev and test set dataframe shape: (824260, 9) (274754, 9) (274754, 9)\n",
      "Home and Kitchen reviews train, dev and test set dataframe shape: (2552355, 9) (850785, 9) (850786, 9)\n"
     ]
    }
   ],
   "source": [
    "#Create train,dev,test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_toys,devtest = train_test_split(df_toys, test_size=0.4,random_state=42)\n",
    "dev_toys,test_toys = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Toy reviews train, dev and test set dataframe shape:',train_toys.shape,dev_toys.shape,test_toys.shape)\n",
    "\n",
    "#For Video games reviews\n",
    "train_vid,devtest = train_test_split(df_vid, test_size=0.4,random_state=42)\n",
    "dev_vid,test_vid = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Video games reviews train, dev and test set dataframe shape:',train_vid.shape,dev_vid.shape,test_vid.shape)\n",
    "\n",
    "#For Auto reviews\n",
    "train_aut,devtest = train_test_split(df_aut, test_size=0.4,random_state=42)\n",
    "dev_aut,test_aut = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Auto reviews train, dev and test set dataframe shape:',train_aut.shape,dev_aut.shape,test_aut.shape)\n",
    "\n",
    "#For Home and Kitchen reviews\n",
    "train_hnk,devtest = train_test_split(df_hnk, test_size=0.4,random_state=42)\n",
    "dev_hnk,test_hnk = train_test_split(devtest,test_size = 0.5,random_state=42)\n",
    "print('Home and Kitchen reviews train, dev and test set dataframe shape:',train_hnk.shape,dev_hnk.shape,test_hnk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create a smaller sized train and dev data set. Enables testing accuracy for different sizes.\n",
    "#Also binarizes the labels. Ratings of 1,2 set to 0; Ratings of 4,5 to 1.\n",
    "\n",
    "def set_df_size(size,data_train,data_dev):\n",
    "    size_train = size\n",
    "    len_max_train = data_train[data_train.overall!=3].shape[0] #max possible length of train data set taking out the 3 ratings.\n",
    "    #print(\"Number of reviews with ratings != 3 in train set\",len_max_train)\n",
    "    temp_size_train = min(len_max_train,size_train)\n",
    "\n",
    "    len_max_dev = data_dev[data_dev.overall!=3].shape[0]\n",
    "    #print(\"Number of reviews with ratings != 3 in dev set\",len_max_dev)\n",
    "    temp_size_dev = min(len_max_dev,int(0.3*temp_size_train)) #making the dev set about 0.3 times the train set.\n",
    "\n",
    "    temp_train_data = data_train[data_train.overall != 3][:temp_size_train]\n",
    "    #print('Size of train data',temp_train_data.shape)\n",
    "    #print(temp_train_data.groupby('overall').count())\n",
    "    #print(temp_train_toys[:5])\n",
    "\n",
    "    temp_dev_data = data_dev[data_dev.overall!=3][:temp_size_dev]\n",
    "    #print('Size of dev data',temp_dev_data.shape)\n",
    "    #print(temp_dev_data.groupby('overall').count())\n",
    "    #print(temp_dev_data[:2])\n",
    "    \n",
    "    #Binarize ratings\n",
    "    temp_train_y = np.zeros(temp_size_train)\n",
    "    temp_train_y[temp_train_data.overall > 3] = 1\n",
    "    temp_dev_y = np.zeros(temp_size_dev)\n",
    "    temp_dev_y[temp_dev_data.overall>3] = 1\n",
    "    #print('binarized y shape',temp_train_y.shape,temp_dev_y.shape)\n",
    "    #print(temp_dev_y[:20],data_dev.overall[:20])\n",
    "    return temp_train_data,temp_dev_data,temp_train_y,temp_dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_df = ['toys','vid','aut','hnk'] #list of keys that refer to each dataframe. Adding a new dataframe would require updating this list\n",
    "dict_train_df = {} #Dict to store train input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_dev_df = {} #Dict to store dev input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_train_y = {} #Dict to store binarized train data label for each domain\n",
    "dict_dev_y = {} #Dict to store binarized dev data label for each domain\n",
    "#print(len(dict_train_df))\n",
    "\n",
    "def create_sized_data(size = 200000):\n",
    "    size_train = size #Set size of train set here. This is a hyperparameter.\n",
    "    key = list_df[0]\n",
    "    #print('Toys reviews\\n')\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_toys,dev_toys)\n",
    "    #print('\\n Video games reviews\\n')\n",
    "    key = list_df[1]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_vid,dev_vid)\n",
    "    #print('\\n Auto reviews\\n')\n",
    "    key = list_df[2]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_aut,dev_aut)\n",
    "    #print('\\n Home and Kitchen reviews\\n')\n",
    "    key = list_df[3]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_hnk,dev_hnk)\n",
    "    \n",
    "create_sized_data()\n",
    "#print(len(dict_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number words in training corpus for toys 42621\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.64%, AUC :93.61% AUC-PR :98.46%\n",
      "Number words in training corpus for vid 62251\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.67%, AUC :90.11% AUC-PR :96.61%\n",
      "Number words in training corpus for aut 38286\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.16%, AUC :92.61% AUC-PR :98.34%\n",
      "Number words in training corpus for hnk 38065\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 90.85%, AUC :93.13% AUC-PR :98.20%\n",
      "Classification report for toys \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.76      0.73      8934\n",
      "        1.0       0.96      0.94      0.95     51066\n",
      "\n",
      "avg / total       0.92      0.92      0.92     60000\n",
      "\n",
      "Classification report for vid \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.73      0.71     11357\n",
      "        1.0       0.94      0.92      0.93     48643\n",
      "\n",
      "avg / total       0.89      0.89      0.89     60000\n",
      "\n",
      "Classification report for aut \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.66      0.68      8665\n",
      "        1.0       0.94      0.95      0.95     51335\n",
      "\n",
      "avg / total       0.91      0.91      0.91     60000\n",
      "\n",
      "Classification report for hnk \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.74      0.72      0.73     10214\n",
      "        1.0       0.94      0.95      0.95     49786\n",
      "\n",
      "avg / total       0.91      0.91      0.91     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Converting reviews to sparse matrix of word ids with count vectorizer, and using Naive Bayes to make the prediction.\n",
    "#This section also creates the count_vectorizer and Naive Bayes models for each domain to be used to test transfer learning\n",
    "dict_vectorizers = {} #Dict to store the count_vectorizer model developed on each domain\n",
    "dict_train_ids = {} #Dict to store train data reviews as sparse matrix of word ids\n",
    "dict_dev_ids = {} #Dict to store dev data reviews as sparse matrix of word ids\n",
    "dict_nb = {} #Dict to store naive bayes model developed on each domain. Assumes input features are developed using the corresponding count_vectorizer\n",
    "dict_dev_ypred = {} #Dict to store dev predictions\n",
    "dict_dev_ypred_proba = {} #Dict to store dev predictions\n",
    "\n",
    "def create_base_NB_models():\n",
    "    for key in list_df:\n",
    "        #Converting ratings to tokenized word id counts as a sparse matrix using count_vectorizer\n",
    "        dict_vectorizers[key] = CountVectorizer(min_df=2, max_df = 0.8, stop_words='english')\n",
    "        dict_train_ids[key] = dict_vectorizers[key].fit_transform(dict_train_df[key].reviewText)\n",
    "        dict_dev_ids[key] = dict_vectorizers[key].transform(dict_dev_df[key].reviewText)\n",
    "        print(\"Number words in training corpus for\",key,len(dict_vectorizers[key].get_feature_names()))\n",
    "        #print(key,'dataset id shapes',dict_train_ids[key].shape, dict_dev_ids[key].shape)\n",
    "\n",
    "        #Building a Naive Bayes model to predict the ratings\n",
    "        dict_nb[key] = MultinomialNB()\n",
    "        dict_nb[key].fit(dict_train_ids[key],dict_train_y[key])\n",
    "        dict_dev_ypred[key] = dict_nb[key].predict(dict_dev_ids[key])\n",
    "        dict_dev_ypred_proba[key] = dict_nb[key].predict_proba(dict_dev_ids[key])\n",
    "        acc = accuracy_score(dict_dev_y[key], dict_dev_ypred[key])\n",
    "        auc = roc_auc_score(dict_dev_y[key], dict_dev_ypred_proba[key][:,1],average = 'weighted')\n",
    "        auc_pr = average_precision_score(dict_dev_y[key], dict_dev_ypred_proba[key][:,1],average = 'weighted')\n",
    "        print(\"Accuracy on\",key,\"dev set for binary prediction with toys naive bayes model: {:.02%}, AUC :{:.02%} AUC-PR :{:.02%}\".format(acc,auc,auc_pr))\n",
    "\n",
    "def print_base_NB_details():\n",
    "    for key in list_df:\n",
    "      print('Classification report for',key,'\\n',classification_report(dict_dev_y[key], dict_dev_ypred[key]))  \n",
    "        \n",
    "create_base_NB_models()\n",
    "print_base_NB_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 91.6% 90.9% 90.9% 90.9%\n",
      "vid  85.6% 88.7% 87.2% 87.1%\n",
      "aut  73.4% 78.3% 91.2% 82.0%\n",
      "hnk  84.2% 85.5% 90.7% 90.9%\n",
      "\n",
      "AUC of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 93.6% 91.7% 91.9% 91.7%\n",
      "vid  85.4% 90.1% 88.5% 87.1%\n",
      "aut  86.0% 85.0% 92.6% 88.0%\n",
      "hnk  91.0% 89.8% 92.6% 93.1%\n",
      "\n",
      "AUC-PR of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 98.5% 98.0% 98.1% 98.0%\n",
      "vid  94.8% 96.6% 96.3% 95.6%\n",
      "aut  97.1% 96.8% 98.3% 97.6%\n",
      "hnk  97.9% 97.4% 98.0% 98.2%\n",
      "\n",
      "f1_avg of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 84.1% 81.2% 81.4% 81.8%\n",
      "vid  77.3% 81.9% 78.7% 78.4%\n",
      "aut  65.3% 68.3% 81.6% 72.2%\n",
      "hnk  77.1% 77.4% 82.6% 83.7%\n",
      "\n",
      "f1_pos of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 95.1% 94.7% 94.7% 94.7%\n",
      "vid  91.0% 93.0% 92.2% 92.1%\n",
      "aut  82.1% 86.1% 94.9% 88.7%\n",
      "hnk  89.8% 90.9% 94.5% 94.5%\n",
      "\n",
      "f1_neg of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 73.0% 67.7% 68.2% 68.9%\n",
      "vid  63.6% 70.9% 65.3% 64.6%\n",
      "aut  48.5% 50.4% 68.3% 55.7%\n",
      "hnk  64.3% 63.9% 70.7% 72.8%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of transfer learning\n",
    "\n",
    "dict_transfer_ids = {} #Dictionary to store the dev vector ids for dataframe A(df) using the count_vectorizer of dataframe B(vect)\n",
    "transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "transfer_results_auc = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_auc_pr = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_f1_pos = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_f1_neg = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_f1_avg = pd.DataFrame(index=list_df,columns=list_df)\n",
    "\n",
    "def estimate_transfer_accuracy():\n",
    "    for vectKey in list_df:\n",
    "        dict_transfer_ids[vectKey] = {}\n",
    "        #print('vectKey',vectKey)\n",
    "        for dfKey in list_df:\n",
    "            #print('dfKey',dfKey)\n",
    "            dict_transfer_ids[vectKey][dfKey] = dict_vectorizers[vectKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "            #print(dfKey,'dataset using ',vectKey,' count vectorizer, id shapes',dict_transfer_ids[vectKey][dfKey].shape)\n",
    "            dict_dev_ypred = dict_nb[vectKey].predict(dict_transfer_ids[vectKey][dfKey])\n",
    "            acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "            #print(\"Accuracy on \",dfKey,\" dev set for binary prediction with \", vectKey,\" naive bayes model: {:.02%}\".format(acc))\n",
    "            transfer_results[vectKey][dfKey] = acc\n",
    "            dict_dev_ypred_proba = dict_nb[vectKey].predict_proba(dict_transfer_ids[vectKey][dfKey])\n",
    "            auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba[:,1], average = 'macro')\n",
    "            transfer_results_auc[vectKey][dfKey] = auc\n",
    "            auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba[:,1],average = 'macro')\n",
    "            transfer_results_auc_pr[vectKey][dfKey] = auc_pr\n",
    "            f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred, average = None)[1]\n",
    "            f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred, average = None)[0]\n",
    "            f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred, average = 'macro')\n",
    "            transfer_results_f1_pos[vectKey][dfKey] = f1_pos\n",
    "            transfer_results_f1_neg[vectKey][dfKey] = f1_neg\n",
    "            transfer_results_f1_avg[vectKey][dfKey] = f1_avg\n",
    "\n",
    "\n",
    "    print(\"Effectiveness of transfer learning with Naive Bayes:\")\n",
    "    print(\"Accuracy of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nAUC of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_auc.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nAUC-PR of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_auc_pr.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nf1_avg of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_f1_avg.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nf1_pos of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_f1_pos.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nf1_neg of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_f1_neg.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "estimate_transfer_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined df shape for toys vid (400000,)\n",
      "Number words in training corpus for keys toys vid 78691\n",
      "combined df shape for toys aut (400000,)\n",
      "Number words in training corpus for keys toys aut 61089\n",
      "combined df shape for toys hnk (400000,)\n",
      "Number words in training corpus for keys toys hnk 59636\n",
      "combined df shape for vid aut (400000,)\n",
      "Number words in training corpus for keys vid aut 78991\n",
      "combined df shape for vid hnk (400000,)\n",
      "Number words in training corpus for keys vid hnk 78053\n",
      "combined df shape for aut hnk (400000,)\n",
      "Number words in training corpus for keys aut hnk 56888\n",
      "\n",
      " Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys   NaN 90.4% 89.0% 89.5%\n",
      "vid  85.3%   NaN 82.4% 83.5%\n",
      "aut  71.0% 74.9%   NaN 79.2%\n",
      "hnk  82.1% 81.9% 89.4%   NaN\n",
      "\n",
      "AUC of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys   NaN 91.3% 90.3% 90.8%\n",
      "vid  85.1%   NaN 85.3% 85.6%\n",
      "aut  84.8% 83.6%   NaN 86.6%\n",
      "hnk  89.8% 88.0% 91.5%   NaN\n",
      "\n",
      "AUC_PR of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys   NaN 97.9% 97.8% 97.9%\n",
      "vid  94.7%   NaN 95.6% 95.5%\n",
      "aut  96.9% 96.5%   NaN 97.3%\n",
      "hnk  97.6% 97.1% 97.7%   NaN\n",
      "\n",
      "f1_avg of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys   NaN 80.5% 78.9% 79.8%\n",
      "vid  76.9%   NaN 74.1% 75.3%\n",
      "aut  63.3% 65.5%   NaN 69.7%\n",
      "hnk  75.0% 73.9% 81.0%   NaN\n",
      "\n",
      "f1_pos of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys   NaN 94.4% 93.5% 93.8%\n",
      "vid  90.8%   NaN 88.7% 89.5%\n",
      "aut  80.1% 83.5%   NaN 86.7%\n",
      "hnk  88.3% 88.3% 93.6%   NaN\n",
      "\n",
      "f1_neg of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys   NaN 66.7% 64.3% 65.8%\n",
      "vid  63.0%   NaN 59.5% 61.1%\n",
      "aut  46.5% 47.6%   NaN 52.6%\n",
      "hnk  61.6% 59.4% 68.4%   NaN\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of transfer learning - updating to use countvectorizer developed on both dataframes instead of just the source domain.\n",
    "\n",
    "dict_transfer_vect = {} ##Dictionary to store countvectorizer for two dfs combined.\n",
    "dict_transfer_train_ids = {} ##Dictionary to store train ids using countvectorizer for two dfs combined.\n",
    "dict_transfer_dev_ids = {} ## Dictionary to store dev ids using countvectorizer for two dfs combined.\n",
    "transfer_results = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store accuracy on transfer. Col = Model, row = dataframe\n",
    "transfer_results_auc = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_auc_pr = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_f1_pos = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_f1_neg = pd.DataFrame(index=list_df,columns=list_df)\n",
    "transfer_results_f1_avg = pd.DataFrame(index=list_df,columns=list_df)\n",
    "\n",
    "for vectKey in list_df:\n",
    "    dict_transfer_vect[vectKey] = {}\n",
    "    dict_transfer_train_ids[vectKey] = {}\n",
    "    dict_transfer_dev_ids[vectKey] = {}\n",
    "\n",
    "def estimate_transfer_accuracy():\n",
    "    #First create the countvectorizer for the two dfs together, then create the train and dev ids for both dfs using that.\n",
    "    for vectKey in list_df:\n",
    "        #print('vectKey',vectKey)\n",
    "        for dfKey in list_df:\n",
    "            if list_df.index(dfKey) > list_df.index(vectKey): \n",
    "                \n",
    "                #Create combined dataframe of reviewText from both domains\n",
    "                temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,dict_train_df[dfKey].reviewText])\n",
    "                print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape)\n",
    "                \n",
    "                #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "                dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, max_df = 0.9, stop_words='english')\n",
    "                dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "                print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "                #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "                dict_transfer_train_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_train_df[vectKey].reviewText)\n",
    "                dict_transfer_train_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_train_df[dfKey].reviewText)\n",
    "                dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "                dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "                #using vectKey as source, and dfkey as target\n",
    "                source_modelVect = MultinomialNB()\n",
    "                source_modelVect.fit(dict_transfer_train_ids[vectKey][dfKey],dict_train_y[vectKey])\n",
    "                dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "                dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "                acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "                auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba[:,1], average = 'weighted')\n",
    "                auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba[:,1], average = 'weighted')\n",
    "                transfer_results[vectKey][dfKey] = acc\n",
    "                transfer_results_auc[vectKey][dfKey] = auc\n",
    "                transfer_results_auc_pr[vectKey][dfKey] = auc_pr\n",
    "                f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred, average = None)[1]\n",
    "                f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred, average = None)[0]\n",
    "                f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred, average = 'macro')\n",
    "                transfer_results_f1_pos[vectKey][dfKey] = f1_pos\n",
    "                transfer_results_f1_neg[vectKey][dfKey] = f1_neg\n",
    "                transfer_results_f1_avg[vectKey][dfKey] = f1_avg\n",
    "                \n",
    "                #using dfKey as source, and Vectkey as target\n",
    "                source_modeldf = MultinomialNB()\n",
    "                source_modeldf.fit(dict_transfer_train_ids[dfKey][vectKey],dict_train_y[dfKey])\n",
    "                dict_dev_ypred = source_modeldf.predict(dict_transfer_dev_ids[vectKey][dfKey])\n",
    "                dict_dev_ypred_proba = source_modeldf.predict_proba(dict_transfer_dev_ids[vectKey][dfKey])\n",
    "                acc = accuracy_score(dict_dev_y[vectKey], dict_dev_ypred)\n",
    "                auc = roc_auc_score(dict_dev_y[vectKey], dict_dev_ypred_proba[:,1], average = 'weighted')\n",
    "                auc_pr = average_precision_score(dict_dev_y[vectKey], dict_dev_ypred_proba[:,1], average = 'weighted')\n",
    "                #print(\"Accuracy on \",dfKey,\" dev set for binary prediction with \", vectKey,\" naive bayes model: {:.02%}\".format(acc))\n",
    "                transfer_results[dfKey][vectKey] = acc\n",
    "                transfer_results_auc[dfKey][vectKey] = auc\n",
    "                transfer_results_auc_pr[dfKey][vectKey] = auc_pr\n",
    "                f1_pos = f1_score(dict_dev_y[vectKey], dict_dev_ypred, average = None)[1]\n",
    "                f1_neg = f1_score(dict_dev_y[vectKey], dict_dev_ypred, average = None)[0]\n",
    "                f1_avg = f1_score(dict_dev_y[vectKey], dict_dev_ypred, average = 'macro')\n",
    "                transfer_results_f1_pos[dfKey][vectKey] = f1_pos\n",
    "                transfer_results_f1_neg[dfKey][vectKey] = f1_neg\n",
    "                transfer_results_f1_avg[dfKey][vectKey] = f1_avg\n",
    "\n",
    "    print(\"\\n Effectiveness of transfer learning with Naive Bayes:\")\n",
    "    print(\"Accuracy of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nAUC of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_auc.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nAUC_PR of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_auc_pr.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nf1_avg of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_f1_avg.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nf1_pos of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_f1_pos.to_string(float_format = '{:.01%}'.format))\n",
    "    \n",
    "    print(\"\\nf1_neg of rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_results_f1_neg.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "estimate_transfer_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer loss on rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "     toys  vid  aut  hnk\n",
      "toys  NaN  NaN  NaN  NaN\n",
      "vid   NaN  NaN  NaN  NaN\n",
      "aut   NaN  NaN  NaN  NaN\n",
      "hnk   NaN  NaN  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "#Calculating and displaying as transfer loss\n",
    "transfer_loss = pd.DataFrame(index=list_df,columns=list_df) #Dataframe to store loss in accuracy on transfer. Col = Model, row = dataframe\n",
    "def estimate_transfer_loss():\n",
    "    for A in list_df:\n",
    "        for B in list_df:\n",
    "            transfer_loss[A][B] = transfer_results[B][B] - transfer_results[A][B]\n",
    "    print(\"Transfer loss on rating predictions\")\n",
    "    print(\"Colums = source domain, Rows = target domain\\n\")\n",
    "    print(transfer_loss.to_string(float_format = '{:.01%}'.format))\n",
    "\n",
    "estimate_transfer_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train data_set size = 5000\n",
      "Number words in training corpus for toys 7133\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 90.53%\n",
      "Number words in training corpus for vid 10570\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.87%\n",
      "Number words in training corpus for aut 6610\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.40%\n",
      "Number words in training corpus for hnk 7255\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 89.80%\n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 90.5% 88.1% 89.9% 90.0%\n",
      "vid  86.1% 88.9% 86.1% 86.4%\n",
      "aut  78.5% 82.5% 91.4% 88.8%\n",
      "hnk  86.0% 87.4% 88.5% 89.8%\n",
      "Transfer loss on rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys  vid  aut  hnk\n",
      "toys  0.0% 2.5% 0.7% 0.5%\n",
      "vid   2.7% 0.0% 2.8% 2.5%\n",
      "aut  12.9% 8.9% 0.0% 2.6%\n",
      "hnk   3.8% 2.4% 1.3% 0.0%\n",
      "\n",
      " Train data_set size = 100000\n",
      "Number words in training corpus for toys 31452\n",
      "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.55%\n",
      "Number words in training corpus for vid 44827\n",
      "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.65%\n",
      "Number words in training corpus for aut 27765\n",
      "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.41%\n",
      "Number words in training corpus for hnk 28189\n",
      "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.27%\n",
      "Effectiveness of transfer learning with Naive Bayes:\n",
      "Accuracy of rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut   hnk\n",
      "toys 91.5% 91.2% 91.6% 91.2%\n",
      "vid  85.8% 88.6% 87.7% 87.3%\n",
      "aut  71.6% 76.1% 91.4% 82.0%\n",
      "hnk  83.2% 85.3% 91.1% 91.3%\n",
      "Transfer loss on rating predictions\n",
      "Colums = source domain, Rows = target domain\n",
      "\n",
      "      toys   vid   aut  hnk\n",
      "toys  0.0%  0.4% -0.1% 0.3%\n",
      "vid   2.9%  0.0%  0.9% 1.4%\n",
      "aut  19.8% 15.3%  0.0% 9.4%\n",
      "hnk   8.1%  6.0%  0.2% 0.0%\n"
     ]
    }
   ],
   "source": [
    "#for size in (50000,100000,250000,500000,1000000):\n",
    "for size in (5000,100000):\n",
    "    print(\"\\n Train data_set size =\",size)\n",
    "    create_sized_data(size = size)\n",
    "    create_base_NB_models()\n",
    "    estimate_transfer_accuracy()\n",
    "    estimate_transfer_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a function to calculate JS Divergence using two discrete distributions.\n",
    "from scipy.stats import entropy\n",
    "from scipy import spatial\n",
    "#from scipy.sparse.linalg import norm\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def JSD(P, Q):\n",
    "   _P = P / norm(P, ord=1)\n",
    "   _Q = Q / norm(Q, ord=1)\n",
    "   _M = 0.5 * (_P + _Q)\n",
    "   return 0.5 * (entropy(_P, _M) + entropy(_Q, _M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 9)\n",
      "Number words in training corpus 56918\n",
      "toys (200000, 56918)\n",
      "vid (200000, 56918)\n",
      "aut (200000, 56918)\n",
      "hnk (200000, 56918)\n"
     ]
    }
   ],
   "source": [
    "#Create a vocabulary on the reviewText of all dataframes for the sake of comparing their distributions on the same baseline.\n",
    "all_df_reviews = pd.DataFrame(columns = dict_train_df[list_df[0]].columns)\n",
    "for key in list_df:\n",
    "    #print(dict_train_df[key].shape)\n",
    "    all_df_reviews = pd.concat([dict_train_df[key],all_df_reviews])\n",
    "print(all_df_reviews.shape)\n",
    "#print(type(all_df_reviews))\n",
    "#print(all_df_reviews.columns)\n",
    "\n",
    "all_vectorizer = CountVectorizer(min_df=5, max_df=0.8, stop_words='english')\n",
    "all_ids = all_vectorizer.fit_transform(all_df_reviews.reviewText)\n",
    "print(\"Number words in training corpus\",len(all_vectorizer.get_feature_names()))\n",
    "\n",
    "#Create a word if distribution of each df on the integrated vocabulary ids.\n",
    "dict_allVocab_ids = {}\n",
    "for key in list_df:\n",
    "    dict_allVocab_ids[key] = all_vectorizer.transform(dict_train_df[key].reviewText)\n",
    "    print(key,dict_allVocab_ids[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Divergence\n",
      "                  toys               vid               aut               hnk\n",
      "toys             [0.0]  [0.121246343811]  [0.148541482886]  [0.128727888777]\n",
      "vid   [0.121246343811]             [0.0]   [0.19731515398]  [0.200997729739]\n",
      "aut   [0.148541482886]   [0.19731515398]             [0.0]  [0.117755259719]\n",
      "hnk   [0.128727888777]  [0.200997729739]  [0.117755259719]             [0.0]\n",
      "\n",
      "Cosine Distance\n",
      "             toys       vid       aut          hnk\n",
      "toys  1.11022e-16  0.345773   0.28744     0.236155\n",
      "vid      0.345773         0  0.548035     0.527581\n",
      "aut       0.28744  0.548035         0     0.144695\n",
      "hnk      0.236155  0.527581  0.144695 -2.22045e-16\n"
     ]
    }
   ],
   "source": [
    "JSD_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "cosine_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "for key1 in list_df:\n",
    "   for key2 in list_df:\n",
    "       dict_train_ids_1 = dict_allVocab_ids[key1].sum(axis=0).T\n",
    "       dict_train_ids_2 = dict_allVocab_ids[key2].sum(axis=0).T\n",
    "       #print(dict_allVocab_ids[key1].shape,dict_train_ids_1.shape,dict_train_ids_2.shape)\n",
    "       JSD_results[key1][key2] = JSD(dict_train_ids_1,dict_train_ids_2)\n",
    "       cosine_results[key1][key2] = spatial.distance.cosine(dict_train_ids_1,dict_train_ids_2)\n",
    "       \n",
    "print('JS Divergence')\n",
    "print(JSD_results)\n",
    "print('\\nCosine Distance')\n",
    "print(cosine_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Divergence\n",
      "                  toys               vid               aut               hnk\n",
      "toys               NaN  [0.123001673566]  [0.149751428655]  [0.129778788002]\n",
      "vid   [0.123001673566]               NaN   [0.19897829178]  [0.202496415382]\n",
      "aut   [0.149751428655]   [0.19897829178]               NaN  [0.118910613139]\n",
      "hnk   [0.129778788002]  [0.202496415382]  [0.118910613139]               NaN\n",
      "\n",
      "Cosine Distance\n",
      "          toys       vid       aut       hnk\n",
      "toys       NaN   0.34578  0.287441  0.236156\n",
      "vid    0.34578       NaN   0.54804  0.527586\n",
      "aut   0.287441   0.54804       NaN  0.144696\n",
      "hnk   0.236156  0.527586  0.144696       NaN\n"
     ]
    }
   ],
   "source": [
    "#Calculating similarity using countVectorizer of two dfs together rather than all 4.\n",
    "JSD_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "cosine_results = pd.DataFrame(index=list_df,columns=list_df)\n",
    "for key1 in list_df:\n",
    "    for key2 in list_df:\n",
    "        if list_df.index(key1)!= list_df.index(key2):\n",
    "            #print(key1,key2)\n",
    "            dict_train_ids_1 = dict_transfer_train_ids[key1][key2].sum(axis=0).T\n",
    "            dict_train_ids_2 = dict_transfer_train_ids[key2][key1].sum(axis=0).T\n",
    "            #print(dict_allVocab_ids[key1].shape,dict_train_ids_1.shape,dict_train_ids_2.shape)\n",
    "            JSD_results[key1][key2] = JSD(dict_train_ids_1,dict_train_ids_2)\n",
    "            cosine_results[key1][key2] = spatial.distance.cosine(dict_train_ids_1,dict_train_ids_2)\n",
    "       \n",
    "print('JS Divergence')\n",
    "print(JSD_results)\n",
    "print('\\nCosine Distance')\n",
    "print(cosine_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2)\n",
      "[[ 0.22240641  0.77759359]\n",
      " [ 0.42763597  0.57236403]\n",
      " [ 0.00342877  0.99657123]\n",
      " [ 0.01078046  0.98921954]\n",
      " [ 0.09652324  0.90347676]] [ 0.55518717  0.14472805  0.99314247  0.97843908  0.80695351]\n",
      "max, min uncertainty absolute 1.0 6.68216880217e-06\n",
      "max, min uncertainty 1.0 -1.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating uncetainty for each target train set review\n",
    "key1 = 'vid' #source domain\n",
    "key2 = 'aut' #target domain\n",
    "\n",
    "source_model = dict_nb[key1]\n",
    "target_train_ids = dict_vectorizers[key1].transform(dict_train_df[key2].reviewText)\n",
    "u_train_target_abs = np.zeros(len(dict_train_y[key2]))\n",
    "uncertainty_train_target = np.zeros(len(dict_train_y[key2]))\n",
    "target_y_pred_proba = source_model.predict_proba(target_train_ids)\n",
    "print(target_y_pred_proba.shape)\n",
    "u_train_target_abs = np.absolute(target_y_pred_proba[:,1] - target_y_pred_proba[:,0])\n",
    "u_train_target = target_y_pred_proba[:,1] - target_y_pred_proba[:,0]\n",
    "print(target_y_pred_proba[:5],u_train_target_abs[:5])\n",
    "\n",
    "print('max, min uncertainty absolute',np.max(u_train_target_abs),np.min(u_train_target_abs))\n",
    "print('max, min uncertainty',np.max(u_train_target),np.min(u_train_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78991, 1) (200000,) (60000,)\n",
      "511106.886934\n",
      "cosine distance metrics, train set: 1.0 0.456956799804 (200000,)\n",
      "number of reviews with zero norm =  86\n",
      "(array([    1,     0,     0,     0,     1,     2,     1,     7,     8,\n",
      "          15,    47,   240,  1142,  4041, 12081, 26610, 44378, 52285,\n",
      "       43789, 15352]), array([ 0.4569568 ,  0.48410896,  0.51126112,  0.53841328,  0.56556544,\n",
      "        0.5927176 ,  0.61986976,  0.64702192,  0.67417408,  0.70132624,\n",
      "        0.7284784 ,  0.75563056,  0.78278272,  0.80993488,  0.83708704,\n",
      "        0.8642392 ,  0.89139136,  0.91854352,  0.94569568,  0.97284784,  1.        ]))\n",
      "1.0 0.601775726121\n",
      "total time taken 192.66279697418213\n"
     ]
    }
   ],
   "source": [
    "#calculating cosine similarity for each individual review.\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "key1 = 'vid'\n",
    "key2 = 'aut'\n",
    "source_ids = dict_transfer_train_ids[key1][key2].sum(axis=0).T\n",
    "cosine_distance_train = np.ones((len(dict_train_y[key2])))\n",
    "cosine_distance_dev = np.ones((len(dict_dev_y[key2])))\n",
    "review_length_train = np.ones((len(dict_train_y[key2])))\n",
    "review_length_dev = np.ones((len(dict_dev_y[key2])))\n",
    "print(source_ids.shape,cosine_distance_train.shape,cosine_distance_dev.shape)\n",
    "print(norm(source_ids))\n",
    "n = norm(source_ids)\n",
    "\n",
    "start = time.time()\n",
    "count_zero_norm = 0\n",
    "for i in range(len(dict_train_y[key2])):\n",
    "    y = dict_transfer_train_ids[key2][key1][i].T.toarray()\n",
    "    #review_length_train[i] = sum(y)\n",
    "#     if i < 10:\n",
    "#         print('sums',review_length_train[i], other_sum)\n",
    "    if norm(y) == 0:\n",
    "        cosine_distance_train[i] = 1\n",
    "        count_zero_norm += 1\n",
    "    else:\n",
    "        cosine_distance_train[i] = spatial.distance.cosine(source_ids,y)\n",
    "#     if i%1000 == 0:\n",
    "#         print(i, 'train examples done')\n",
    "print('cosine distance metrics, train set:',max(cosine_distance_train),min(cosine_distance_train),cosine_distance_train.shape)\n",
    "print('number of reviews with zero norm = ',count_zero_norm)\n",
    "\n",
    "y = np.histogram(cosine_distance_train,bins=20, normed=False)\n",
    "print(y)\n",
    "\n",
    "for i in range(len(dict_dev_y[key2])):\n",
    "    z = dict_transfer_dev_ids[key2][key1][i].T.toarray()\n",
    "    #review_length_dev[i] = sum(z)\n",
    "    if norm(z) == 0:\n",
    "        cosine_distance_dev[i] = 1\n",
    "    else:\n",
    "        cosine_distance_dev[i] = spatial.distance.cosine(source_ids,z)\n",
    "#     if i%1000 == 0:\n",
    "#         print(i, 'dev examples done')\n",
    "        \n",
    "print(max(cosine_distance_dev),min(cosine_distance_dev))\n",
    "end = time.time()\n",
    "print('total time taken', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Review Length by Cosine distance\n",
      "Cosine dist 0.00 to 0.05 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.05 to 0.10 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.10 to 0.15 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.15 to 0.20 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.20 to 0.25 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.25 to 0.30 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.30 to 0.35 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.35 to 0.40 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.40 to 0.45 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.45 to 0.50 Avg Review Length: 15.00 Avg Cosine Dist: 0.46 Number reviews 1\n",
      "Cosine dist 0.50 to 0.55 Avg Review Length: nan Avg Cosine Dist: nan Number reviews 0\n",
      "Cosine dist 0.55 to 0.60 Avg Review Length: 20.00 Avg Cosine Dist: 0.57 Number reviews 1\n",
      "Cosine dist 0.60 to 0.65 Avg Review Length: 11.75 Avg Cosine Dist: 0.63 Number reviews 4\n",
      "Cosine dist 0.65 to 0.70 Avg Review Length: 30.00 Avg Cosine Dist: 0.68 Number reviews 12\n",
      "Cosine dist 0.70 to 0.75 Avg Review Length: 54.25 Avg Cosine Dist: 0.73 Number reviews 48\n",
      "Cosine dist 0.75 to 0.80 Avg Review Length: 53.27 Avg Cosine Dist: 0.79 Number reviews 787\n",
      "Cosine dist 0.80 to 0.85 Avg Review Length: 41.85 Avg Cosine Dist: 0.83 Number reviews 9006\n",
      "Cosine dist 0.85 to 0.90 Avg Review Length: 33.61 Avg Cosine Dist: 0.88 Number reviews 46431\n",
      "Cosine dist 0.90 to 0.95 Avg Review Length: 26.13 Avg Cosine Dist: 0.93 Number reviews 92240\n",
      "Cosine dist 0.95 to 1.00 Avg Review Length: 17.03 Avg Cosine Dist: 0.97 Number reviews 51383\n",
      "\n",
      "Average Review Length by Average prob difference (certainty)\n",
      "Average abs delta pos-neg class 0.00 to 0.05 Avg Review Length: 22.19 Avg Cosine Dist: 0.03 Number reviews 3345\n",
      "Average abs delta pos-neg class 0.05 to 0.10 Avg Review Length: 21.77 Avg Cosine Dist: 0.05 Number reviews 3245\n",
      "Average abs delta pos-neg class 0.10 to 0.15 Avg Review Length: 22.09 Avg Cosine Dist: 0.07 Number reviews 3196\n",
      "Average abs delta pos-neg class 0.15 to 0.20 Avg Review Length: 21.07 Avg Cosine Dist: 0.10 Number reviews 3276\n",
      "Average abs delta pos-neg class 0.20 to 0.25 Avg Review Length: 21.96 Avg Cosine Dist: 0.13 Number reviews 3389\n",
      "Average abs delta pos-neg class 0.25 to 0.30 Avg Review Length: 21.65 Avg Cosine Dist: 0.15 Number reviews 3545\n",
      "Average abs delta pos-neg class 0.30 to 0.35 Avg Review Length: 21.38 Avg Cosine Dist: 0.18 Number reviews 3615\n",
      "Average abs delta pos-neg class 0.35 to 0.40 Avg Review Length: 21.74 Avg Cosine Dist: 0.21 Number reviews 3811\n",
      "Average abs delta pos-neg class 0.40 to 0.45 Avg Review Length: 20.97 Avg Cosine Dist: 0.23 Number reviews 3984\n",
      "Average abs delta pos-neg class 0.45 to 0.50 Avg Review Length: 21.43 Avg Cosine Dist: 0.26 Number reviews 4277\n",
      "Average abs delta pos-neg class 0.50 to 0.55 Avg Review Length: 21.27 Avg Cosine Dist: 0.29 Number reviews 4697\n",
      "Average abs delta pos-neg class 0.55 to 0.60 Avg Review Length: 21.11 Avg Cosine Dist: 0.32 Number reviews 4877\n",
      "Average abs delta pos-neg class 0.60 to 0.65 Avg Review Length: 20.35 Avg Cosine Dist: 0.36 Number reviews 5609\n",
      "Average abs delta pos-neg class 0.65 to 0.70 Avg Review Length: 21.18 Avg Cosine Dist: 0.39 Number reviews 6017\n",
      "Average abs delta pos-neg class 0.70 to 0.75 Avg Review Length: 20.58 Avg Cosine Dist: 0.43 Number reviews 7066\n",
      "Average abs delta pos-neg class 0.75 to 0.80 Avg Review Length: 20.35 Avg Cosine Dist: 0.47 Number reviews 8384\n",
      "Average abs delta pos-neg class 0.80 to 0.85 Avg Review Length: 20.86 Avg Cosine Dist: 0.51 Number reviews 10207\n",
      "Average abs delta pos-neg class 0.85 to 0.90 Avg Review Length: 20.40 Avg Cosine Dist: 0.56 Number reviews 13845\n",
      "Average abs delta pos-neg class 0.90 to 0.95 Avg Review Length: 20.61 Avg Cosine Dist: 0.62 Number reviews 20995\n",
      "Average abs delta pos-neg class 0.95 to 1.00 Avg Review Length: 33.18 Avg Cosine Dist: 0.73 Number reviews 82275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:1110: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "span = 0.05\n",
    "\n",
    "print('Average Review Length by Cosine distance')\n",
    "for i in range(int(1/span)):\n",
    "    avg_review_length = np.average(review_length_train[(cosine_distance_train > span*i) & (cosine_distance_train < span*(i+1))])\n",
    "    average_cosine_distance = np.average(cosine_distance_train[(cosine_distance_train > span*i) & (cosine_distance_train < span*(i+1))])\n",
    "    number_reviews = len(review_length_train[(cosine_distance_train > span*i) & (cosine_distance_train < span*(i+1))])\n",
    "    print('Cosine dist %0.2f to %0.2f'%(span*(i),span*(i+1)),'Avg Review Length: %0.2f'%avg_review_length,\n",
    "          'Avg Cosine Dist: %0.2f'%average_cosine_distance,'Number reviews %d'%number_reviews)\n",
    "    \n",
    "print('\\nAverage Review Length by Average prob difference (certainty)')\n",
    "for i in range(int(1/span)):\n",
    "    avg_review_length = np.average(review_length_train[(u_train_target_abs > span*i) & (u_train_target_abs < span*(i+1))])\n",
    "    average_u_train_target_abs = np.average(u_train_target_abs[(cosine_distance_train > span*i) & (u_train_target_abs < span*(i+1))])\n",
    "    number_reviews = len(review_length_train[(u_train_target_abs > span*i) & (u_train_target_abs < span*(i+1))])\n",
    "    print('Average abs delta pos-neg class %0.2f to %0.2f'%(span*(i),span*(i+1)),'Avg Review Length: %0.2f'%avg_review_length,\n",
    "          'Avg Cosine Dist: %0.2f'%average_u_train_target_abs,'Number reviews %d'%number_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall transfer accuracy 0.7491\n",
      "Overall AUC 0.835992361142\n",
      "Cosine dist 0.00 to 0.05, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.05 to 0.10, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.10 to 0.15, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.15 to 0.20, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.20 to 0.25, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.25 to 0.30, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.30 to 0.35, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.35 to 0.40, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.40 to 0.45, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.45 to 0.50, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.50 to 0.55, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.55 to 0.60, Transfer acc: nan AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 0 pos_percent nan\n",
      "Cosine dist 0.60 to 0.65, Transfer acc: 0.667 AUC 0.500 AUC-PR 0.833 f1_pos 0.800 f1_neg 0.000 f1_avg 0.400 #reviews 3 pos_percent 0.67\n",
      "Cosine dist 0.65 to 0.70, Transfer acc: 1.000 AUC 0.000 AUC-PR 0.000 f1_pos 0.000 f1_neg 0.000 f1_avg 0.000 #reviews 5 pos_percent 1.00\n",
      "Cosine dist 0.70 to 0.75, Transfer acc: 0.923 AUC 0.917 AUC-PR 0.994 f1_pos 0.957 f1_neg 0.667 f1_avg 0.812 #reviews 13 pos_percent 0.92\n",
      "Cosine dist 0.75 to 0.80, Transfer acc: 0.894 AUC 0.960 AUC-PR 0.998 f1_pos 0.941 f1_neg 0.489 f1_avg 0.715 #reviews 218 pos_percent 0.95\n",
      "Cosine dist 0.80 to 0.85, Transfer acc: 0.788 AUC 0.826 AUC-PR 0.981 f1_pos 0.874 f1_neg 0.336 f1_avg 0.605 #reviews 2647 pos_percent 0.92\n",
      "Cosine dist 0.85 to 0.90, Transfer acc: 0.771 AUC 0.859 AUC-PR 0.982 f1_pos 0.859 f1_neg 0.397 f1_avg 0.628 #reviews 13876 pos_percent 0.91\n",
      "Cosine dist 0.90 to 0.95, Transfer acc: 0.742 AUC 0.843 AUC-PR 0.966 f1_pos 0.829 f1_neg 0.477 f1_avg 0.653 #reviews 27887 pos_percent 0.86\n",
      "Cosine dist 0.95 to 1.00, Transfer acc: 0.733 AUC 0.816 AUC-PR 0.940 f1_pos 0.813 f1_neg 0.535 f1_avg 0.674 #reviews 15323 pos_percent 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:1110: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#calculating accuracy by distance buckets\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "source_modelVect = MultinomialNB()\n",
    "source_modelVect.fit(dict_transfer_train_ids[key1][key2],dict_train_y[key1])\n",
    "dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[key2][key1])\n",
    "dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[key2][key1])[:,1]\n",
    "#print(dict_dev_ypred_proba[:5])\n",
    "dev_y_actual = dict_dev_y[key2]\n",
    "#print(dict_dev_ypred[:5])\n",
    "acc = accuracy_score(dict_dev_y[key2], dict_dev_ypred)\n",
    "print('Overall transfer accuracy',acc)\n",
    "auc = roc_auc_score(dict_dev_y[key2], dict_dev_ypred_proba, average = 'weighted')\n",
    "print('Overall AUC',auc)\n",
    "\n",
    "span = 0.05 #determines the number of buckets by which we look at metrics by buckets of cosine similarity\n",
    "acc_by_similarity = np.zeros(int(1/span))\n",
    "auc_by_sim = np.zeros(int(1/span))\n",
    "auc_pr_by_sim = np.zeros(int(1/span))\n",
    "f1_pos = np.zeros(int(1/span))\n",
    "f1_neg = np.zeros(int(1/span))\n",
    "f1_avg = np.zeros(int(1/span))\n",
    "percent_pos_class = np.zeros(int(1/span))\n",
    "\n",
    "\n",
    "for i in range(int(1/span)):\n",
    "    acc_by_similarity[i] = accuracy_score(dev_y_actual[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))], \n",
    "                                          dict_dev_ypred[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))])\n",
    "    dev_y_selected = dev_y_actual[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))]\n",
    "    dev_y_predict_selected = dict_dev_ypred[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))]\n",
    "    percent_pos_class[i] = np.sum(dev_y_selected)/len(dev_y_selected)\n",
    "    if (percent_pos_class[i] > 0.05 and percent_pos_class[i] < 0.95):\n",
    "        auc_by_sim[i] = roc_auc_score(dev_y_actual[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))], \n",
    "                                    dict_dev_ypred_proba[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))],\n",
    "                                     average = 'weighted')\n",
    "        auc_pr_by_sim[i] = average_precision_score(dev_y_actual[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))], \n",
    "                                    dict_dev_ypred_proba[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))],\n",
    "                                     average = 'weighted')\n",
    "#         print(type(f1_score(dev_y_selected, dev_y_predict_selected,average = None)))\n",
    "#         print(f1_score(dev_y_selected, dev_y_predict_selected,average = None).shape)\n",
    "#         print(f1_score(dev_y_selected, dev_y_predict_selected,average = None))\n",
    "        f1_pos[i] = f1_score(dev_y_selected, dev_y_predict_selected,average = None)[1] #pos class\n",
    "        f1_neg[i] = f1_score(dev_y_selected, dev_y_predict_selected,average = None)[0] #neg class  \n",
    "        f1_avg[i] = f1_score(dev_y_selected, dev_y_predict_selected,average = 'macro') #average\n",
    "        avg_review_length = np.average(review_length_dev[(cosine_distance_dev > span*i) & (cosine_distance_dev < span*(i+1))])\n",
    "    print('Cosine dist %0.2f to %0.2f, Transfer acc: %0.3f AUC %0.3f AUC-PR %0.3f f1_pos %0.3f f1_neg %0.3f f1_avg %0.3f #reviews %d Avg review length %d pos_percent %0.2f'\n",
    "          %(span*(i),span*(i+1),acc_by_similarity[i],auc_by_sim[i],auc_pr_by_sim[i],f1_pos[i],f1_neg[i],f1_avg[i],len(dev_y_selected),avg_review_length,percent_pos_class[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Adding random samples from target domain\n",
      "combined df shape for vid aut (200000,) (200000,)\n",
      "Number words in training corpus for keys vid aut 62251\n",
      "for size = 0, accuracy = 0.783, auc 0.850 auc-pr 0.968 f1_pos 0.861 f1_neg 0.504 f1_avg 0.683\n",
      "combined df shape for vid aut (205000,) (205000,)\n",
      "Number words in training corpus for keys vid aut 63093\n",
      "for size = 5000, accuracy = 0.821, auc 0.865 auc-pr 0.971 f1_pos 0.888 f1_neg 0.541 f1_avg 0.715\n",
      "combined df shape for vid aut (210000,) (210000,)\n",
      "Number words in training corpus for keys vid aut 63783\n",
      "for size = 10000, accuracy = 0.839, auc 0.871 auc-pr 0.972 f1_pos 0.901 f1_neg 0.560 f1_avg 0.731\n",
      "combined df shape for vid aut (225000,) (225000,)\n",
      "Number words in training corpus for keys vid aut 65460\n",
      "for size = 25000, accuracy = 0.868, auc 0.883 auc-pr 0.973 f1_pos 0.921 f1_neg 0.595 f1_avg 0.758\n",
      "combined df shape for vid aut (250000,) (250000,)\n",
      "Number words in training corpus for keys vid aut 67836\n",
      "for size = 50000, accuracy = 0.886, auc 0.891 auc-pr 0.975 f1_pos 0.933 f1_neg 0.620 f1_avg 0.776\n",
      "combined df shape for vid aut (275000,) (275000,)\n",
      "Number words in training corpus for keys vid aut 69996\n",
      "for size = 75000, accuracy = 0.894, auc 0.896 auc-pr 0.975 f1_pos 0.938 f1_neg 0.628 f1_avg 0.783\n",
      "combined df shape for vid aut (300000,) (300000,)\n",
      "Number words in training corpus for keys vid aut 71936\n",
      "for size = 100000, accuracy = 0.898, auc 0.900 auc-pr 0.976 f1_pos 0.941 f1_neg 0.635 f1_avg 0.788\n",
      "pre sort [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "\n",
      " Post sort [ 0.  1.  1.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.] first 20 [  6.68216880e-06   2.35394588e-05   7.59235947e-05   9.01917329e-05\n",
      "   1.04840731e-04   1.14251374e-04   1.16244858e-04   1.24625696e-04\n",
      "   1.36248916e-04   1.38031791e-04   1.43707787e-04   1.48482835e-04\n",
      "   1.48905580e-04   1.51633681e-04   1.72923250e-04   1.95075058e-04\n",
      "   2.23439671e-04   2.75130656e-04   2.80753834e-04   3.08328055e-04] [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "\n",
      " Adding least certain\n",
      "combined df shape for vid aut (200000,) (200000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:1110: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number words in training corpus for keys vid aut 62251\n",
      "for size = 0, accuracy = 0.783, auc 0.850 auc-pr 0.968 f1_pos 0.861 f1_neg  0.504 f1_avg 0.683,avg uncertainty nan\n",
      "combined df shape for vid aut (205000,) (205000,)\n",
      "Number words in training corpus for keys vid aut 62948\n",
      "for size = 5000, accuracy = 0.832, auc 0.868 auc-pr 0.971 f1_pos 0.897 f1_neg  0.552 f1_avg 0.724,avg uncertainty 0.04\n",
      "combined df shape for vid aut (210000,) (210000,)\n",
      "Number words in training corpus for keys vid aut 63569\n",
      "for size = 10000, accuracy = 0.855, auc 0.876 auc-pr 0.972 f1_pos 0.912 f1_neg  0.577 f1_avg 0.745,avg uncertainty 0.08\n",
      "combined df shape for vid aut (225000,) (225000,)\n",
      "Number words in training corpus for keys vid aut 65026\n",
      "for size = 25000, accuracy = 0.885, auc 0.883 auc-pr 0.972 f1_pos 0.933 f1_neg  0.612 f1_avg 0.772,avg uncertainty 0.19\n",
      "combined df shape for vid aut (250000,) (250000,)\n",
      "Number words in training corpus for keys vid aut 67109\n",
      "for size = 50000, accuracy = 0.899, auc 0.885 auc-pr 0.971 f1_pos 0.942 f1_neg  0.623 f1_avg 0.783,avg uncertainty 0.35\n",
      "combined df shape for vid aut (275000,) (275000,)\n",
      "Number words in training corpus for keys vid aut 68884\n",
      "for size = 75000, accuracy = 0.903, auc 0.883 auc-pr 0.969 f1_pos 0.945 f1_neg  0.614 f1_avg 0.779,avg uncertainty 0.48\n",
      "combined df shape for vid aut (300000,) (300000,)\n",
      "Number words in training corpus for keys vid aut 70493\n",
      "for size = 100000, accuracy = 0.905, auc 0.882 auc-pr 0.969 f1_pos 0.946 f1_neg  0.604 f1_avg 0.775,avg uncertainty 0.58\n",
      "\n",
      " Adding most certain\n",
      "combined df shape for vid aut (400000,) (400000,)\n",
      "Number words in training corpus for keys vid aut 78991\n",
      "for size = 0, accuracy = 0.905, auc 0.910 auc-pr 0.979 f1_pos 0.945 f1_neg  0.650 f1_avg 0.798,avg certainty 0.78\n",
      "combined df shape for vid aut (205000,) (205000,)\n",
      "Number words in training corpus for keys vid aut 65001\n",
      "for size = 5000, accuracy = 0.636, auc 0.816 auc-pr 0.961 f1_pos 0.736 f1_neg  0.413 f1_avg 0.574,avg certainty 1.00\n",
      "combined df shape for vid aut (210000,) (210000,)\n",
      "Number words in training corpus for keys vid aut 66288\n",
      "for size = 10000, accuracy = 0.662, auc 0.827 auc-pr 0.964 f1_pos 0.760 f1_neg  0.430 f1_avg 0.595,avg certainty 1.00\n",
      "combined df shape for vid aut (225000,) (225000,)\n",
      "Number words in training corpus for keys vid aut 68268\n",
      "for size = 25000, accuracy = 0.743, auc 0.850 auc-pr 0.968 f1_pos 0.829 f1_neg  0.484 f1_avg 0.656,avg certainty 1.00\n",
      "combined df shape for vid aut (250000,) (250000,)\n",
      "Number words in training corpus for keys vid aut 70332\n",
      "for size = 50000, accuracy = 0.816, auc 0.869 auc-pr 0.971 f1_pos 0.885 f1_neg  0.545 f1_avg 0.715,avg certainty 1.00\n",
      "combined df shape for vid aut (275000,) (275000,)\n",
      "Number words in training corpus for keys vid aut 71950\n",
      "for size = 75000, accuracy = 0.854, auc 0.880 auc-pr 0.973 f1_pos 0.911 f1_neg  0.585 f1_avg 0.748,avg certainty 0.99\n",
      "combined df shape for vid aut (300000,) (300000,)\n",
      "Number words in training corpus for keys vid aut 73451\n",
      "for size = 100000, accuracy = 0.874, auc 0.888 auc-pr 0.974 f1_pos 0.925 f1_neg  0.609 f1_avg 0.767,avg certainty 0.98\n"
     ]
    }
   ],
   "source": [
    "#Improvement in accuracy with adding an actively selected sample of different sizes from the target domain to the source domain\n",
    "#This cell contains outcomes for using uncertainty as the metric for samples to add.\n",
    "\n",
    "vectKey = key1\n",
    "dfKey = key2\n",
    "size_list = [0,5000,10000,25000,50000,75000,100000]\n",
    "\n",
    "print('\\n Adding random samples from target domain')\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = dict_train_df[dfKey][:size]\n",
    "    labels_to_add = dict_train_y[dfKey][:size]\n",
    "    \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[dfKey][vectKey])[:,1]\n",
    "    auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[1] #pos class\n",
    "    f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[0]\n",
    "    f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = 'macro')\n",
    "    print('for size = %d, accuracy = %0.3f, auc %0.3f auc-pr %0.3f f1_pos %0.3f f1_neg %0.3f f1_avg %0.3f'\n",
    "          %(size,acc,auc,auc_pr,f1_pos,f1_neg,f1_avg))\n",
    "\n",
    "#Sorting the data frame and labels by cosine distance\n",
    "\n",
    "# sort_ids = np.argsort(cosine_distance_train)\n",
    "# cosine_distance_sorted = cosine_distance_train[sort_ids]\n",
    "sort_ids = np.argsort(u_train_target_abs)\n",
    "cosine_distance_sorted = u_train_target_abs[sort_ids]\n",
    "#print(sort_ids)\n",
    "df_target_ids_pre = dict_train_df[dfKey]\n",
    "df_target_labels_pre = dict_train_y[dfKey]\n",
    "print('pre sort',df_target_labels_pre[-20:])\n",
    "#print(type(df_target_labels_pre))\n",
    "df_target_ids_pre = df_target_ids_pre.iloc([sort_ids])\n",
    "df_target_ids = df_target_ids_pre[sort_ids]\n",
    "df_target_labels = df_target_labels_pre[sort_ids]\n",
    "print('\\n Post sort',df_target_labels[-20:],'first 20',cosine_distance_sorted[:20],cosine_distance_sorted[-20:])\n",
    "\n",
    "# print('\\n Adding least cosine distance')\n",
    "print('\\n Adding least certain')\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = df_target_ids[:size]\n",
    "    labels_to_add = df_target_labels[:size]\n",
    "    avg_cosine_distance = np.average(cosine_distance_sorted[:size])\n",
    "    \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[dfKey][vectKey])[:,1]\n",
    "    auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[1] #pos class\n",
    "    f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[0]\n",
    "    f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = 'macro')\n",
    "    print('for size = %d, accuracy = %0.3f, auc %0.3f auc-pr %0.3f f1_pos %0.3f f1_neg  %0.3f f1_avg %0.3f,avg uncertainty %0.2f'\n",
    "          %(size,acc,auc,auc_pr,f1_pos,f1_neg,f1_avg,avg_cosine_distance))\n",
    "    \n",
    "\n",
    "#print('\\n Adding most cosine distance')\n",
    "print('\\n Adding most certain')\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = df_target_ids[-size:]\n",
    "    labels_to_add = df_target_labels[-size:]\n",
    "    avg_cosine_distance = np.average(cosine_distance_sorted[-size:])\n",
    "       \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[dfKey][vectKey])[:,1]\n",
    "    auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[1] #pos class\n",
    "    f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[0]\n",
    "    f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = 'macro')\n",
    "    print('for size = %d, accuracy = %0.3f, auc %0.3f auc-pr %0.3f f1_pos %0.3f f1_neg  %0.3f f1_avg %0.3f,avg certainty %0.2f'\n",
    "          %(size,acc,auc,auc_pr,f1_pos,f1_neg,f1_avg,avg_cosine_distance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Adding random samples from target domain\n",
      "combined df shape for vid aut (200000,) (200000,)\n",
      "Number words in training corpus for keys vid aut 62251\n",
      "for size = 0, accuracy = 0.783, auc 0.850 auc-pr 0.968 f1_pos 0.861 f1_neg 0.504 f1_avg 0.683\n",
      "combined df shape for vid aut (205000,) (205000,)\n",
      "Number words in training corpus for keys vid aut 63093\n",
      "for size = 5000, accuracy = 0.821, auc 0.865 auc-pr 0.971 f1_pos 0.888 f1_neg 0.541 f1_avg 0.715\n",
      "combined df shape for vid aut (210000,) (210000,)\n",
      "Number words in training corpus for keys vid aut 63783\n",
      "for size = 10000, accuracy = 0.839, auc 0.871 auc-pr 0.972 f1_pos 0.901 f1_neg 0.560 f1_avg 0.731\n",
      "combined df shape for vid aut (225000,) (225000,)\n",
      "Number words in training corpus for keys vid aut 65460\n",
      "for size = 25000, accuracy = 0.868, auc 0.883 auc-pr 0.973 f1_pos 0.921 f1_neg 0.595 f1_avg 0.758\n",
      "combined df shape for vid aut (250000,) (250000,)\n",
      "Number words in training corpus for keys vid aut 67836\n",
      "for size = 50000, accuracy = 0.886, auc 0.891 auc-pr 0.975 f1_pos 0.933 f1_neg 0.620 f1_avg 0.776\n",
      "combined df shape for vid aut (275000,) (275000,)\n",
      "Number words in training corpus for keys vid aut 69996\n",
      "for size = 75000, accuracy = 0.894, auc 0.896 auc-pr 0.975 f1_pos 0.938 f1_neg 0.628 f1_avg 0.783\n",
      "combined df shape for vid aut (300000,) (300000,)\n",
      "Number words in training corpus for keys vid aut 71936\n",
      "for size = 100000, accuracy = 0.898, auc 0.900 auc-pr 0.976 f1_pos 0.941 f1_neg 0.635 f1_avg 0.788\n",
      "pre sort [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "\n",
      " Post sort [ 1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.] first 20 [ 0.4569568   0.57259192  0.61653357  0.61916132  0.64551499  0.64736754\n",
      "  0.65315208  0.66434296  0.66521875  0.66653877  0.66780081  0.67036564\n",
      "  0.67635678  0.6852163   0.69113298  0.69290619  0.69451167  0.69470964\n",
      "  0.70028342  0.70089118] [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "\n",
      " Adding least certain\n",
      "combined df shape for vid aut (200000,) (200000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:1110: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/arunima/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number words in training corpus for keys vid aut 62251\n",
      "for size = 0, accuracy = 0.783, auc 0.850 auc-pr 0.968 f1_pos 0.861 f1_neg  0.504 f1_avg 0.683,avg uncertainty nan\n",
      "combined df shape for vid aut (205000,) (205000,)\n",
      "Number words in training corpus for keys vid aut 63279\n",
      "for size = 5000, accuracy = 0.847, auc 0.860 auc-pr 0.968 f1_pos 0.907 f1_neg  0.555 f1_avg 0.731,avg uncertainty 0.81\n",
      "combined df shape for vid aut (210000,) (210000,)\n",
      "Number words in training corpus for keys vid aut 64010\n",
      "for size = 10000, accuracy = 0.865, auc 0.858 auc-pr 0.966 f1_pos 0.920 f1_neg  0.565 f1_avg 0.742,avg uncertainty 0.83\n",
      "combined df shape for vid aut (225000,) (225000,)\n",
      "Number words in training corpus for keys vid aut 65905\n",
      "for size = 25000, accuracy = 0.885, auc 0.863 auc-pr 0.966 f1_pos 0.933 f1_neg  0.575 f1_avg 0.754,avg uncertainty 0.85\n",
      "combined df shape for vid aut (250000,) (250000,)\n",
      "Number words in training corpus for keys vid aut 68484\n",
      "for size = 50000, accuracy = 0.893, auc 0.866 auc-pr 0.966 f1_pos 0.939 f1_neg  0.573 f1_avg 0.756,avg uncertainty 0.87\n",
      "combined df shape for vid aut (275000,) (275000,)\n",
      "Number words in training corpus for keys vid aut 70684\n",
      "for size = 75000, accuracy = 0.896, auc 0.874 auc-pr 0.968 f1_pos 0.941 f1_neg  0.577 f1_avg 0.759,avg uncertainty 0.88\n",
      "combined df shape for vid aut (300000,) (300000,)\n",
      "Number words in training corpus for keys vid aut 72615\n",
      "for size = 100000, accuracy = 0.898, auc 0.881 auc-pr 0.970 f1_pos 0.942 f1_neg  0.585 f1_avg 0.764,avg uncertainty 0.89\n",
      "\n",
      " Adding most certain\n",
      "combined df shape for vid aut (400000,) (400000,)\n",
      "Number words in training corpus for keys vid aut 78991\n",
      "for size = 0, accuracy = 0.905, auc 0.910 auc-pr 0.979 f1_pos 0.945 f1_neg  0.650 f1_avg 0.798,avg certainty 0.92\n",
      "combined df shape for vid aut (205000,) (205000,)\n",
      "Number words in training corpus for keys vid aut 63153\n",
      "for size = 5000, accuracy = 0.778, auc 0.855 auc-pr 0.970 f1_pos 0.857 f1_neg  0.505 f1_avg 0.681,avg certainty 0.99\n",
      "combined df shape for vid aut (210000,) (210000,)\n",
      "Number words in training corpus for keys vid aut 63685\n",
      "for size = 10000, accuracy = 0.789, auc 0.864 auc-pr 0.972 f1_pos 0.865 f1_neg  0.520 f1_avg 0.693,avg certainty 0.98\n",
      "combined df shape for vid aut (225000,) (225000,)\n",
      "Number words in training corpus for keys vid aut 65100\n",
      "for size = 25000, accuracy = 0.809, auc 0.879 auc-pr 0.975 f1_pos 0.879 f1_neg  0.546 f1_avg 0.713,avg certainty 0.98\n",
      "combined df shape for vid aut (250000,) (250000,)\n",
      "Number words in training corpus for keys vid aut 67282\n",
      "for size = 50000, accuracy = 0.836, auc 0.894 auc-pr 0.978 f1_pos 0.898 f1_neg  0.582 f1_avg 0.740,avg certainty 0.97\n",
      "combined df shape for vid aut (275000,) (275000,)\n",
      "Number words in training corpus for keys vid aut 69413\n",
      "for size = 75000, accuracy = 0.861, auc 0.903 auc-pr 0.979 f1_pos 0.915 f1_neg  0.614 f1_avg 0.765,avg certainty 0.96\n",
      "combined df shape for vid aut (300000,) (300000,)\n",
      "Number words in training corpus for keys vid aut 71410\n",
      "for size = 100000, accuracy = 0.880, auc 0.908 auc-pr 0.980 f1_pos 0.928 f1_neg  0.639 f1_avg 0.783,avg certainty 0.95\n"
     ]
    }
   ],
   "source": [
    "#Improvement in accuracy with adding an actively selected sample of different sizes from the target domain to the source domain\n",
    "#This cell contains outcomes for using cosine distance as the metric for samples to add.\n",
    "\n",
    "vectKey = key1\n",
    "dfKey = key2\n",
    "size_list = [0,5000,10000,25000,50000,75000,100000]\n",
    "\n",
    "print('\\n Adding random samples from target domain')\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = dict_train_df[dfKey][:size]\n",
    "    labels_to_add = dict_train_y[dfKey][:size]\n",
    "    \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[dfKey][vectKey])[:,1]\n",
    "    auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[1] #pos class\n",
    "    f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[0]\n",
    "    f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = 'macro')\n",
    "    print('for size = %d, accuracy = %0.3f, auc %0.3f auc-pr %0.3f f1_pos %0.3f f1_neg %0.3f f1_avg %0.3f'\n",
    "          %(size,acc,auc,auc_pr,f1_pos,f1_neg,f1_avg))\n",
    "\n",
    "#Sorting the data frame and labels by cosine distance\n",
    "\n",
    "sort_ids = np.argsort(cosine_distance_train)\n",
    "cosine_distance_sorted = cosine_distance_train[sort_ids]\n",
    "#sort_ids = np.argsort(u_train_target_abs)\n",
    "#cosine_distance_sorted = u_train_target_abs[sort_ids]\n",
    "#print(sort_ids)\n",
    "df_target_ids_pre = dict_train_df[dfKey]\n",
    "df_target_labels_pre = dict_train_y[dfKey]\n",
    "print('pre sort',df_target_labels_pre[-20:])\n",
    "#print(type(df_target_labels_pre))\n",
    "df_target_ids_pre = df_target_ids_pre.iloc([sort_ids])\n",
    "df_target_ids = df_target_ids_pre[sort_ids]\n",
    "df_target_labels = df_target_labels_pre[sort_ids]\n",
    "print('\\n Post sort',df_target_labels[-20:],'first 20',cosine_distance_sorted[:20],cosine_distance_sorted[-20:])\n",
    "\n",
    "# print('\\n Adding least cosine distance')\n",
    "print('\\n Adding least certain')\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = df_target_ids[:size]\n",
    "    labels_to_add = df_target_labels[:size]\n",
    "    avg_cosine_distance = np.average(cosine_distance_sorted[:size])\n",
    "    \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[dfKey][vectKey])[:,1]\n",
    "    auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[1] #pos class\n",
    "    f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[0]\n",
    "    f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = 'macro')\n",
    "    print('for size = %d, accuracy = %0.3f, auc %0.3f auc-pr %0.3f f1_pos %0.3f f1_neg  %0.3f f1_avg %0.3f,avg uncertainty %0.2f'\n",
    "          %(size,acc,auc,auc_pr,f1_pos,f1_neg,f1_avg,avg_cosine_distance))\n",
    "    \n",
    "\n",
    "#print('\\n Adding most cosine distance')\n",
    "print('\\n Adding most certain')\n",
    "for size in size_list: \n",
    "    \n",
    "    #pick out samples from target domain\n",
    "    df_to_add = df_target_ids[-size:]\n",
    "    labels_to_add = df_target_labels[-size:]\n",
    "    avg_cosine_distance = np.average(cosine_distance_sorted[-size:])\n",
    "       \n",
    "    #Create combined dataframe of reviewText from both domains\n",
    "    temp_two_df_reviews = pd.concat([dict_train_df[vectKey].reviewText,df_to_add.reviewText])\n",
    "    temp_two_labels = np.concatenate([dict_train_y[vectKey],labels_to_add])\n",
    "    print('combined df shape for',vectKey,dfKey,temp_two_df_reviews.shape, temp_two_labels.shape)\n",
    "                \n",
    "    #create countVectorizer on combined dataframe of reviewText from both domains\n",
    "    dict_transfer_vect[vectKey][dfKey] = CountVectorizer(min_df=2, stop_words='english')\n",
    "    dict_transfer_vect[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].fit(temp_two_df_reviews)\n",
    "    print(\"Number words in training corpus for keys\",vectKey,dfKey,len(dict_transfer_vect[vectKey][dfKey].get_feature_names()))\n",
    "                \n",
    "    #create id vectors of reviews for each df, train and dev set, using combined countVectorizer\n",
    "    dict_transfer_train = dict_transfer_vect[vectKey][dfKey].transform(temp_two_df_reviews)\n",
    "    dict_transfer_dev_ids[vectKey][dfKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[vectKey].reviewText)\n",
    "    dict_transfer_dev_ids[dfKey][vectKey] = dict_transfer_vect[vectKey][dfKey].transform(dict_dev_df[dfKey].reviewText)\n",
    "                \n",
    "    #using vectKey as source, and dfkey as target\n",
    "    source_modelVect = MultinomialNB()\n",
    "    source_modelVect.fit(dict_transfer_train,temp_two_labels)\n",
    "    dict_dev_ypred = source_modelVect.predict(dict_transfer_dev_ids[dfKey][vectKey])\n",
    "    acc = accuracy_score(dict_dev_y[dfKey], dict_dev_ypred)\n",
    "    dict_dev_ypred_proba = source_modelVect.predict_proba(dict_transfer_dev_ids[dfKey][vectKey])[:,1]\n",
    "    auc = roc_auc_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    auc_pr = average_precision_score(dict_dev_y[dfKey], dict_dev_ypred_proba, average = 'weighted')\n",
    "    f1_pos = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[1] #pos class\n",
    "    f1_neg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = None)[0]\n",
    "    f1_avg = f1_score(dict_dev_y[dfKey], dict_dev_ypred,average = 'macro')\n",
    "    print('for size = %d, accuracy = %0.3f, auc %0.3f auc-pr %0.3f f1_pos %0.3f f1_neg  %0.3f f1_avg %0.3f,avg certainty %0.2f'\n",
    "          %(size,acc,auc,auc_pr,f1_pos,f1_neg,f1_avg,avg_cosine_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 8 6]\n",
      "pre sort df              reviewerID        asin                             reviewerName  \\\n",
      "496617   A3KLNIO5LSJUFX  B001BQISSS                                zephyrous   \n",
      "1200153   A5AMO3KTY3QQR  B008OEQ6WU  M. Chase \"Film,Theatre, Products Used.\"   \n",
      "409816   A3UXW18DP4WSD6  B000VZJH6W                        Richard \"Richard\"   \n",
      "886302   A1GSIW3K44CAWW  B004DRV5GY                                jeffs4589   \n",
      "\n",
      "        helpful                                         reviewText  overall  \\\n",
      "496617   [0, 0]  This ashtray looks smaller in person than it d...      4.0   \n",
      "1200153  [1, 1]  Easy to install this air filter does what it s...      5.0   \n",
      "409816   [0, 0]  I need to check to price at the auto stores to...      5.0   \n",
      "886302   [0, 0]  THE OLD LIGHTS WERE FOGGED OVER WITH THE NEW O...      5.0   \n",
      "\n",
      "                     summary  unixReviewTime   reviewTime  \n",
      "496617     Simple and cheap.      1398988800   05 2, 2014  \n",
      "1200153           Air Filter      1370217600   06 3, 2013  \n",
      "409816         great to have      1393718400   03 2, 2014  \n",
      "886302   GREAT FOR THE PRICE      1373414400  07 10, 2013  \n",
      "sort indices [1 0 3 2]\n",
      "sorted array [2 4 6 8]\n",
      "sorted dataframe              reviewerID        asin                             reviewerName  \\\n",
      "1200153   A5AMO3KTY3QQR  B008OEQ6WU  M. Chase \"Film,Theatre, Products Used.\"   \n",
      "496617   A3KLNIO5LSJUFX  B001BQISSS                                zephyrous   \n",
      "886302   A1GSIW3K44CAWW  B004DRV5GY                                jeffs4589   \n",
      "409816   A3UXW18DP4WSD6  B000VZJH6W                        Richard \"Richard\"   \n",
      "\n",
      "        helpful                                         reviewText  overall  \\\n",
      "1200153  [1, 1]  Easy to install this air filter does what it s...      5.0   \n",
      "496617   [0, 0]  This ashtray looks smaller in person than it d...      4.0   \n",
      "886302   [0, 0]  THE OLD LIGHTS WERE FOGGED OVER WITH THE NEW O...      5.0   \n",
      "409816   [0, 0]  I need to check to price at the auto stores to...      5.0   \n",
      "\n",
      "                     summary  unixReviewTime   reviewTime  \n",
      "1200153           Air Filter      1370217600   06 3, 2013  \n",
      "496617     Simple and cheap.      1398988800   05 2, 2014  \n",
      "886302   GREAT FOR THE PRICE      1373414400  07 10, 2013  \n",
      "409816         great to have      1393718400   03 2, 2014  \n",
      "last obs             reviewerID        asin       reviewerName helpful  \\\n",
      "886302  A1GSIW3K44CAWW  B004DRV5GY          jeffs4589  [0, 0]   \n",
      "409816  A3UXW18DP4WSD6  B000VZJH6W  Richard \"Richard\"  [0, 0]   \n",
      "\n",
      "                                               reviewText  overall  \\\n",
      "886302  THE OLD LIGHTS WERE FOGGED OVER WITH THE NEW O...      5.0   \n",
      "409816  I need to check to price at the auto stores to...      5.0   \n",
      "\n",
      "                    summary  unixReviewTime   reviewTime  \n",
      "886302  GREAT FOR THE PRICE      1373414400  07 10, 2013  \n",
      "409816        great to have      1393718400   03 2, 2014  \n"
     ]
    }
   ],
   "source": [
    "# temp code to figure and confirm sorting of arrays and dataframes\n",
    "arr1 = np.array([2,1,4,3])\n",
    "arr2 = np.array([4,2,8,6])\n",
    "print(arr2)\n",
    "df = dict_train_df['aut'][:4]\n",
    "print('pre sort df',df)\n",
    "sort_id = np.argsort(arr1)\n",
    "print('sort indices',sort_id)\n",
    "arr2 = arr2[sort_id]\n",
    "print('sorted array',arr2)\n",
    "df = df.iloc([sort_id])\n",
    "df1 = df[sort_id]\n",
    "#print(df[sort_id])\n",
    "print('sorted dataframe',df1)\n",
    "print('last obs',df1[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_weights = nb.feature_log_prob_[1,] - nb.feature_log_prob_[0,]  # populate this with actual values\n",
    "top_negative_features = np.argsort(linear_weights)[:10]\n",
    "top_positive_features = np.argsort(linear_weights)[-10:]\n",
    "\n",
    "#### END(YOUR CODE) ####\n",
    "\n",
    "print(\"Most negative features:\")\n",
    "for idx in top_negative_features:\n",
    "    print(\"  {:s} ({:.02f})\".format(ds.vocab.id_to_word[idx], \n",
    "                                    linear_weights[idx]))\n",
    "print(\"\")\n",
    "print(\"Most positive features:\")\n",
    "for idx in top_positive_features:\n",
    "    print(\"  {:s} ({:.02f})\".format(ds.vocab.id_to_word[idx], \n",
    "                                    linear_weights[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results from test runs for transfer learning based on cosine distance\n",
    "\n",
    "Overall transfer accuracy 0.76186\n",
    "Overall AUC 0.841640426022\n",
    "\n",
    "Buckets of cosine distance 0.0 to 0.1, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.1 to 0.1, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.1 to 0.2, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.2 to 0.2, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.2 to 0.2, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.2 to 0.3, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.3 to 0.4, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.4 to 0.4, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.4 to 0.5, transfer accuracy: 1.00 auc 0.0 # reviews 1 % pos 1.0\n",
    "Buckets of cosine distance 0.5 to 0.5, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.5 to 0.6, transfer accuracy: nan auc 0.0 # reviews 0 % pos nan\n",
    "Buckets of cosine distance 0.6 to 0.6, transfer accuracy: 1.00 auc 0.0 # reviews 1 % pos 0.0\n",
    "Buckets of cosine distance 0.6 to 0.7, transfer accuracy: 0.75 auc 0.333333333333 # reviews 4 % pos 0.75\n",
    "Buckets of cosine distance 0.7 to 0.7, transfer accuracy: 0.90 auc 0.666666666667 # reviews 10 % pos 0.9\n",
    "Buckets of cosine distance 0.7 to 0.8, transfer accuracy: 0.80 auc 0.923076923077 # reviews 40 % pos 0.975\n",
    "Buckets of cosine distance 0.8 to 0.8, transfer accuracy: 0.86 auc 0.918264442231 # reviews 534 % pos 0.940074906367\n",
    "Buckets of cosine distance 0.8 to 0.9, transfer accuracy: 0.80 auc 0.854634836004 # reviews 6610 % pos 0.927534039334\n",
    "Buckets of cosine distance 0.9 to 0.9, transfer accuracy: 0.78 auc 0.865238149244 # reviews 34715 % pos 0.902088434394\n",
    "Buckets of cosine distance 0.9 to 1.0, transfer accuracy: 0.76 auc 0.848956565647 # reviews 69589 % pos 0.855709954159\n",
    "Buckets of cosine distance 1.0 to 1.0, transfer accuracy: 0.75 auc 0.818424003384 # reviews 38440 % pos 0.796383975026\n",
    "\n",
    "Results from adding random samples of target domain\n",
    "combined df shape for vid aut (500000,) (500000,)\n",
    "Number words in training corpus for keys vid aut 99497\n",
    "for size = 0, accuracy = 0.788, auc 0.852\n",
    "combined df shape for vid aut (525000,) (525000,)\n",
    "Number words in training corpus for keys vid aut 102022\n",
    "for size = 25000, accuracy = 0.846, auc 0.876\n",
    "combined df shape for vid aut (550000,) (550000,)\n",
    "Number words in training corpus for keys vid aut 103999\n",
    "for size = 50000, accuracy = 0.864, auc 0.884\n",
    "combined df shape for vid aut (575000,) (575000,)\n",
    "Number words in training corpus for keys vid aut 105819\n",
    "for size = 75000, accuracy = 0.876, auc 0.889\n",
    "combined df shape for vid aut (600000,) (600000,)\n",
    "Number words in training corpus for keys vid aut 107436\n",
    "for size = 100000, accuracy = 0.883, auc 0.893\n",
    "combined df shape for vid aut (650000,) (650000,)\n",
    "Number words in training corpus for keys vid aut 110460\n",
    "for size = 150000, accuracy = 0.891, auc 0.899\n",
    "combined df shape for vid aut (700000,) (700000,)\n",
    "Number words in training corpus for keys vid aut 113417\n",
    "for size = 200000, accuracy = 0.896, auc 0.902\n",
    "combined df shape for vid aut (800000,) (800000,)\n",
    "Number words in training corpus for keys vid aut 118653\n",
    "for size = 300000, accuracy = 0.902, auc 0.907\n",
    "\n",
    "Results from adding sorted samples:\n",
    "Adding least cosine distance first\n",
    "combined df shape for vid aut (525000,) (525000,)\n",
    "Number words in training corpus for keys vid aut 102434\n",
    "for size = 25000, accuracy = 0.87, auc 0.86\n",
    "combined df shape for vid aut (550000,) (550000,)\n",
    "Number words in training corpus for keys vid aut 104597\n",
    "for size = 50000, accuracy = 0.88, auc 0.86\n",
    "combined df shape for vid aut (575000,) (575000,)\n",
    "Number words in training corpus for keys vid aut 106436\n",
    "for size = 75000, accuracy = 0.89, auc 0.86\n",
    "combined df shape for vid aut (600000,) (600000,)\n",
    "Number words in training corpus for keys vid aut 108115\n",
    "for size = 100000, accuracy = 0.89, auc 0.87\n",
    "combined df shape for vid aut (650000,) (650000,)\n",
    "Number words in training corpus for keys vid aut 111329\n",
    "for size = 150000, accuracy = 0.90, auc 0.87\n",
    "combined df shape for vid aut (700000,) (700000,)\n",
    "Number words in training corpus for keys vid aut 114161\n",
    "for size = 200000, accuracy = 0.90, auc 0.88\n",
    "Adding most cosine distance first\n",
    "combined df shape for vid aut (525000,) (525000,)\n",
    "Number words in training corpus for keys vid aut 102073\n",
    "for size = 25000, accuracy = 0.793, auc 0.869\n",
    "combined df shape for vid aut (550000,) (550000,)\n",
    "Number words in training corpus for keys vid aut 103710\n",
    "for size = 50000, accuracy = 0.806, auc 0.879\n",
    "combined df shape for vid aut (575000,) (575000,)\n",
    "Number words in training corpus for keys vid aut 105211\n",
    "for size = 75000, accuracy = 0.816, auc 0.886\n",
    "combined df shape for vid aut (600000,) (600000,)\n",
    "Number words in training corpus for keys vid aut 106703\n",
    "for size = 100000, accuracy = 0.827, auc 0.892\n",
    "combined df shape for vid aut (650000,) (650000,)\n",
    "Number words in training corpus for keys vid aut 109722\n",
    "for size = 150000, accuracy = 0.848, auc 0.901\n",
    "combined df shape for vid aut (700000,) (700000,)\n",
    "Number words in training corpus for keys vid aut 112695\n",
    "for size = 200000, accuracy = 0.867, auc 0.907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping track of results from test runs\n",
    "With number in train set = 10000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 88.74%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 67.16%\n",
    "    Vocab Size : 38696\n",
    "    \n",
    "With number in train set = 50000 (excl 3 ratings)   \n",
    "    Accuracy on dev set for binary prediction: 91.33%   \n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 69.33% \n",
    "    Vocab Size : ~ ..\n",
    "    \n",
    "With number in train set = 100000 (excl 3 ratings)\n",
    "    Accuracy on dev set for binary prediction: 91.56%   \n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.42%\n",
    "    Vocab Size : 105304\n",
    "\n",
    "With number in train set = 500000, dev set = 150000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 91.73%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.95%\n",
    "    vocab size 307822\n",
    "    \n",
    "With number in train set = 1200000, dev set = 360000 (excl 3 ratings)    \n",
    "    Accuracy on dev set for binary prediction: 91.92%\n",
    "    Accuracy on dev set for 4 level (1,2,4,5) prediction: 71.24%\n",
    "    vocab size 674074 (not repeated with correction for vocab)\n",
    "    \n",
    "### Output from trying different pre-processing with the toys review set.\n",
    " \n",
    " Accuracy on dev set for binary prediction: 91.69%\n",
    "classification report naive bayes binary classification \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.70      0.77      0.74     22472\n",
    "        1.0       0.96      0.94      0.95    127528\n",
    "\n",
    "avg / total       0.92      0.92      0.92    150000\n",
    "\n",
    "Accuracy on dev set for binary prediction with count vectorizer: 91.92%\n",
    "classification report naive bayes binary classification with count vectorizer \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.71      0.79      0.75     22472\n",
    "        1.0       0.96      0.94      0.95    127528\n",
    "\n",
    "avg / total       0.92      0.92      0.92    150000\n",
    "\n",
    "Accuracy on dev set for binary prediction with tfidf: 90.13%\n",
    "classification report naive bayes binary classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.90      0.38      0.54     22472\n",
    "        1.0       0.90      0.99      0.94    127528\n",
    "\n",
    "avg / total       0.90      0.90      0.88    150000\n",
    "\n",
    "Accuracy on dev set for 4 level (1,2,4,5) prediction: 70.91%\n",
    "classification report naive bayes multinomial classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          1       0.60      0.74      0.66     13975\n",
    "          2       0.32      0.05      0.09      8497\n",
    "          4       0.42      0.34      0.37     29733\n",
    "          5       0.80      0.87      0.83     97795\n",
    "\n",
    "avg / total       0.68      0.71      0.68    150000\n",
    "\n",
    "### Output from simple ratings prediction with video games review set.\n",
    "\n",
    "train set size : 10000, dev set size : 3000\n",
    "Accuracy on dev set for binary prediction with count vectorizer: 88.93%\n",
    "classification report naive bayes binary classification with count vectorizer \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.77      0.54      0.64       534\n",
    "        1.0       0.91      0.96      0.93      2466\n",
    "\n",
    "avg / total       0.88      0.89      0.88      3000\n",
    "\n",
    "Accuracy on dev set for binary prediction with tfidf: 84.93%\n",
    "classification report naive bayes binary classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.95      0.16      0.28       534\n",
    "        1.0       0.85      1.00      0.92      2466\n",
    "\n",
    "avg / total       0.86      0.85      0.80      3000\n",
    "\n",
    "Using SVM, with Count Vectorizer pre-processing:\n",
    "Accuracy on dev set for binary prediction: 82.20%\n",
    "classification report svm              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.00      0.00      0.00       534\n",
    "        1.0       0.82      1.00      0.90      2466\n",
    "\n",
    "avg / total       0.68      0.82      0.74      3000\n",
    "\n",
    "time taken for SVM 48.42102265357971\n",
    "\n",
    "Using SVM with TFIDF pre-processing:\n",
    "Accuracy on dev set for binary prediction: 82.20%\n",
    "classification report svm              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.00      0.00      0.00       534\n",
    "        1.0       0.82      1.00      0.90      2466\n",
    "\n",
    "avg / total       0.68      0.82      0.74      3000\n",
    "\n",
    "train set size : 100000, dev set size : 30000\n",
    "Accuracy on dev set for binary prediction with count vectorizer: 89.12%\n",
    "classification report naive bayes binary classification with count vectorizer \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.72      0.71      0.71      5728\n",
    "        1.0       0.93      0.93      0.93     24272\n",
    "\n",
    "avg / total       0.89      0.89      0.89     30000\n",
    "\n",
    "Accuracy on dev set for binary prediction with tfidf: 86.04%\n",
    "classification report naive bayes binary classification with tfidf \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.91      0.30      0.45      5728\n",
    "        1.0       0.86      0.99      0.92     24272\n",
    "\n",
    "avg / total       0.87      0.86      0.83     30000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for transfer learning from toys to video games\n",
    "number words in training corpus for toys: 63984\n",
    "toys dataset id shapes (100000, 63984) (30000, 63984)\n",
    "number words in training corpus for video games: 98899\n",
    "videos dataset id shapes (100000, 98899) (30000, 98899)\n",
    "number words in training corpus for automobiles: 59468\n",
    "automobile dataset id shapes (100000, 59468) (30000, 59468)\n",
    "number words in training corpus for home and kitchen: 57884\n",
    "home and kitchen dataset id shapes (100000, 57884) (30000, 57884)\n",
    "\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.23%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.74      0.74      0.74      4503\n",
    "        1.0       0.95      0.95      0.95     25497\n",
    "\n",
    "avg / total       0.92      0.92      0.92     30000\n",
    "\n",
    "Accuracy on video games dev set for binary prediction with video games naive bayes model: 89.16%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.72      0.71      0.71      5725\n",
    "        1.0       0.93      0.93      0.93     24275\n",
    "\n",
    "avg / total       0.89      0.89      0.89     30000\n",
    "\n",
    "Accuracy on autos dev set for binary prediction with autos naive bayes model: 91.93%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.78      0.61      0.69      4323\n",
    "        1.0       0.94      0.97      0.95     25677\n",
    "\n",
    "avg / total       0.91      0.92      0.92     30000\n",
    "\n",
    "Accuracy on home and kitchen dev set for binary prediction with home and kitchen naive bayes model: 91.37%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.76      0.71      0.73      5072\n",
    "        1.0       0.94      0.96      0.95     24928\n",
    "\n",
    "avg / total       0.91      0.91      0.91     30000\n",
    "\n",
    "### Transfer learning:\n",
    "\n",
    "Accuracy on video games dev set for binary prediction with toys naive bayes model: 86.99%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.66      0.65      0.66      5725\n",
    "        1.0       0.92      0.92      0.92     24275\n",
    "\n",
    "avg / total       0.87      0.87      0.87     30000\n",
    "\n",
    "Accuracy on automobiles dev set for binary prediction with toys naive bayes model: 76.06%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.36      0.88      0.51      4323\n",
    "        1.0       0.97      0.74      0.84     25677\n",
    "\n",
    "avg / total       0.88      0.76      0.79     30000\n",
    "\n",
    "Accuracy on home and kitchen dev set for binary prediction with toys naive bayes model: 85.78%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.55      0.85      0.67      5072\n",
    "        1.0       0.97      0.86      0.91     24928\n",
    "\n",
    "avg / total       0.90      0.86      0.87     30000\n",
    "\n",
    "Accuracy on toys dev set for binary prediction with video games naive bayes model: 91.53%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.76      0.63      0.69      4503\n",
    "        1.0       0.94      0.97      0.95     25497\n",
    "\n",
    "avg / total       0.91      0.92      0.91     30000\n",
    "\n",
    "Accuracy on automobiles dev set for binary prediction with video games naive bayes model: 80.50%   \n",
    "Corresponding classification report              precision    recall  f1-score   support\n",
    "\n",
    "        0.0       0.41      0.77      0.53      4323\n",
    "        1.0       0.96      0.81      0.88     25677\n",
    "\n",
    "avg / total       0.88      0.81      0.83     30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from running Naive Bayes for all 4 dfs, with different train set size.\n",
    "\n",
    "Train data_set size = 50000\n",
    "Number words in training corpus for toys 45973\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.46%\n",
    "Number words in training corpus for vid 68303\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 89.37%\n",
    "Number words in training corpus for aut 41130\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.57%\n",
    "Number words in training corpus for hnk 41378\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.43%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 92.5% 91.4% 90.9% 91.2%\n",
    "vid  87.1% 89.4% 86.8% 87.3%\n",
    "aut  76.7% 80.0% 91.6% 84.6%\n",
    "hnk  86.1% 86.5% 90.3% 91.4%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid  aut  hnk\n",
    "toys  0.0%  1.0% 1.6% 1.3%\n",
    "vid   2.2%  0.0% 2.5% 2.1%\n",
    "aut  14.9% 11.5% 0.0% 7.0%\n",
    "hnk   5.3%  4.9% 1.1% 0.0%\n",
    "\n",
    " Train data_set size = 100000\n",
    "Number words in training corpus for toys 64698\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 92.17%\n",
    "Number words in training corpus for vid 98625\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 89.22%\n",
    "Number words in training corpus for aut 59179\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.56%\n",
    "Number words in training corpus for hnk 57706\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.56%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 92.2% 91.3% 91.3% 91.1%\n",
    "vid  86.6% 89.2% 87.4% 87.3%\n",
    "aut  75.4% 78.8% 91.6% 83.6%\n",
    "hnk  85.8% 86.5% 90.9% 91.6%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid  aut  hnk\n",
    "toys  0.0%  0.8% 0.9% 1.0%\n",
    "vid   2.6%  0.0% 1.8% 1.9%\n",
    "aut  16.2% 12.8% 0.0% 8.0%\n",
    "hnk   5.8%  5.1% 0.7% 0.0%\n",
    "\n",
    " Train data_set size = 250000\n",
    "Number words in training corpus for toys 104512\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.92%\n",
    "Number words in training corpus for vid 165841\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 89.01%\n",
    "Number words in training corpus for aut 97914\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 91.87%\n",
    "Number words in training corpus for hnk 93561\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.58%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 91.9% 91.4% 91.8% 91.3%\n",
    "vid  86.1% 89.0% 88.0% 87.5%\n",
    "aut  72.7% 78.0% 91.9% 83.6%\n",
    "hnk  84.9% 86.3% 91.5% 91.6%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid  aut  hnk\n",
    "toys  0.0%  0.6% 0.1% 0.7%\n",
    "vid   2.9%  0.0% 1.0% 1.6%\n",
    "aut  19.2% 13.8% 0.0% 8.3%\n",
    "hnk   6.7%  5.3% 0.1% 0.0%\n",
    "\n",
    " Train data_set size = 500000\n",
    "Number words in training corpus for toys 151534\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.81%\n",
    "Number words in training corpus for vid 249256\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.99%\n",
    "Number words in training corpus for aut 144802\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 92.06%\n",
    "Number words in training corpus for hnk 137575\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.55%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 91.8% 91.4% 91.9% 91.4%\n",
    "vid  85.9% 89.0% 88.4% 87.9%\n",
    "aut  72.8% 78.7% 92.1% 83.6%\n",
    "hnk  84.5% 86.9% 91.7% 91.6%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut  hnk\n",
    "toys  0.0%  0.4% -0.1% 0.5%\n",
    "vid   3.1%  0.0%  0.6% 1.1%\n",
    "aut  19.3% 13.3%  0.0% 8.5%\n",
    "hnk   7.1%  4.7% -0.2% 0.0%\n",
    "\n",
    " Train data_set size = 1000000\n",
    "Number words in training corpus for toys 224573\n",
    "Accuracy on toys dev set for binary prediction with toys naive bayes model: 91.74%\n",
    "Number words in training corpus for vid 309416\n",
    "Accuracy on vid dev set for binary prediction with toys naive bayes model: 88.89%\n",
    "Number words in training corpus for aut 185933\n",
    "Accuracy on aut dev set for binary prediction with toys naive bayes model: 92.03%\n",
    "Number words in training corpus for hnk 204991\n",
    "Accuracy on hnk dev set for binary prediction with toys naive bayes model: 91.50%\n",
    "Effectiveness of transfer learning with Naive Bayes:\n",
    "Accuracy of rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut   hnk\n",
    "toys 91.7% 91.5% 91.9% 91.4%\n",
    "vid  85.8% 88.9% 88.7% 88.0%\n",
    "aut  73.0% 78.6% 92.0% 83.3%\n",
    "hnk  84.4% 86.5% 91.8% 91.5%\n",
    "Transfer loss on rating predictions\n",
    "Colums = source domain, Rows = target domain\n",
    "\n",
    "      toys   vid   aut  hnk\n",
    "toys  0.0%  0.3% -0.2% 0.3%\n",
    "vid   3.1%  0.0%  0.2% 0.9%\n",
    "aut  19.0% 13.5%  0.0% 8.7%\n",
    "hnk   7.1%  5.0% -0.3% 0.0%\n",
    "\n",
    "from scipy.stats import entropy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
