{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/ubuntu/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/ubuntu/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting nltk\n",
      "Requirement already up-to-date: six in /usr/local/lib/python3.5/dist-packages (from nltk)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.2.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/ubuntu/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/ubuntu/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/ubuntu/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/ubuntu/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting tflearn\n",
      "  Downloading tflearn-0.3.2.tar.gz (98kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 5.7MB/s a 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from tflearn)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from tflearn)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.5/dist-packages (from tflearn)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.5/dist-packages (from Pillow->tflearn)\n",
      "Installing collected packages: tflearn\n",
      "  Running setup.py install for tflearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed tflearn-0.3.2\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 (default, Sep 14 2017, 22:51:06) \n",
      "[GCC 5.4.0 20160609]\n",
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "# Install a few python packages using pip\n",
    "from common import utils\n",
    "utils.require_package('nltk')\n",
    "utils.require_package(\"wget\")      # for fetching dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Standard python helper libraries.\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import os, sys, time\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "# Numerical manipulation libraries.\n",
    "import numpy as np\n",
    "from scipy import stats, optimize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Helper libraries\n",
    "from common import utils, vocabulary, glove_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read the amazon review data files\n",
    "def parse(path):\n",
    "  print('start parse')\n",
    "  start_parse = time.time()\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "  end_parse = time.time()\n",
    "  print('end parse with time for parse',end_parse - start_parse)\n",
    "\n",
    "def getDF(path):\n",
    "  print('start getDF')\n",
    "  start = time.time()\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  print('end getDF')\n",
    "  end = time.time()\n",
    "  print('time taken to load data = ',end-start)\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "#df = getDF('reviews_Toys_and_Games.json.gz') #old def function corresponding to the step bt step vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.100d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 100))\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Using pretrained GLove embeddings\n",
    "hands = glove_helper.Hands(ndim=100)  # 50, 100, 200, 300 dim are available\n",
    "hands.shape\n",
    "print(hands.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 138.08097743988037\n",
      "end getDF\n",
      "time taken to load data =  138.08151531219482\n"
     ]
    }
   ],
   "source": [
    "df_toys = getDF('reviews_Toys_and_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_vid = getDF('reviews_Video_Games.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 76.23472046852112\n",
      "end getDF\n",
      "time taken to load data =  76.2351188659668\n"
     ]
    }
   ],
   "source": [
    "df_aut = getDF('reviews_Automotive.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start getDF\n",
      "start parse\n",
      "end parse with time for parse 243.03609085083008\n",
      "end getDF\n",
      "time taken to load data =  243.0368616580963\n"
     ]
    }
   ],
   "source": [
    "df_hnk = getDF('reviews_Home_and_Kitchen.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hnk.to_pickle('./df.hnk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Home and Kitchen reviews examples\n",
      "\n",
      "A210NOCSTBT4OD\n",
      "Have you ever thought about how you met your best friend? Was it normal, or was it wacky - like how Elias met Shohei? Pulling a boa constrictor snake named Mathilda out of your backpack can make a remarkable first impression! This book is about three best friends Elias, Honoria, and Shohei, who are united against \"That Which Is The Peshtigo School\". Their goal is to make it through the annual school science fair, but things don't always go as planned.Elias is part of a family made up of science fanatics who would do anything to win a science fair. Elias isn't exactly what you'd call the ambitious type, especially when it comes to science fairs. So he becomes like Galileo and \"retests\" one of his sibling's past projects. Honoria loves to be ambitious, especially when it comes to being a legal counsel extraordinaire. But when she faces a bigger challenge than beating Goliath Reed or getting a piranha to become vegetarian, she doesn't know if she can make it. Shohei is an all around slacker who tries to mooch off Elias instead of creating something on his own. His adoptive parents are constantly encouraging him to start \"hearing\" his ancestors. His mom has even turned Shohei's room into what looks like a walk-in Japanese museum exhibit!This book is laugh out loud hilarious and the more you read, the more exciting and unexpected it gets. I love the title on this book because it really made me laugh and want to read the book. I also like how people so different from one another can be such close friends. There is not much excitement in the beginning, but it builds up very quickly. So if you like that type of story, then this is the book for you.\n",
      "A28ILV4TOG8BH2\n",
      "The butter dish is serving us well, and keeping the butter fresh and healthy. Couldn't be happier with it, and the color is a pleasing green.\n"
     ]
    }
   ],
   "source": [
    "#Looking at a few examples of review text\n",
    "# print('Toys reviews examples\\n')\n",
    "# for i in range(1):\n",
    "#     print(df_toys['reviewerID'].iloc[i])\n",
    "#     print(df_toys['reviewText'].iloc[i])\n",
    "\n",
    "# print('\\n Video games reviews examples\\n')\n",
    "# for i in range(1):\n",
    "#     print(df_vid['reviewerID'].iloc[i])\n",
    "#     print(df_vid['reviewText'].iloc[i])\n",
    "    \n",
    "# print('\\n Automobile reviews examples\\n')\n",
    "# for i in range(1):\n",
    "#     print(df_aut['reviewerID'].iloc[i])\n",
    "#     print(df_aut['reviewText'].iloc[i])\n",
    "    \n",
    "print('\\n Home and Kitchen reviews examples\\n')\n",
    "for i in range(2):\n",
    "    print(df_hnk['reviewerID'].iloc[i])\n",
    "    print(df_hnk['reviewText'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home and Kitchen reviews train, dev and test set dataframe shape: (2552355, 9) (850785, 9) (850786, 9)\n"
     ]
    }
   ],
   "source": [
    "# Create train,dev,test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train_toys,devtest = train_test_split(df_toys, test_size=0.4, random_state=42)\n",
    "# dev_toys,test_toys = train_test_split(devtest,test_size = 0.5, random_state=42)\n",
    "# print('Toy reviews train, dev and test set dataframe shape:',train_toys.shape,dev_toys.shape,test_toys.shape)\n",
    "\n",
    "#For Video games reviews\n",
    "# train_vid,devtest = train_test_split(df_vid, test_size=0.4)\n",
    "# dev_vid,test_vid = train_test_split(devtest,test_size = 0.5)\n",
    "# print('Video games reviews train, dev and test set dataframe shape:',train_vid.shape,dev_vid.shape,test_vid.shape)\n",
    "\n",
    "#For Auto reviews\n",
    "# train_aut,devtest = train_test_split(df_aut, test_size=0.4)\n",
    "# dev_aut,test_aut = train_test_split(devtest,test_size = 0.5)\n",
    "# print('Auto reviews train, dev and test set dataframe shape:',train_aut.shape,dev_aut.shape,test_aut.shape)\n",
    "\n",
    "#For Home and Kitchen reviews\n",
    "train_hnk,devtest = train_test_split(df_hnk, test_size=0.4)\n",
    "dev_hnk,test_hnk = train_test_split(devtest,test_size = 0.5)\n",
    "print('Home and Kitchen reviews train, dev and test set dataframe shape:',train_hnk.shape,dev_hnk.shape,test_hnk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create a smaller sized train and dev data set. Enables testing accuracy for different sizes.\n",
    "#Also binarizes the labels. Ratings of 1,2 and to 0; Ratings of 4,5 to 1.\n",
    "\n",
    "def set_df_size(size,data_train,data_dev):\n",
    "    size_train = size\n",
    "    len_max_train = data_train[data_train.overall!=3].shape[0] #max possible length of train data set taking out the 3 ratings.\n",
    "    #print(\"Number of reviews with ratings != 3 in train set\",len_max_train)\n",
    "    temp_size_train = min(len_max_train,size_train)\n",
    "\n",
    "    len_max_dev = data_dev[data_dev.overall!=3].shape[0]\n",
    "    #print(\"Number of reviews with ratings != 3 in dev set\",len_max_dev)\n",
    "    temp_size_dev = min(len_max_dev,int(0.3*temp_size_train)) #making the dev set about 0.3 times the train set.\n",
    "\n",
    "    temp_train_data = data_train[data_train.overall != 3][:temp_size_train]\n",
    "    #print('Size of train data',temp_train_data.shape)\n",
    "    #print(temp_train_data.groupby('overall').count())\n",
    "    #print(temp_train_toys[:5])\n",
    "\n",
    "    temp_dev_data = data_dev[data_dev.overall!=3][:temp_size_dev]\n",
    "    #print('Size of dev data',temp_dev_data.shape)\n",
    "    #print(temp_dev_data.groupby('overall').count())\n",
    "    #print(temp_dev_data[:2])\n",
    "    \n",
    "    #Binarize ratings\n",
    "    temp_train_y = np.zeros(temp_size_train)\n",
    "    temp_train_y[temp_train_data.overall > 3] = 1\n",
    "    temp_dev_y = np.zeros(temp_size_dev)\n",
    "    temp_dev_y[temp_dev_data.overall>3] = 1\n",
    "    #print('binarized y shape',temp_train_y.shape,temp_dev_y.shape)\n",
    "    #print(temp_dev_y[:20],data_dev.overall[:20])\n",
    "    return temp_train_data,temp_dev_data,temp_train_y,temp_dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Home and Kitchen reviews\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_df = ['toys','vid','aut','hnk'] #list of keys that refer to each dataframe. Adding a new dataframe would require updating this list\n",
    "dict_train_df = {} #Dict to store train input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_dev_df = {} #Dict to store dev input data frame for each domain, can be accessed by using domain name as key\n",
    "dict_train_y = {} #Dict to store binarized train data label for each domain\n",
    "dict_dev_y = {} #Dict to store binarized dev data label for each domain\n",
    "#print(len(dict_train_df))\n",
    "\n",
    "def create_sized_data(size = 100000):\n",
    "    size_train = size #Set size of train set here. This is a hyperparameter.\n",
    "#     key = list_df[0]\n",
    "#     #print('Toys reviews\\n')\n",
    "#     dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_toys,dev_toys)\n",
    "#     #print('\\n Video games reviews\\n')\n",
    "#     key = list_df[1]\n",
    "#     dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_vid,dev_vid)\n",
    "#     #print('\\n Auto reviews\\n')\n",
    "#     key = list_df[2]\n",
    "#     dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_aut,dev_aut)\n",
    "    print('\\n Home and Kitchen reviews\\n')\n",
    "    key = list_df[3]\n",
    "    dict_train_df[key], dict_dev_df[key], dict_train_y[key], dict_dev_y[key] = set_df_size(size_train,train_hnk,dev_hnk)\n",
    "    \n",
    "create_sized_data()\n",
    "#print(len(dict_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_length = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "(100000, 150)\n",
      "y train shape (100000,)\n",
      "Total words: 91173\n",
      "Time taken to vectorize 100000 size dataframe 16.284374237060547\n",
      "sample review I have been using Neat-os around the house for about a year, and I love them! I use them for lunches for my kids and myself, snacks, and even storing lettuce. I also love their see-through feature for things like holding change, storing jewelry for traveling, and art supplies. It's great to have a green substitute for plastic bags that I can throw in the dishwasher or washing machine. I usually just air dry them & have never had one fall apart. I also love the zippers, just as convenient as Ziploc and much better than some of the other reusable bags that have Velcro that gets dirty and worn out easily. You;re not going to be able to use them for liquid storage, marinating, or other super messy things, but, hey, that's what my glass storage bowls are for! If you are committed to phasing out disposable products in your kitchen and home, these are a great addition to your repertoire of green products. Highly recommend! \n",
      "\n",
      "corresponding ids\n",
      " [  3  84  66 302 303 233  11 304  99 305  55 306  10   3  16 307   3 166\n",
      " 307  99 308  99 309 310  10 311 312  10 313 314 315   3 316  16 317 318\n",
      " 319  99 320 321 322 323 314 324  99 325  10 326 327  71  82  53  84  55\n",
      " 328 329  99 141 330 112   3 331 332  24  11 333 334 335  83   3 336 290\n",
      " 337 338 307  84 114 115 339 340 341   3 316  16  11 342 290 291 343 291\n",
      " 344  10 240 345  97 346  26  11 123 347 330 112  84 348 112 349 350  10\n",
      " 351 153 352 353 354 219  67  53 355 356  53 166 307  99 357 358 359 334\n",
      " 123  72 360 320 361 362 363   2 309 364 358 365 144  99 147 148 144 366\n",
      "  53 367 153 368 369  24]\n",
      "sample review I was skeptical.  But this is truely an exceptional product.  In one fill up I was able to steam my interview suit, a blouse, and a formal overcoat, and had water left in the reserve for about two more garments.  I used all the attachments because the variation in fabrics required me to.  It was just great, the steamer handled every curve and cleared up all the pet hair and fuzz on the garments as well.  I needed a brush for the overcoat, well I had one.  I needed a fine fabric filter, well, I had that too.  And my wool skirt looks like new.  I know this sounds like I was paid for this review, but I truly am more than satisfied.  It takes a few passes to get the hang of it.  But it was so easy and my clothes look better than if they came back from the cleaners.  This is a winner and the machine that I have been waiting for for 20 years.  Thank you Shark. \n",
      "\n",
      "corresponding ids\n",
      " [    3    43  1255  1128    17     7 14840   161  4748   630  1226   339\n",
      "  1011   177     3    43   356    53   768   309 42897  6089    55  9598\n",
      "    10    55  3355     0    10   115   539  1372    24    11  4371    99\n",
      "   305    29   585  3301     3    85    61    11   848    41    11 19833\n",
      "    24  6087  2973   529    53   631    43   290    82    11   466  1622\n",
      "  1504  1521    10  8517   177    61    11  4647  1031    10   729   154\n",
      "    11  3301   291    92     3   229    55  1530    99    11     0    92\n",
      "     3   115   339     3   229    55   754  4078  3322    92     3   115\n",
      "   112   253  2235   309  2320 10623   683   321   451     3   448    17\n",
      "  3142   321     3    43  1481    99    17  1347   361     3  3243   690\n",
      "   585    97  2923   631  3019    55   733  6908    53   116    11  2967\n",
      "    26    42  1128    42    43   257    73    10   309  2781   176   345\n",
      "    97   300   387   222    52   435]\n"
     ]
    }
   ],
   "source": [
    "vocab_processor = tflearn.data_utils.VocabularyProcessor(max_length, min_frequency=0)\n",
    "#Note : Above function was used instead of the below, which is deprecated. \n",
    "# vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(max_length)\n",
    "\n",
    "def process_inputs(key, vocab_processor):\n",
    "    \n",
    "    # For simplicity, we call our features x and our outputs y\n",
    "    start_vectorize = time.time()\n",
    "    x_train = dict_train_df[key].reviewText\n",
    "    y_train = dict_train_y[key]\n",
    "    x_dev = dict_dev_df[key].reviewText\n",
    "    y_dev = dict_dev_y[key]\n",
    "    print(x_train.shape)\n",
    "    \n",
    "    # Train the vocab_processor from the training set\n",
    "    x_train = vocab_processor.fit_transform(x_train)\n",
    "    # Transform our test set with the vocabulary processor\n",
    "    x_dev = vocab_processor.transform(x_dev)\n",
    "\n",
    "    # We need these to be np.arrays instead of generators\n",
    "    x_train = np.array(list(x_train))\n",
    "    print(x_train.shape)\n",
    "    x_dev = np.array(list(x_dev))\n",
    "    y_train = np.array(y_train).astype(int)\n",
    "    y_dev = np.array(y_dev).astype(int)\n",
    "    \n",
    "#     y_train = tf.expand_dims(y_train,1)\n",
    "#     y_dev = tf.expand_dims(y_dev,1)\n",
    "    print('y train shape',y_train.shape)\n",
    "\n",
    "    V = len(vocab_processor.vocabulary_)\n",
    "    print('Total words: %d' % V)\n",
    "    end_vectorize = time.time()\n",
    "    print('Time taken to vectorize %d size dataframe'%x_train.shape[0],end_vectorize-start_vectorize)\n",
    "\n",
    "    # Return the transformed data and the number of words\n",
    "    return x_train, y_train, x_dev, y_dev, V\n",
    "\n",
    "x_train, y_train, x_dev, y_dev, V = process_inputs('hnk',vocab_processor)\n",
    "\n",
    "#Print a few examples for viewing\n",
    "print('sample review',dict_train_df['hnk']['reviewText'].iloc[3],'\\n')\n",
    "print('corresponding ids\\n',x_train[3])\n",
    "print('sample review',dict_dev_df['hnk']['reviewText'].iloc[3],'\\n')\n",
    "print('corresponding ids\\n',x_dev[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "(30000,)\n",
      "0.8308\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_dev.shape)\n",
    "print(np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__( self, sequence_length, num_classes, vocab_size, learning_rate, momentum, embedding_size, \n",
    "                 gl_embed, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.int32, [None], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "\n",
    "        with tf.name_scope(\"embedding\"):\n",
    "            #self.W = tf.get_variable(\"W_in\",[vocab_size, embedding_size],initializer =tf.random_uniform_initializer(0,1)) #from wildML\n",
    "            self.W=tf.get_variable(name=\"embedding_\",shape=gl_embed.shape,\n",
    "                                       initializer=tf.constant_initializer(gl_embed),trainable=True)\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            #print('embedded_chars',self.embedded_chars.get_shape())\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "            #print('embedded_chars_expanded',self.embedded_chars_expanded.get_shape())\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                #W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                Wname = \"w_%d\"%filter_size\n",
    "                W = tf.get_variable(Wname, shape = filter_shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.Variable(tf.constant(0.0, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d( self.embedded_chars_expanded, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv\")\n",
    "\n",
    "                # Apply nonlinearity\n",
    "                conv+= b\n",
    "                h = tf.nn.relu(conv, name=\"relu\")\n",
    "                #print('h',h.get_shape())\n",
    "\n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(h, ksize=[1, sequence_length - filter_size + 1, 1, 1], strides=[1, 1, 1, 1],\n",
    "                    padding='VALID', name=\"pool\")\n",
    "                #print('pooled',pooled.get_shape())\n",
    "                pooled_outputs.append(pooled)\n",
    "                #print('pooled_outputs',type(pooled_outputs))\n",
    "                #print('pooled_outputs as array',type(np.array(pooled_outputs)),np.array(pooled_outputs).shape)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        #print('h_pool',self.h_pool.get_shape())\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "        #print('h_pool_flat',self.h_pool_flat.get_shape())\n",
    "        \n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\"W\", shape=[num_filters_total, num_classes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.0, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            #print('self.scores',self.scores.get_shape())\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "            #print('self.predictions',self.predictions.get_shape())\n",
    "            \n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "            #self.loss = tf.losses.mean_squared_error(self.input_y, self.scores)\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(tf.cast(self.predictions,tf.int32), self.input_y)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "#             correct_pred = tf.equal(tf.cast(tf.round(self.scores), tf.int32), self.input_y)\n",
    "#             self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "            \n",
    "        with tf.name_scope('train'):\n",
    "            #self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "            self.optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate,momentum=momentum,use_nesterov=True).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(ids, labels, batch_size=100):\n",
    "            #ids is input, X_train\n",
    "            #need to fix this to shuffle between epochs\n",
    "    \n",
    "            n_batches = len(ids)//batch_size\n",
    "            ids, labels = ids[:n_batches*batch_size], labels[:n_batches*batch_size]\n",
    "            shuffle = np.random.permutation(np.arange(n_batches*batch_size))\n",
    "            ids, labels = ids[shuffle], labels[shuffle]\n",
    "\n",
    "    \n",
    "            for ii in range(0, len(ids), batch_size):\n",
    "                yield ids[ii:ii+batch_size], labels[ii:ii+batch_size]\n",
    "\n",
    "# for ii, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "#     print(ii,type(x),x.shape,type(np.array(y)),y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/ubuntu/W266Project/final_project/runs/cnn\n",
      "\n",
      "completed cnn creation\n",
      "# batches = 1562\n",
      "Train epoch 0, average loss 0.315445, average accuracy 0.867898,\n",
      "\t\tDev epoch 0, average loss 0.242731, average accuracy 0.904647,\n",
      "\t\t\t\t    Time taken for 0 epochs =  37.176440477371216\n",
      "Train epoch 3, average loss 0.157395, average accuracy 0.93714,\n",
      "Train epoch 6, average loss 0.0870137, average accuracy 0.96742,\n",
      "\t\tDev epoch 6, average loss 0.209739, average accuracy 0.924412,\n",
      "Train epoch 9, average loss 0.0477468, average accuracy 0.982644,\n",
      "Train epoch 12, average loss 0.0323209, average accuracy 0.988486,\n",
      "\t\tDev epoch 12, average loss 0.254533, average accuracy 0.925581,\n",
      "\t\t\t\t    Time taken for 12 epochs =  454.1315793991089\n",
      "Train epoch 15, average loss 0.02173, average accuracy 0.992628,\n",
      "Train epoch 18, average loss 0.016564, average accuracy 0.994728,\n",
      "\t\tDev epoch 18, average loss 0.299426, average accuracy 0.927083,\n",
      "Train epoch 21, average loss 0.0138337, average accuracy 0.995809,\n",
      "Train epoch 24, average loss 0.0110263, average accuracy 0.996589,\n",
      "\t\tDev epoch 24, average loss 0.327215, average accuracy 0.926716,\n",
      "\t\t\t\t    Time taken for 24 epochs =  871.095502614975\n",
      "Train epoch 27, average loss 0.0101196, average accuracy 0.996659,\n",
      "Train epoch 30, average loss 0.00930095, average accuracy 0.997099,\n",
      "\t\tDev epoch 30, average loss 0.398451, average accuracy 0.924312,\n",
      "Train epoch 33, average loss 0.00831027, average accuracy 0.997409,\n",
      "Train epoch 36, average loss 0.00723346, average accuracy 0.997769,\n",
      "\t\tDev epoch 36, average loss 0.401322, average accuracy 0.926349,\n",
      "\t\t\t\t    Time taken for 36 epochs =  1288.182965517044\n",
      "Train epoch 39, average loss 0.00636969, average accuracy 0.998159,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6ac3f8e3986a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Actual training loop:\n",
    "\n",
    "#embed_dim = 50 #use when not using pre-trained embeddings\n",
    "embed_dim = hands.shape[1]\n",
    "filter_sizes= [3,4,5]\n",
    "num_filters = 256\n",
    "l2_reg_lambda = 0\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "keep_prob = 0.8\n",
    "evaluate_train = 3 # of epochs at which to print test accuracy\n",
    "evaluate_dev = 6 # of epochs at which to estimate and print dev accuracy\n",
    "time_print = 12 # of epochs at which to print time taken\n",
    "num_classes = 2\n",
    "num_epochs = 61\n",
    "num_checkpoints = 1\n",
    "batch_size = 64\n",
    "\n",
    "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", \"cnn\"))\n",
    "print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        cnn = TextCNN(sequence_length=x_train.shape[1], num_classes=num_classes, vocab_size=V, learning_rate = learning_rate,\n",
    "                        momentum = momentum, embedding_size=embed_dim, gl_embed = hands.W, filter_sizes= filter_sizes, \n",
    "                      num_filters=num_filters, l2_reg_lambda=l2_reg_lambda)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('completed cnn creation')\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "        # Write vocabulary\n",
    "        ## vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "        print('# batches =', len(x_train)//batch_size)\n",
    "        start = time.time()\n",
    "        for e in range(num_epochs):\n",
    "                    \n",
    "            #sum_scores = np.zeros((batch_size*(len(x_train)//batch_size),1))\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for i, (x, y) in enumerate(batch_generator(x_train, y_train, batch_size), 1):\n",
    "                feed = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: keep_prob}\n",
    "                _, scores, loss, accuracy = sess.run([cnn.optimizer,cnn.scores,cnn.loss, cnn.accuracy],feed_dict = feed)\n",
    "                total_loss += loss*len(x)\n",
    "                total_acc += accuracy*len(x)\n",
    "                \n",
    "                #sum_scores[i*batch_size:(i+1)*batch_size,:] = scores\n",
    "                #print(np.mean(sum_scores))\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "            if e%evaluate_train==0:\n",
    "                avg_loss = total_loss/(batch_size*(len(x_train)//batch_size))\n",
    "                avg_acc = total_acc/(batch_size*(len(x_train)//batch_size))\n",
    "                print(\"Train epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "                #print('average',np.mean(scores))\n",
    "\n",
    "            if e%evaluate_dev==0:\n",
    "                total_loss = 0\n",
    "                total_acc = 0\n",
    "                num_batches = 0\n",
    "                for ii, (x, y) in enumerate(batch_generator(x_dev, y_dev, batch_size), 1):\n",
    "                    feed_dict = {cnn.input_x: x, cnn.input_y: y, cnn.dropout_keep_prob: 1.0}\n",
    "                    loss, accuracy = sess.run([cnn.loss, cnn.accuracy],feed_dict)\n",
    "                    total_loss += loss*len(x)\n",
    "                    total_acc += accuracy*len(x)\n",
    "                    num_batches += 1\n",
    "                avg_loss = total_loss/(num_batches*batch_size)\n",
    "                avg_acc = total_acc/(num_batches*batch_size)\n",
    "                #time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"\\t\\tDev epoch {}, average loss {:g}, average accuracy {:g},\".format(e, avg_loss, avg_acc))\n",
    "            if e%time_print == 0:\n",
    "                end = time.time()\n",
    "                print(\"\\t\\t\\t\\t    Time taken for\",e,\"epochs = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KEEPING TRACK OF RESULTS FROM DIFFERENT RUNS\n",
    "#### Number samples = 10000, Number batches = 156, Without pre-trained embeddings, no dropout\n",
    "Train epoch 0, loss 0.357085, average loss 0.440941, acc 0.84375, average acc 0.845152,\n",
    "\tDev epoch 0, loss 0.494501, average loss 0.394619, acc 0.78125, average acc 0.854959,\n",
    "\t\tTime taken for 0 epochs =  36.18872332572937\n",
    "Train epoch 2, loss 0.25934, average loss 0.335786, acc 0.875, average acc 0.862079,\n",
    "Train epoch 4, loss 0.214457, average loss 0.263726, acc 0.875, average acc 0.891827,\n",
    "Train epoch 6, loss 0.161232, average loss 0.194851, acc 0.890625, average acc 0.92528,\n",
    "Train epoch 8, loss 0.0968393, average loss 0.132971, acc 0.984375, average acc 0.958133,\n",
    "Train epoch 10, loss 0.0598382, average loss 0.0935878, acc 1, average acc 0.978766,\n",
    "\tDev epoch 10, loss 0.318434, average loss 0.279314, acc 0.875, average acc 0.891304,\n",
    "\t\tTime taken for 10 epochs =  366.54717350006104\n",
    "Train epoch 12, loss 0.0432213, average loss 0.089715, acc 1, average acc 0.979768,\n",
    "Train epoch 14, loss 0.0724975, average loss 0.299487, acc 1, average acc 0.957933,\n",
    "Train epoch 16, loss 0.0388074, average loss 0.0520482, acc 1, average acc 0.991987,\n",
    "Train epoch 18, loss 0.0239645, average loss 0.0351604, acc 1, average acc 0.997196,\n",
    "Train epoch 20, loss 0.0157139, average loss 0.0272624, acc 1, average acc 0.996595,\n",
    "\tDev epoch 20, loss 0.304895, average loss 0.283551, acc 0.921875, average acc 0.902853,\n",
    "\t\tTime taken for 20 epochs =  697.680163860321\n",
    "Train epoch 22, loss 0.0131277, average loss 0.017179, acc 1, average acc 0.999299,\n",
    "Train epoch 24, loss 0.0104588, average loss 0.0121853, acc 1, average acc 0.9999,\n",
    "Train epoch 26, loss 0.0072446, average loss 0.00969622, acc 1, average acc 0.9999,\n",
    "Train epoch 28, loss 0.00628954, average loss 0.00805781, acc 1, average acc 0.9999,\n",
    "Train epoch 30, loss 0.00585206, average loss 0.00689346, acc 1, average acc 0.9999,\n",
    "\tDev epoch 30, loss 0.37002, average loss 0.327092, acc 0.875, average acc 0.902514,\n",
    "\t\tTime taken for 30 epochs =  1029.1201057434082\n",
    "Train epoch 32, loss 0.00559655, average loss 0.00594074, acc 1, average acc 0.9999,\n",
    "Train epoch 34, loss 0.0053231, average loss 0.00518374, acc 1, average acc 1,\n",
    "Train epoch 36, loss 0.00504235, average loss 0.00461033, acc 1, average acc 1,\n",
    "Train epoch 38, loss 0.00477842, average loss 0.00416377, acc 1, average acc 1,\n",
    "Train epoch 40, loss 0.00451324, average loss 0.00380536, acc 1, average acc 1,\n",
    "\tDev epoch 40, loss 0.451459, average loss 0.382435, acc 0.859375, average acc 0.899796,\n",
    "\t\tTime taken for 40 epochs =  1360.2103555202484\n",
    "        \n",
    "        \n",
    "#### Number samples = 10000, Number batches = 156, With pre-trained embeddings(Trainable = False), dropout = 0.8\n",
    "Train epoch 0, average loss 0.819034, average acc 0.802784,\n",
    "\tDev epoch 0, average loss 0.415172, average acc 0.853601,\n",
    "\t\tTime taken for 0 epochs =  35.559093713760376\n",
    "Train epoch 2, average loss 0.403757, average acc 0.841046,\n",
    "Train epoch 4, average loss 0.340479, average acc 0.860777,\n",
    "\tDev epoch 5, average loss 0.329067, average acc 0.867188,\n",
    "Train epoch 6, average loss 0.289147, average acc 0.882312,\n",
    "Train epoch 8, average loss 0.237817, average acc 0.904948,\n",
    "Train epoch 10, average loss 0.194272, average acc 0.923978,\n",
    "\tDev epoch 10, average loss 0.330927, average acc 0.876698,\n",
    "\t\tTime taken for 10 epochs =  363.92726016044617\n",
    "Train epoch 12, average loss 0.149883, average acc 0.940405,\n",
    "Train epoch 14, average loss 0.128152, average acc 0.951322,\n",
    "\tDev epoch 15, average loss 0.349508, average acc 0.877717,\n",
    "Train epoch 16, average loss 0.101319, average acc 0.961639,\n",
    "Train epoch 18, average loss 0.079585, average acc 0.970052,\n",
    "Train epoch 20, average loss 0.0705579, average acc 0.97516,\n",
    "\tDev epoch 20, average loss 0.364253, average acc 0.878057,\n",
    "\t\tTime taken for 20 epochs =  692.3398864269257\n",
    "Train epoch 22, average loss 0.0631964, average acc 0.978466,\n",
    "Train epoch 24, average loss 0.0484077, average acc 0.984876,\n",
    "\tDev epoch 25, average loss 0.435054, average acc 0.877717,\n",
    "Train epoch 26, average loss 0.0433892, average acc 0.985377,\n",
    "Train epoch 28, average loss 0.0368327, average acc 0.988381,\n",
    "Train epoch 30, average loss 0.0308169, average acc 0.990385,\n",
    "\tDev epoch 30, average loss 0.570798, average acc 0.875679,\n",
    "\t\tTime taken for 30 epochs =  1052.273297548294\n",
    "Train epoch 32, average loss 0.0291807, average acc 0.991086,\n",
    "Train epoch 34, average loss 0.0271599, average acc 0.991987,\n",
    "\tDev epoch 35, average loss 0.661539, average acc 0.87534,\n",
    "Train epoch 36, average loss 0.029594, average acc 0.991486,\n",
    "Train epoch 38, average loss 0.0236557, average acc 0.99359,\n",
    "Train epoch 40, average loss 0.018746, average acc 0.995292,\n",
    "\tDev epoch 40, average loss 0.506544, average acc 0.878397,\n",
    "\t\tTime taken for 40 epochs =  1466.0729427337646\n",
    "        \n",
    "        \n",
    "#### Changes. Changed convolutional layer weights to xavier initialization. Added random see = 42 to train-test split. Dropped learning rate initial to 0.007\n",
    "\n",
    "Train epoch 0, average loss 0.399899, average accuracy 0.858273,\n",
    "\tDev epoch 0, average loss 0.374428, average accuracy 0.857337,\n",
    "\t\tTime taken for 0 epochs =  34.83389401435852\n",
    "Train epoch 2, average loss 0.326706, average accuracy 0.869391,\n",
    "Train epoch 4, average loss 0.269826, average accuracy 0.891126,\n",
    "\tDev epoch 5, average loss 0.303238, average accuracy 0.88519,\n",
    "Train epoch 6, average loss 0.219368, average accuracy 0.911659,\n",
    "Train epoch 8, average loss 0.171234, average accuracy 0.935296,\n",
    "Train epoch 10, average loss 0.13296, average accuracy 0.953325,\n",
    "\tDev epoch 10, average loss 0.293018, average accuracy 0.887568,\n",
    "\t\tTime taken for 10 epochs =  370.47870922088623\n",
    "Train epoch 12, average loss 0.100562, average accuracy 0.967348,\n",
    "Train epoch 14, average loss 0.0793127, average accuracy 0.977063,\n",
    "\tDev epoch 15, average loss 0.320119, average accuracy 0.886209,\n",
    "Train epoch 16, average loss 0.0582729, average accuracy 0.988482,\n",
    "Train epoch 18, average loss 0.0456755, average accuracy 0.990385,\n",
    "Train epoch 20, average loss 0.0405185, average accuracy 0.992788,\n",
    "\tDev epoch 20, average loss 0.321604, average accuracy 0.886889,\n",
    "\t\tTime taken for 20 epochs =  705.0958936214447\n",
    "Train epoch 22, average loss 0.0351258, average accuracy 0.993089,\n",
    "Train epoch 24, average loss 0.0270392, average accuracy 0.996194,\n",
    "\tDev epoch 25, average loss 0.399808, average accuracy 0.884171,\n",
    "Train epoch 26, average loss 0.0262923, average accuracy 0.995994,\n",
    "Train epoch 28, average loss 0.0242657, average accuracy 0.995994,\n",
    "Train epoch 30, average loss 0.0208821, average accuracy 0.996394,\n",
    "\tDev epoch 30, average loss 0.413923, average accuracy 0.886889,\n",
    "\t\tTime taken for 30 epochs =  1039.4113600254059\n",
    "Train epoch 32, average loss 0.017492, average accuracy 0.997696,\n",
    "Train epoch 34, average loss 0.0146527, average accuracy 0.998097,\n",
    "\tDev epoch 35, average loss 0.386267, average accuracy 0.884851,\n",
    "Train epoch 36, average loss 0.0168233, average accuracy 0.997396,\n",
    "Train epoch 38, average loss 0.0142984, average accuracy 0.997796,\n",
    "Train epoch 40, average loss 0.0110543, average accuracy 0.998998,\n",
    "\tDev epoch 40, average loss 0.478341, average accuracy 0.884171,\n",
    "\t\tTime taken for 40 epochs =  1374.086744070053\n",
    "Train epoch 42, average loss 0.012298, average accuracy 0.998397,\n",
    "Train epoch 44, average loss 0.0116889, average accuracy 0.998197,\n",
    "\tDev epoch 45, average loss 0.448394, average accuracy 0.88587,\n",
    "Train epoch 46, average loss 0.0107089, average accuracy 0.998197,\n",
    "Train epoch 48, average loss 0.00953887, average accuracy 0.998898,\n",
    "Train epoch 50, average loss 0.0097256, average accuracy 0.998898,\n",
    "\tDev epoch 50, average loss 0.424627, average accuracy 0.886209,\n",
    "\t\tTime taken for 50 epochs =  1708.131004333496\n",
    "Train epoch 52, average loss 0.00792942, average accuracy 0.999099,\n",
    "Train epoch 54, average loss 0.00777054, average accuracy 0.999099,\n",
    "\tDev epoch 55, average loss 0.434766, average accuracy 0.887228,\n",
    "Train epoch 56, average loss 0.00812112, average accuracy 0.999099,\n",
    "Train epoch 58, average loss 0.00817043, average accuracy 0.998798,\n",
    "Train epoch 60, average loss 0.00776972, average accuracy 0.998498,\n",
    "\tDev epoch 60, average loss 0.447535, average accuracy 0.886889,\n",
    "\t\tTime taken for 60 epochs =  2042.1303217411041\n",
    "Train epoch 62, average loss 0.00759579, average accuracy 0.998998,\n",
    "Train epoch 64, average loss 0.00697335, average accuracy 0.998798,\n",
    "\tDev epoch 65, average loss 0.514295, average accuracy 0.88519,\n",
    "Train epoch 66, average loss 0.00579109, average accuracy 0.999199,\n",
    "Train epoch 68, average loss 0.00583337, average accuracy 0.999499,\n",
    "\n",
    "#### Changes. set trainable = True in glove embeddings. Changed learning rate back to 0.01 initial.\n",
    "# batches = 156\n",
    "Train epoch 0, average loss 0.399899, average accuracy 0.858273,\n",
    "\tDev epoch 0, average loss 0.374428, average accuracy 0.857337,\n",
    "\t\tTime taken for 0 epochs =  34.83389401435852\n",
    "Train epoch 2, average loss 0.326706, average accuracy 0.869391,\n",
    "Train epoch 4, average loss 0.269826, average accuracy 0.891126,\n",
    "\tDev epoch 5, average loss 0.303238, average accuracy 0.88519,\n",
    "Train epoch 6, average loss 0.219368, average accuracy 0.911659,\n",
    "Train epoch 8, average loss 0.171234, average accuracy 0.935296,\n",
    "Train epoch 10, average loss 0.13296, average accuracy 0.953325,\n",
    "\tDev epoch 10, average loss 0.293018, average accuracy 0.887568,\n",
    "\t\tTime taken for 10 epochs =  370.47870922088623\n",
    "Train epoch 12, average loss 0.100562, average accuracy 0.967348,\n",
    "Train epoch 14, average loss 0.0793127, average accuracy 0.977063,\n",
    "\tDev epoch 15, average loss 0.320119, average accuracy 0.886209,\n",
    "Train epoch 16, average loss 0.0582729, average accuracy 0.988482,\n",
    "Train epoch 18, average loss 0.0456755, average accuracy 0.990385,\n",
    "Train epoch 20, average loss 0.0405185, average accuracy 0.992788,\n",
    "\tDev epoch 20, average loss 0.321604, average accuracy 0.886889,\n",
    "\t\tTime taken for 20 epochs =  705.0958936214447\n",
    "Train epoch 22, average loss 0.0351258, average accuracy 0.993089,\n",
    "Train epoch 24, average loss 0.0270392, average accuracy 0.996194,\n",
    "\tDev epoch 25, average loss 0.399808, average accuracy 0.884171,\n",
    "Train epoch 26, average loss 0.0262923, average accuracy 0.995994,\n",
    "Train epoch 28, average loss 0.0242657, average accuracy 0.995994,\n",
    "Train epoch 30, average loss 0.0208821, average accuracy 0.996394,\n",
    "\tDev epoch 30, average loss 0.413923, average accuracy 0.886889,\n",
    "\t\tTime taken for 30 epochs =  1039.4113600254059\n",
    "Train epoch 32, average loss 0.017492, average accuracy 0.997696,\n",
    "Train epoch 34, average loss 0.0146527, average accuracy 0.998097,\n",
    "\tDev epoch 35, average loss 0.386267, average accuracy 0.884851,\n",
    "Train epoch 36, average loss 0.0168233, average accuracy 0.997396,\n",
    "Train epoch 38, average loss 0.0142984, average accuracy 0.997796,\n",
    "Train epoch 40, average loss 0.0110543, average accuracy 0.998998,\n",
    "\tDev epoch 40, average loss 0.478341, average accuracy 0.884171,\n",
    "\t\tTime taken for 40 epochs =  1374.086744070053\n",
    "Train epoch 42, average loss 0.012298, average accuracy 0.998397,\n",
    "Train epoch 44, average loss 0.0116889, average accuracy 0.998197,\n",
    "\tDev epoch 45, average loss 0.448394, average accuracy 0.88587,\n",
    "Train epoch 46, average loss 0.0107089, average accuracy 0.998197,\n",
    "Train epoch 48, average loss 0.00953887, average accuracy 0.998898,\n",
    "Train epoch 50, average loss 0.0097256, average accuracy 0.998898,\n",
    "\tDev epoch 50, average loss 0.424627, average accuracy 0.886209,\n",
    "\t\tTime taken for 50 epochs =  1708.131004333496\n",
    "Train epoch 52, average loss 0.00792942, average accuracy 0.999099,\n",
    "Train epoch 54, average loss 0.00777054, average accuracy 0.999099,\n",
    "\tDev epoch 55, average loss 0.434766, average accuracy 0.887228,\n",
    "Train epoch 56, average loss 0.00812112, average accuracy 0.999099,\n",
    "Train epoch 58, average loss 0.00817043, average accuracy 0.998798,\n",
    "Train epoch 60, average loss 0.00776972, average accuracy 0.998498,\n",
    "\tDev epoch 60, average loss 0.447535, average accuracy 0.886889,\n",
    "\t\tTime taken for 60 epochs =  2042.1303217411041\n",
    "Train epoch 62, average loss 0.00759579, average accuracy 0.998998,\n",
    "Train epoch 64, average loss 0.00697335, average accuracy 0.998798,\n",
    "\tDev epoch 65, average loss 0.514295, average accuracy 0.88519,\n",
    "Train epoch 66, average loss 0.00579109, average accuracy 0.999199,\n",
    "Train epoch 68, average loss 0.00583337, average accuracy 0.999499,\n",
    "\n",
    "\n",
    "#### Changes : increased sample size to 20000. increased filter number to 256 per filter size. Both together slowed it down 4 times. Ran 150 epochs.\n",
    "\n",
    "Result - get to accuracy of about 90.5% on dev set. First saw it in about 80 epochs.\n",
    "\n",
    "number of batches = 312\n",
    "Train epoch 0, average loss 0.399409, average accuracy 0.851763,\n",
    "\tDev epoch 0, average loss 0.390935, average accuracy 0.849798,\n",
    "\t\tTime taken for 0 epochs =  126.17049622535706\n",
    "Train epoch 2, average loss 0.310082, average accuracy 0.877955,\n",
    "Train epoch 4, average loss 0.240321, average accuracy 0.905298,\n",
    "\tDev epoch 5, average loss 0.309063, average accuracy 0.879872,\n",
    "Train epoch 6, average loss 0.183422, average accuracy 0.929137,\n",
    "Train epoch 8, average loss 0.132305, average accuracy 0.950871,\n",
    "Train epoch 10, average loss 0.091186, average accuracy 0.96855,\n",
    "\tDev epoch 10, average loss 0.359275, average accuracy 0.887769,\n",
    "\t\tTime taken for 10 epochs =  1301.3605210781097\n",
    "Train epoch 12, average loss 0.0655771, average accuracy 0.978966,\n",
    "Train epoch 14, average loss 0.0487824, average accuracy 0.986579,\n",
    "\tDev epoch 15, average loss 0.31907, average accuracy 0.901546,\n",
    "Train epoch 16, average loss 0.0353836, average accuracy 0.991136,\n",
    "Train epoch 18, average loss 0.0272109, average accuracy 0.993389,\n",
    "Train epoch 20, average loss 0.0209386, average accuracy 0.995843,\n",
    "\tDev epoch 20, average loss 0.473887, average accuracy 0.888609,\n",
    "\t\tTime taken for 20 epochs =  2475.8890883922577\n",
    "Train epoch 22, average loss 0.0169513, average accuracy 0.996444,\n",
    "Train epoch 24, average loss 0.0144857, average accuracy 0.997045,\n",
    "\tDev epoch 25, average loss 0.52256, average accuracy 0.886929,\n",
    "Train epoch 26, average loss 0.0115876, average accuracy 0.998147,\n",
    "Train epoch 28, average loss 0.00961356, average accuracy 0.998347,\n",
    "Train epoch 30, average loss 0.00915859, average accuracy 0.998297,\n",
    "\tDev epoch 30, average loss 0.458756, average accuracy 0.895665,\n",
    "\t\tTime taken for 30 epochs =  3649.31303191185\n",
    "Train epoch 32, average loss 0.00898325, average accuracy 0.998498,\n",
    "Train epoch 34, average loss 0.00841926, average accuracy 0.998448,\n",
    "\tDev epoch 35, average loss 0.457308, average accuracy 0.897681,\n",
    "Train epoch 36, average loss 0.00646681, average accuracy 0.999149,\n",
    "Train epoch 38, average loss 0.00662382, average accuracy 0.998598,\n",
    "Train epoch 40, average loss 0.00595506, average accuracy 0.999149,\n",
    "\tDev epoch 40, average loss 0.378182, average accuracy 0.901546,\n",
    "\t\tTime taken for 40 epochs =  4823.336989402771\n",
    "Train epoch 42, average loss 0.00593351, average accuracy 0.999149,\n",
    "Train epoch 44, average loss 0.00464219, average accuracy 0.999249,\n",
    "\tDev epoch 45, average loss 0.431081, average accuracy 0.90121,\n",
    "Train epoch 46, average loss 0.00444085, average accuracy 0.999499,\n",
    "Train epoch 48, average loss 0.00461485, average accuracy 0.999349,\n",
    "Train epoch 50, average loss 0.00466378, average accuracy 0.999199,\n",
    "\tDev epoch 50, average loss 0.380632, average accuracy 0.90289,\n",
    "\t\tTime taken for 50 epochs =  5997.558866024017\n",
    "Train epoch 52, average loss 0.00401276, average accuracy 0.999299,\n",
    "Train epoch 54, average loss 0.00360064, average accuracy 0.999549,\n",
    "\tDev epoch 55, average loss 0.472261, average accuracy 0.900706,\n",
    "Train epoch 56, average loss 0.00390259, average accuracy 0.999449,\n",
    "Train epoch 58, average loss 0.00343323, average accuracy 0.999499,\n",
    "Train epoch 60, average loss 0.00328182, average accuracy 0.999549,\n",
    "\tDev epoch 60, average loss 0.405813, average accuracy 0.901714,\n",
    "\t\tTime taken for 60 epochs =  7171.330280542374\n",
    "Train epoch 62, average loss 0.00357674, average accuracy 0.999499,\n",
    "Train epoch 64, average loss 0.00316356, average accuracy 0.999449,\n",
    "\tDev epoch 65, average loss 0.484432, average accuracy 0.899698,\n",
    "Train epoch 66, average loss 0.00242786, average accuracy 0.99975,\n",
    "Train epoch 68, average loss 0.0029979, average accuracy 0.999399,\n",
    "Train epoch 70, average loss 0.00219736, average accuracy 0.999599,\n",
    "\tDev epoch 70, average loss 0.522188, average accuracy 0.89953,\n",
    "\t\tTime taken for 70 epochs =  8345.40755033493\n",
    "Train epoch 72, average loss 0.00263028, average accuracy 0.999599,\n",
    "Train epoch 74, average loss 0.00262097, average accuracy 0.999599,\n",
    "\tDev epoch 75, average loss 0.501381, average accuracy 0.90037,\n",
    "Train epoch 76, average loss 0.00184087, average accuracy 0.99975,\n",
    "Train epoch 78, average loss 0.00261343, average accuracy 0.999399,\n",
    "Train epoch 80, average loss 0.00210662, average accuracy 0.9997,\n",
    "\tDev epoch 80, average loss 0.437249, average accuracy 0.90457,\n",
    "\t\tTime taken for 80 epochs =  9519.476462364197\n",
    "Train epoch 82, average loss 0.00218873, average accuracy 0.999599,\n",
    "Train epoch 84, average loss 0.00204953, average accuracy 0.9997,\n",
    "\tDev epoch 85, average loss 0.440843, average accuracy 0.90457,\n",
    "Train epoch 86, average loss 0.00178851, average accuracy 0.99975,\n",
    "Train epoch 88, average loss 0.00177724, average accuracy 0.999599,\n",
    "Train epoch 90, average loss 0.0018953, average accuracy 0.999599,\n",
    "\tDev epoch 90, average loss 0.465653, average accuracy 0.905074,\n",
    "\t\tTime taken for 90 epochs =  10693.68774318695\n",
    "Train epoch 92, average loss 0.00145395, average accuracy 0.9998,\n",
    "Train epoch 94, average loss 0.00158429, average accuracy 0.999649,\n",
    "\tDev epoch 95, average loss 0.472749, average accuracy 0.90541,\n",
    "Train epoch 96, average loss 0.00238694, average accuracy 0.999499,\n",
    "Train epoch 98, average loss 0.00175795, average accuracy 0.9997,\n",
    "Train epoch 100, average loss 0.00153946, average accuracy 0.9998,\n",
    "\tDev epoch 100, average loss 0.440989, average accuracy 0.906754,\n",
    "\t\tTime taken for 100 epochs =  11867.341850280762\n",
    "Train epoch 102, average loss 0.00144569, average accuracy 0.9998,\n",
    "Train epoch 104, average loss 0.00135836, average accuracy 0.99975,\n",
    "\tDev epoch 105, average loss 0.450465, average accuracy 0.90457,\n",
    "Train epoch 106, average loss 0.00134604, average accuracy 0.99985,\n",
    "Train epoch 108, average loss 0.00198454, average accuracy 0.999549,\n",
    "Train epoch 110, average loss 0.0016289, average accuracy 0.99975,\n",
    "\tDev epoch 110, average loss 0.43462, average accuracy 0.905242,\n",
    "\t\tTime taken for 110 epochs =  13040.53886771202\n",
    "Train epoch 112, average loss 0.00116808, average accuracy 0.99975,\n",
    "Train epoch 114, average loss 0.00163431, average accuracy 0.999649,\n",
    "\tDev epoch 115, average loss 0.544521, average accuracy 0.901714,\n",
    "Train epoch 116, average loss 0.00107182, average accuracy 0.9999,\n",
    "Train epoch 118, average loss 0.00118616, average accuracy 0.99985,\n",
    "Train epoch 120, average loss 0.00116875, average accuracy 0.9998,\n",
    "\tDev epoch 120, average loss 0.456846, average accuracy 0.906082,\n",
    "\t\tTime taken for 120 epochs =  14214.848599672318\n",
    "Train epoch 122, average loss 0.00144058, average accuracy 0.999649,\n",
    "Train epoch 124, average loss 0.00139588, average accuracy 0.999649,\n",
    "\tDev epoch 125, average loss 0.456731, average accuracy 0.90709,\n",
    "Train epoch 126, average loss 0.00129419, average accuracy 0.99975,\n",
    "Train epoch 128, average loss 0.000993939, average accuracy 0.9998,\n",
    "Train epoch 130, average loss 0.00110859, average accuracy 0.99975,\n",
    "\tDev epoch 130, average loss 0.440627, average accuracy 0.905242,\n",
    "\t\tTime taken for 130 epochs =  15387.949309825897\n",
    "Train epoch 132, average loss 0.000869354, average accuracy 0.9998,\n",
    "Train epoch 134, average loss 0.0010678, average accuracy 0.99975,\n",
    "\tDev epoch 135, average loss 0.662642, average accuracy 0.895497,\n",
    "Train epoch 136, average loss 0.00121623, average accuracy 0.99985,\n",
    "Train epoch 138, average loss 0.00106557, average accuracy 0.9998,\n",
    "Train epoch 140, average loss 0.0012005, average accuracy 0.9997,\n",
    "\tDev epoch 140, average loss 0.48323, average accuracy 0.905578,\n",
    "\t\tTime taken for 140 epochs =  16560.915422201157\n",
    "Train epoch 142, average loss 0.00142349, average accuracy 0.999649,\n",
    "Train epoch 144, average loss 0.00100832, average accuracy 0.9998,\n",
    "\tDev epoch 145, average loss 0.469864, average accuracy 0.906082,\n",
    "Train epoch 146, average loss 0.000867766, average accuracy 0.99985,\n",
    "Train epoch 148, average loss 0.000895252, average accuracy 0.9998,\n",
    "Train epoch 150, average loss 0.00128643, average accuracy 0.99975,\n",
    "\tDev epoch 150, average loss 0.504558, average accuracy 0.904738,\n",
    "\t\tTime taken for 150 epochs =  17732.689709424973\n",
    "Train epoch 152, average loss 0.00106975, average accuracy 0.99975,\n",
    "Train epoch 154, average loss 0.000923771, average accuracy 0.9998,\n",
    "\tDev epoch 155, average loss 0.46343, average accuracy 0.904066,\n",
    "    \n",
    "    \n",
    "#### Home and Kitchen, 100000 reviews. 200 epochs, min-documents = 0, embedding size = 100, embeddings trainable = True.\n",
    "\n",
    "completed cnn creation\n",
    "Number batches = 1562\n",
    "Train epoch 0, average loss 0.304591, average accuracy 0.87457,\n",
    "\tDev epoch 0, average loss 0.237596, average accuracy 0.904013,\n",
    "\t\tTime taken for 0 epochs =  36.92328929901123\n",
    "Train epoch 1, average loss 0.223893, average accuracy 0.910071,\n",
    "Train epoch 2, average loss 0.183924, average accuracy 0.927187,\n",
    "Train epoch 3, average loss 0.150811, average accuracy 0.941301,\n",
    "Train epoch 4, average loss 0.123611, average accuracy 0.952775,\n",
    "Train epoch 5, average loss 0.101681, average accuracy 0.961138,\n",
    "\tDev epoch 5, average loss 0.215108, average accuracy 0.917234,\n",
    "Train epoch 6, average loss 0.0824821, average accuracy 0.9694,\n",
    "Train epoch 7, average loss 0.0682877, average accuracy 0.975272,\n",
    "Train epoch 8, average loss 0.0581098, average accuracy 0.978353,\n",
    "Train epoch 9, average loss 0.0481609, average accuracy 0.982815,\n",
    "Train epoch 10, average loss 0.0426059, average accuracy 0.984625,\n",
    "\tDev epoch 10, average loss 0.258906, average accuracy 0.918336,\n",
    "\t\tTime taken for 10 epochs =  381.81759333610535\n",
    "Train epoch 11, average loss 0.0369901, average accuracy 0.986686,\n",
    "Train epoch 12, average loss 0.0348868, average accuracy 0.986946,\n",
    "Train epoch 13, average loss 0.0291087, average accuracy 0.989937,\n",
    "Train epoch 14, average loss 0.0271577, average accuracy 0.990807,\n",
    "Train epoch 15, average loss 0.0248202, average accuracy 0.991487,\n",
    "\tDev epoch 15, average loss 0.317684, average accuracy 0.925114,\n",
    "Train epoch 16, average loss 0.0232966, average accuracy 0.992037,\n",
    "Train epoch 17, average loss 0.0218823, average accuracy 0.992578,\n",
    "Train epoch 18, average loss 0.0189234, average accuracy 0.993878,\n",
    "Train epoch 19, average loss 0.0175714, average accuracy 0.993978,\n",
    "Train epoch 20, average loss 0.0175559, average accuracy 0.994108,\n",
    "\tDev epoch 20, average loss 0.322537, average accuracy 0.924746,\n",
    "\t\tTime taken for 20 epochs =  727.1127679347992\n",
    "Train epoch 21, average loss 0.0159045, average accuracy 0.994638,\n",
    "Train epoch 22, average loss 0.0141158, average accuracy 0.995409,\n",
    "Train epoch 23, average loss 0.0130852, average accuracy 0.995809,\n",
    "Train epoch 24, average loss 0.0131137, average accuracy 0.995709,\n",
    "Train epoch 25, average loss 0.0123618, average accuracy 0.995899,\n",
    "\tDev epoch 25, average loss 0.403685, average accuracy 0.924646,\n",
    "Train epoch 26, average loss 0.0112836, average accuracy 0.996369,\n",
    "Train epoch 27, average loss 0.0111362, average accuracy 0.996449,\n",
    "Train epoch 28, average loss 0.00865663, average accuracy 0.997299,\n",
    "Train epoch 29, average loss 0.00935199, average accuracy 0.996959,\n",
    "Train epoch 30, average loss 0.00935717, average accuracy 0.996699,\n",
    "\tDev epoch 30, average loss 0.367405, average accuracy 0.924579,\n",
    "\t\tTime taken for 30 epochs =  1072.1994183063507\n",
    "Train epoch 31, average loss 0.00909225, average accuracy 0.997149,\n",
    "Train epoch 32, average loss 0.00754316, average accuracy 0.997819,\n",
    "Train epoch 33, average loss 0.0079119, average accuracy 0.997379,\n",
    "Train epoch 34, average loss 0.00705012, average accuracy 0.997719,\n",
    "Train epoch 35, average loss 0.00730037, average accuracy 0.997829,\n",
    "\tDev epoch 35, average loss 0.370859, average accuracy 0.926749,\n",
    "Train epoch 36, average loss 0.00705196, average accuracy 0.997799,\n",
    "Train epoch 37, average loss 0.00669642, average accuracy 0.998039,\n",
    "Train epoch 38, average loss 0.00627199, average accuracy 0.998009,\n",
    "Train epoch 39, average loss 0.00528379, average accuracy 0.998309,\n",
    "Train epoch 40, average loss 0.00593793, average accuracy 0.998229,\n",
    "\tDev epoch 40, average loss 0.383177, average accuracy 0.927618,\n",
    "\t\tTime taken for 40 epochs =  1416.9269080162048\n",
    "Train epoch 41, average loss 0.00519099, average accuracy 0.998289,\n",
    "Train epoch 42, average loss 0.00574083, average accuracy 0.998259,\n",
    "Train epoch 43, average loss 0.00573397, average accuracy 0.998269,\n",
    "Train epoch 44, average loss 0.00478373, average accuracy 0.99844,\n",
    "Train epoch 45, average loss 0.00476654, average accuracy 0.99864,\n",
    "\tDev epoch 45, average loss 0.401872, average accuracy 0.927651,\n",
    "Train epoch 46, average loss 0.00546603, average accuracy 0.998079,\n",
    "Train epoch 47, average loss 0.00552262, average accuracy 0.998299,\n",
    "Train epoch 48, average loss 0.0044039, average accuracy 0.9986,\n",
    "Train epoch 49, average loss 0.00444202, average accuracy 0.99858,\n",
    "Train epoch 50, average loss 0.00553655, average accuracy 0.998239,\n",
    "\tDev epoch 50, average loss 0.410369, average accuracy 0.926182,\n",
    "\t\tTime taken for 50 epochs =  1761.8077738285065\n",
    "Train epoch 51, average loss 0.00446012, average accuracy 0.99862,\n",
    "Train epoch 52, average loss 0.00399219, average accuracy 0.9988,\n",
    "Train epoch 53, average loss 0.00413133, average accuracy 0.99876,\n",
    "Train epoch 54, average loss 0.00465115, average accuracy 0.99857,\n",
    "Train epoch 55, average loss 0.00390704, average accuracy 0.99883,\n",
    "\tDev epoch 55, average loss 0.523764, average accuracy 0.924212,\n",
    "Train epoch 56, average loss 0.00380121, average accuracy 0.99894,\n",
    "Train epoch 57, average loss 0.0041114, average accuracy 0.99863,\n",
    "Train epoch 58, average loss 0.00400388, average accuracy 0.99874,\n",
    "Train epoch 59, average loss 0.00436616, average accuracy 0.99868,\n",
    "Train epoch 60, average loss 0.00410136, average accuracy 0.99879,\n",
    "\tDev epoch 60, average loss 0.465152, average accuracy 0.926115,\n",
    "\t\tTime taken for 60 epochs =  2106.424416542053\n",
    "Train epoch 61, average loss 0.00331209, average accuracy 0.99906,\n",
    "Train epoch 62, average loss 0.00366131, average accuracy 0.99892,\n",
    "Train epoch 63, average loss 0.00425752, average accuracy 0.99884,\n",
    "Train epoch 64, average loss 0.00341706, average accuracy 0.99892,\n",
    "Train epoch 65, average loss 0.00352085, average accuracy 0.99884,\n",
    "\tDev epoch 65, average loss 0.443976, average accuracy 0.919404,\n",
    "Train epoch 66, average loss 0.00392861, average accuracy 0.99874,\n",
    "Train epoch 67, average loss 0.00390108, average accuracy 0.99879,\n",
    "Train epoch 68, average loss 0.00344137, average accuracy 0.99892,\n",
    "Train epoch 69, average loss 0.00282472, average accuracy 0.99918,\n",
    "Train epoch 70, average loss 0.00305406, average accuracy 0.99906,\n",
    "\tDev epoch 70, average loss 0.497239, average accuracy 0.926783,\n",
    "\t\tTime taken for 70 epochs =  2451.336544752121\n",
    "Train epoch 71, average loss 0.00335245, average accuracy 0.99887,\n",
    "Train epoch 72, average loss 0.00321827, average accuracy 0.99912,\n",
    "Train epoch 73, average loss 0.0030572, average accuracy 0.99906,\n",
    "Train epoch 74, average loss 0.00308252, average accuracy 0.99905,\n",
    "Train epoch 75, average loss 0.00312562, average accuracy 0.99909,\n",
    "\tDev epoch 75, average loss 0.454947, average accuracy 0.927818,\n",
    "Train epoch 76, average loss 0.00308124, average accuracy 0.99912,\n",
    "Train epoch 77, average loss 0.00282977, average accuracy 0.9991,\n",
    "Train epoch 78, average loss 0.00250926, average accuracy 0.99929,\n",
    "Train epoch 79, average loss 0.00278992, average accuracy 0.99917,\n",
    "Train epoch 80, average loss 0.00226384, average accuracy 0.99932,\n",
    "\tDev epoch 80, average loss 0.524143, average accuracy 0.925314,\n",
    "\t\tTime taken for 80 epochs =  2796.155880212784\n",
    "Train epoch 81, average loss 0.00289398, average accuracy 0.99907,\n",
    "Train epoch 82, average loss 0.00267882, average accuracy 0.99915,\n",
    "Train epoch 83, average loss 0.00251234, average accuracy 0.99917,\n",
    "Train epoch 84, average loss 0.00212931, average accuracy 0.99929,\n",
    "Train epoch 85, average loss 0.00204477, average accuracy 0.99936,\n",
    "\tDev epoch 85, average loss 0.533493, average accuracy 0.926382,\n",
    "Train epoch 86, average loss 0.00236821, average accuracy 0.99926,\n",
    "Train epoch 87, average loss 0.00237569, average accuracy 0.99921,\n",
    "Train epoch 88, average loss 0.00245643, average accuracy 0.99923,\n",
    "Train epoch 89, average loss 0.00226378, average accuracy 0.99937,\n",
    "Train epoch 90, average loss 0.00233121, average accuracy 0.99925,\n",
    "\tDev epoch 90, average loss 0.58426, average accuracy 0.924112,\n",
    "\t\tTime taken for 90 epochs =  3140.9629440307617\n",
    "Train epoch 91, average loss 0.00239393, average accuracy 0.99934,\n",
    "Train epoch 92, average loss 0.00168514, average accuracy 0.99947,\n",
    "Train epoch 93, average loss 0.00218618, average accuracy 0.99934,\n",
    "Train epoch 94, average loss 0.00201177, average accuracy 0.99939,\n",
    "Train epoch 95, average loss 0.00265143, average accuracy 0.99903,\n",
    "\n",
    "\tDev epoch 95, average loss 0.522781, average accuracy 0.927284,\n",
    "Train epoch 96, average loss 0.00200737, average accuracy 0.99945,\n",
    "Train epoch 97, average loss 0.00167531, average accuracy 0.99956,\n",
    "Train epoch 98, average loss 0.00197691, average accuracy 0.99943,\n",
    "Train epoch 99, average loss 0.00189404, average accuracy 0.99943,\n",
    "Train epoch 100, average loss 0.00217102, average accuracy 0.99935,\n",
    "\tDev epoch 100, average loss 0.509596, average accuracy 0.927417,\n",
    "\t\tTime taken for 100 epochs =  3485.5287368297577\n",
    "Train epoch 101, average loss 0.00214391, average accuracy 0.99932,\n",
    "Train epoch 102, average loss 0.00166687, average accuracy 0.99949,\n",
    "Train epoch 103, average loss 0.00193214, average accuracy 0.99941,\n",
    "Train epoch 104, average loss 0.00230417, average accuracy 0.99928,\n",
    "Train epoch 105, average loss 0.00262318, average accuracy 0.99917,\n",
    "\tDev epoch 105, average loss 0.580702, average accuracy 0.924379,\n",
    "Train epoch 106, average loss 0.00217951, average accuracy 0.99936,\n",
    "Train epoch 107, average loss 0.00196965, average accuracy 0.9994,\n",
    "Train epoch 108, average loss 0.00169252, average accuracy 0.99945,\n",
    "Train epoch 109, average loss 0.00184972, average accuracy 0.99937,\n",
    "Train epoch 110, average loss 0.00203432, average accuracy 0.99938,\n",
    "\tDev epoch 110, average loss 0.580674, average accuracy 0.925214,\n",
    "\t\tTime taken for 110 epochs =  3830.0551614761353\n",
    "Train epoch 111, average loss 0.0018848, average accuracy 0.99941,\n",
    "Train epoch 112, average loss 0.001956, average accuracy 0.99934,\n",
    "Train epoch 113, average loss 0.00164951, average accuracy 0.99948,\n",
    "Train epoch 114, average loss 0.00189435, average accuracy 0.99941,\n",
    "Train epoch 115, average loss 0.00179166, average accuracy 0.99939,\n",
    "\tDev epoch 115, average loss 0.541616, average accuracy 0.926282,\n",
    "Train epoch 116, average loss 0.0018286, average accuracy 0.99944,\n",
    "Train epoch 117, average loss 0.00176589, average accuracy 0.99943,\n",
    "Train epoch 118, average loss 0.00170349, average accuracy 0.99947,\n",
    "Train epoch 119, average loss 0.00222146, average accuracy 0.99928,\n",
    "Train epoch 120, average loss 0.00133639, average accuracy 0.99959,\n",
    "\tDev epoch 120, average loss 0.587092, average accuracy 0.926482,\n",
    "\t\tTime taken for 120 epochs =  4174.599865913391\n",
    "Train epoch 121, average loss 0.00179675, average accuracy 0.99939,\n",
    "Train epoch 122, average loss 0.00170493, average accuracy 0.99948,\n",
    "Train epoch 123, average loss 0.00196213, average accuracy 0.99939,\n",
    "Train epoch 124, average loss 0.00148926, average accuracy 0.99953,\n",
    "Train epoch 125, average loss 0.00146297, average accuracy 0.99951,\n",
    "\tDev epoch 125, average loss 0.555345, average accuracy 0.926516,\n",
    "Train epoch 126, average loss 0.00200696, average accuracy 0.99936,\n",
    "Train epoch 127, average loss 0.00152734, average accuracy 0.99952,\n",
    "Train epoch 128, average loss 0.00232658, average accuracy 0.9993,\n",
    "Train epoch 129, average loss 0.00197241, average accuracy 0.99939,\n",
    "Train epoch 130, average loss 0.00210397, average accuracy 0.99924,\n",
    "\tDev epoch 130, average loss 0.670168, average accuracy 0.92291,\n",
    "\t\tTime taken for 130 epochs =  4519.105709552765\n",
    "Train epoch 131, average loss 0.00184804, average accuracy 0.99943,\n",
    "Train epoch 132, average loss 0.00178672, average accuracy 0.99941,\n",
    "Train epoch 133, average loss 0.00175419, average accuracy 0.9994,\n",
    "Train epoch 134, average loss 0.0019224, average accuracy 0.99934,\n",
    "Train epoch 135, average loss 0.00222945, average accuracy 0.99931,\n",
    "\tDev epoch 135, average loss 0.657096, average accuracy 0.923377,\n",
    "Train epoch 136, average loss 0.00175209, average accuracy 0.99934,\n",
    "Train epoch 137, average loss 0.00214912, average accuracy 0.99925,\n",
    "Train epoch 138, average loss 0.00162636, average accuracy 0.99941,\n",
    "Train epoch 139, average loss 0.00180691, average accuracy 0.99946,\n",
    "Train epoch 140, average loss 0.00118666, average accuracy 0.99959,\n",
    "\tDev epoch 140, average loss 0.575778, average accuracy 0.926015,\n",
    "\t\tTime taken for 140 epochs =  4863.487067222595\n",
    "        \n",
    "\n",
    "#### Same as above, with 60 epochs.\n",
    "\n",
    "completed cnn creation\n",
    "Number batches = 1562\n",
    "Train epoch 0, average loss 0.30547, average accuracy 0.87393,\n",
    "\tDev epoch 0, average loss 0.237115, average accuracy 0.904915,\n",
    "\t\tTime taken for 0 epochs =  36.875508308410645\n",
    "Train epoch 3, average loss 0.152626, average accuracy 0.940681,\n",
    "Train epoch 6, average loss 0.0826888, average accuracy 0.96937,\n",
    "\tDev epoch 6, average loss 0.237618, average accuracy 0.921307,\n",
    "Train epoch 9, average loss 0.0498599, average accuracy 0.982274,\n",
    "Train epoch 12, average loss 0.0340667, average accuracy 0.987906,\n",
    "\tDev epoch 12, average loss 0.290549, average accuracy 0.922075,\n",
    "\t\tTime taken for 12 epochs =  449.51883339881897\n",
    "Train epoch 15, average loss 0.0254497, average accuracy 0.991217,\n",
    "Train epoch 18, average loss 0.0187158, average accuracy 0.993648,\n",
    "\tDev epoch 18, average loss 0.306756, average accuracy 0.923945,\n",
    "Train epoch 21, average loss 0.0152883, average accuracy 0.995038,\n",
    "Train epoch 24, average loss 0.0124834, average accuracy 0.995999,\n",
    "\tDev epoch 24, average loss 0.329978, average accuracy 0.926716,\n",
    "\t\tTime taken for 24 epochs =  862.4385898113251\n",
    "Train epoch 27, average loss 0.0112456, average accuracy 0.996409,\n",
    "Train epoch 30, average loss 0.00972575, average accuracy 0.996939,\n",
    "\tDev epoch 30, average loss 0.361886, average accuracy 0.92695,\n",
    "Train epoch 33, average loss 0.00892223, average accuracy 0.997189,\n",
    "Train epoch 36, average loss 0.00712946, average accuracy 0.997789,\n",
    "\tDev epoch 36, average loss 0.381359, average accuracy 0.92685,\n",
    "\t\tTime taken for 36 epochs =  1275.2902917861938\n",
    "Train epoch 39, average loss 0.00628213, average accuracy 0.998139,\n",
    "Train epoch 42, average loss 0.00596454, average accuracy 0.998159,\n",
    "\tDev epoch 42, average loss 0.47203, average accuracy 0.924446,\n",
    "Train epoch 45, average loss 0.00500223, average accuracy 0.9985,\n",
    "Train epoch 48, average loss 0.00469857, average accuracy 0.99864,\n",
    "\tDev epoch 48, average loss 0.401148, average accuracy 0.926749,\n",
    "\t\tTime taken for 48 epochs =  1688.264419078827\n",
    "Train epoch 51, average loss 0.00402232, average accuracy 0.99886,\n",
    "Train epoch 54, average loss 0.00421826, average accuracy 0.99865,\n",
    "\tDev epoch 54, average loss 0.416046, average accuracy 0.928385,\n",
    "Train epoch 57, average loss 0.00368313, average accuracy 0.99893,\n",
    "Train epoch 60, average loss 0.00335348, average accuracy 0.99901,\n",
    "\tDev epoch 60, average loss 0.438822, average accuracy 0.927918,\n",
    "\t\tTime taken for 60 epochs =  2101.384346008301\n",
    "\n",
    "#### With the embeddings set to trainable = false.\n",
    "completed cnn creation\n",
    "# batches = 1562\n",
    "Train epoch 0, average loss 0.304837, average accuracy 0.87436,\n",
    "\t\tDev epoch 0, average loss 0.239171, average accuracy 0.905649,\n",
    "\t\t\t\t    Time taken for 0 epochs =  33.351370334625244\n",
    "Train epoch 3, average loss 0.159725, average accuracy 0.93797,\n",
    "Train epoch 6, average loss 0.0951332, average accuracy 0.963478,\n",
    "\t\tDev epoch 6, average loss 0.222475, average accuracy 0.916299,\n",
    "Train epoch 9, average loss 0.0597436, average accuracy 0.978053,\n",
    "Train epoch 12, average loss 0.0414887, average accuracy 0.985045,\n",
    "\t\tDev epoch 12, average loss 0.258621, average accuracy 0.921708,\n",
    "\t\t\t\t    Time taken for 12 epochs =  405.9028522968292\n",
    "Train epoch 15, average loss 0.03174, average accuracy 0.988536,\n",
    "Train epoch 18, average loss 0.0268379, average accuracy 0.990747,\n",
    "\t\tDev epoch 18, average loss 0.308509, average accuracy 0.922242,\n",
    "Train epoch 21, average loss 0.0237158, average accuracy 0.991737,\n",
    "Train epoch 24, average loss 0.0182942, average accuracy 0.993528,\n",
    "\t\tDev epoch 24, average loss 0.330288, average accuracy 0.922643,\n",
    "\t\t\t\t    Time taken for 24 epochs =  778.5845618247986\n",
    "Train epoch 27, average loss 0.0170312, average accuracy 0.994198,\n",
    "Train epoch 30, average loss 0.0140965, average accuracy 0.994978,\n",
    "\t\tDev epoch 30, average loss 0.389294, average accuracy 0.922476,\n",
    "Train epoch 33, average loss 0.0119405, average accuracy 0.996029,\n",
    "Train epoch 36, average loss 0.0102918, average accuracy 0.996929,\n",
    "\t\tDev epoch 36, average loss 0.390921, average accuracy 0.922943,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1150.900290966034\n",
    "Train epoch 39, average loss 0.00885309, average accuracy 0.997279,\n",
    "Train epoch 42, average loss 0.0098332, average accuracy 0.996869,\n",
    "\t\tDev epoch 42, average loss 0.408098, average accuracy 0.922476,\n",
    "Train epoch 45, average loss 0.00801163, average accuracy 0.997559,\n",
    "Train epoch 48, average loss 0.0075703, average accuracy 0.997559,\n",
    "\t\tDev epoch 48, average loss 0.405061, average accuracy 0.920339,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1523.076869726181\n",
    "Train epoch 51, average loss 0.00815841, average accuracy 0.997429,\n",
    "Train epoch 54, average loss 0.00750207, average accuracy 0.997439,\n",
    "\t\tDev epoch 54, average loss 0.411605, average accuracy 0.922109,\n",
    "Train epoch 57, average loss 0.00687906, average accuracy 0.997739,\n",
    "Train epoch 60, average loss 0.00724441, average accuracy 0.997749,\n",
    "\t\tDev epoch 60, average loss 0.513384, average accuracy 0.920039,\n",
    "\t\t\t\t    Time taken for 60 epochs =  1895.2125108242035\n",
    "                    \n",
    " #### embedding dim = 50. trainable = tur\n",
    " Writing to /home/ubuntu/W266Project/final_project/runs/cnn\n",
    "\n",
    "completed cnn creation\n",
    "# batches = 1562\n",
    "Train epoch 0, average loss 0.344391, average accuracy 0.857604,\n",
    "\t\tDev epoch 0, average loss 0.289542, average accuracy 0.875501,\n",
    "\t\t\t\t    Time taken for 0 epochs =  32.877453088760376\n",
    "Train epoch 3, average loss 0.205036, average accuracy 0.915813,\n",
    "Train epoch 6, average loss 0.143437, average accuracy 0.943792,\n",
    "\t\tDev epoch 6, average loss 0.245589, average accuracy 0.913261,\n",
    "Train epoch 9, average loss 0.10241, average accuracy 0.960037,\n",
    "Train epoch 12, average loss 0.0766644, average accuracy 0.970851,\n",
    "\t\tDev epoch 12, average loss 0.256715, average accuracy 0.918636,\n",
    "\t\t\t\t    Time taken for 12 epochs =  357.13569045066833\n",
    "Train epoch 15, average loss 0.0596088, average accuracy 0.978213,\n",
    "Train epoch 18, average loss 0.0488154, average accuracy 0.982314,\n",
    "\t\tDev epoch 18, average loss 0.298308, average accuracy 0.917835,\n",
    "Train epoch 21, average loss 0.0426194, average accuracy 0.984715,\n",
    "Train epoch 24, average loss 0.0340587, average accuracy 0.988276,\n",
    "\t\tDev epoch 24, average loss 0.324277, average accuracy 0.920339,\n",
    "\t\t\t\t    Time taken for 24 epochs =  681.0641686916351\n",
    "Train epoch 27, average loss 0.0312987, average accuracy 0.989157,\n",
    "Train epoch 30, average loss 0.0283847, average accuracy 0.990167,\n",
    "\t\tDev epoch 30, average loss 0.374785, average accuracy 0.92261,\n",
    "Train epoch 33, average loss 0.0240973, average accuracy 0.991917,\n",
    "Train epoch 36, average loss 0.0231575, average accuracy 0.992087,\n",
    "\t\tDev epoch 36, average loss 0.372793, average accuracy 0.922175,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1004.7895133495331\n",
    "Train epoch 39, average loss 0.0181793, average accuracy 0.993778,\n",
    "Train epoch 42, average loss 0.0158069, average accuracy 0.994878,\n",
    "\t\tDev epoch 42, average loss 0.394058, average accuracy 0.917535,\n",
    "Train epoch 45, average loss 0.0152652, average accuracy 0.994888,\n",
    "Train epoch 48, average loss 0.0122295, average accuracy 0.995979,\n",
    "\t\tDev epoch 48, average loss 0.415253, average accuracy 0.917601,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1328.6486732959747\n",
    "Train epoch 51, average loss 0.0120298, average accuracy 0.996009,\n",
    "Train epoch 54, average loss 0.0118266, average accuracy 0.996119,\n",
    "\t\tDev epoch 54, average loss 0.413061, average accuracy 0.922443,\n",
    "        \n",
    "#### increased embedding size to 200\n",
    "\n",
    "Train epoch 0, average loss 0.286025, average accuracy 0.882512,\n",
    "\t\tDev epoch 0, average loss 0.238953, average accuracy 0.901142,\n",
    "\t\t\t\t    Time taken for 0 epochs =  110.49707412719727\n",
    "Train epoch 3, average loss 0.115594, average accuracy 0.956656,\n",
    "Train epoch 6, average loss 0.0497285, average accuracy 0.982724,\n",
    "\t\tDev epoch 6, average loss 0.225743, average accuracy 0.929988,\n",
    "Train epoch 9, average loss 0.0273755, average accuracy 0.990967,\n",
    "Train epoch 12, average loss 0.0186573, average accuracy 0.993748,\n",
    "\t\tDev epoch 12, average loss 0.281195, average accuracy 0.931424,\n",
    "\t\t\t\t    Time taken for 12 epochs =  803.1010024547577\n",
    "Train epoch 15, average loss 0.0134854, average accuracy 0.995819,\n",
    "Train epoch 18, average loss 0.0100261, average accuracy 0.997069,\n",
    "\t\tDev epoch 18, average loss 0.315512, average accuracy 0.930188,\n",
    "Train epoch 21, average loss 0.00782281, average accuracy 0.997709,\n",
    "Train epoch 24, average loss 0.00664231, average accuracy 0.998049,\n",
    "\t\tDev epoch 24, average loss 0.325848, average accuracy 0.930288,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1495.02197265625\n",
    "Train epoch 27, average loss 0.0047185, average accuracy 0.9988,\n",
    "Train epoch 30, average loss 0.00426745, average accuracy 0.99881,\n",
    "\t\tDev epoch 30, average loss 0.402758, average accuracy 0.92892,\n",
    "Train epoch 33, average loss 0.00427015, average accuracy 0.99867,\n",
    "Train epoch 36, average loss 0.00313919, average accuracy 0.99917,\n",
    "\t\tDev epoch 36, average loss 0.364247, average accuracy 0.931858,\n",
    "\t\t\t\t    Time taken for 36 epochs =  2186.8154296875\n",
    "Train epoch 39, average loss 0.00310154, average accuracy 0.99915,\n",
    "Train epoch 42, average loss 0.00245393, average accuracy 0.99941,\n",
    "\t\tDev epoch 42, average loss 0.430721, average accuracy 0.930255,\n",
    "        \n",
    "#### decreased embedding size to 100, and reduced number of filters to 128 per filter size.\n",
    "\n",
    "# batches = 1562\n",
    "Train epoch 0, average loss 0.324282, average accuracy 0.864767,\n",
    "\t\tDev epoch 0, average loss 0.247642, average accuracy 0.896368,\n",
    "\t\t\t\t    Time taken for 0 epochs =  31.22071099281311\n",
    "Train epoch 3, average loss 0.170937, average accuracy 0.932518,\n",
    "Train epoch 6, average loss 0.111375, average accuracy 0.956436,\n",
    "\t\tDev epoch 6, average loss 0.215396, average accuracy 0.916533,\n",
    "Train epoch 9, average loss 0.0755983, average accuracy 0.971181,\n",
    "Train epoch 12, average loss 0.0536806, average accuracy 0.980444,\n",
    "\t\tDev epoch 12, average loss 0.272522, average accuracy 0.921541,\n",
    "\t\t\t\t    Time taken for 12 epochs =  300.37999510765076\n",
    "Train epoch 15, average loss 0.0438895, average accuracy 0.983705,\n",
    "Train epoch 18, average loss 0.0348257, average accuracy 0.987456,\n",
    "\t\tDev epoch 18, average loss 0.311513, average accuracy 0.922676,\n",
    "Train epoch 21, average loss 0.0279689, average accuracy 0.990087,\n",
    "Train epoch 24, average loss 0.025247, average accuracy 0.990957,\n",
    "\t\tDev epoch 24, average loss 0.341999, average accuracy 0.923811,\n",
    "\t\t\t\t    Time taken for 24 epochs =  569.6881365776062\n",
    "Train epoch 27, average loss 0.0203997, average accuracy 0.992968,\n",
    "Train epoch 30, average loss 0.0187122, average accuracy 0.993508,\n",
    "\t\tDev epoch 30, average loss 0.357159, average accuracy 0.923811,\n",
    "Train epoch 33, average loss 0.0158869, average accuracy 0.994488,\n",
    "Train epoch 36, average loss 0.0158628, average accuracy 0.994568,\n",
    "\t\tDev epoch 36, average loss 0.371735, average accuracy 0.92311,\n",
    "\t\t\t\t    Time taken for 36 epochs =  838.69158244133\n",
    "Train epoch 39, average loss 0.0133922, average accuracy 0.995659,\n",
    "Train epoch 42, average loss 0.0127672, average accuracy 0.995709,\n",
    "\t\tDev epoch 42, average loss 0.402635, average accuracy 0.92498,\n",
    "Train epoch 45, average loss 0.0119068, average accuracy 0.996049,\n",
    "Train epoch 48, average loss 0.0107565, average accuracy 0.996499,\n",
    "\t\tDev epoch 48, average loss 0.419966, average accuracy 0.92478,\n",
    "\t\t\t\t    Time taken for 48 epochs =  1107.9437527656555\n",
    "Train epoch 51, average loss 0.0100834, average accuracy 0.996689,\n",
    "Train epoch 54, average loss 0.00994073, average accuracy 0.996889,\n",
    "\t\tDev epoch 54, average loss 0.41175, average accuracy 0.924245,\n",
    "Train epoch 57, average loss 0.00979135, average accuracy 0.996649,\n",
    "Train epoch 60, average loss 0.00821928, average accuracy 0.997469,\n",
    "\t\tDev epoch 60, average loss 0.469267, average accuracy 0.926115,\n",
    "\t\t\t\t    Time taken for 60 epochs =  1377.0541887283325\n",
    "                    \n",
    " #### increased number of filters to 512 per filter size.\n",
    " \n",
    " Train epoch 0, average loss 0.311692, average accuracy 0.870288,\n",
    "\t\tDev epoch 0, average loss 0.242969, average accuracy 0.896701,\n",
    "\t\t\t\t    Time taken for 0 epochs =  84.6077299118042\n",
    "Train epoch 3, average loss 0.142796, average accuracy 0.944482,\n",
    "Train epoch 6, average loss 0.0668666, average accuracy 0.975692,\n",
    "\t\tDev epoch 6, average loss 0.210706, average accuracy 0.924913,\n",
    "Train epoch 9, average loss 0.0342145, average accuracy 0.988336,\n",
    "Train epoch 12, average loss 0.0224968, average accuracy 0.992708,\n",
    "\t\tDev epoch 12, average loss 0.274663, average accuracy 0.926916,\n",
    "\t\t\t\t    Time taken for 12 epochs =  809.0257966518402\n",
    "Train epoch 15, average loss 0.0171242, average accuracy 0.994098,\n",
    "Train epoch 18, average loss 0.0118646, average accuracy 0.996329,\n",
    "\t\tDev epoch 18, average loss 0.302414, average accuracy 0.928218,\n",
    "Train epoch 21, average loss 0.0098251, average accuracy 0.996879,\n",
    "Train epoch 24, average loss 0.0067338, average accuracy 0.998029,\n",
    "\t\tDev epoch 24, average loss 0.331184, average accuracy 0.927985,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1532.959394454956\n",
    "Train epoch 27, average loss 0.00506558, average accuracy 0.99858,\n",
    "Train epoch 30, average loss 0.00396653, average accuracy 0.99893,\n",
    "\t\tDev epoch 30, average loss 0.343347, average accuracy 0.928352,\n",
    "Train epoch 33, average loss 0.00384556, average accuracy 0.99898,\n",
    "Train epoch 36, average loss 0.0030804, average accuracy 0.99932,\n",
    "\t\tDev epoch 36, average loss 0.373929, average accuracy 0.928552,\n",
    "\t\t\t\t    Time taken for 36 epochs =  2256.9254744052887\n",
    "Train epoch 39, average loss 0.00246744, average accuracy 0.99933,\n",
    "Train epoch 42, average loss 0.00211266, average accuracy 0.9996,\n",
    "\t\tDev epoch 42, average loss 0.361598, average accuracy 0.929053,\n",
    "Train epoch 45, average loss 0.00217611, average accuracy 0.99941,\n",
    "Train epoch 48, average loss 0.00197936, average accuracy 0.99955,\n",
    "\t\tDev epoch 48, average loss 0.391054, average accuracy 0.929754,\n",
    "\t\t\t\t    Time taken for 48 epochs =  2980.909019947052\n",
    "Train epoch 51, average loss 0.00187027, average accuracy 0.99957,\n",
    "Train epoch 54, average loss 0.00191055, average accuracy 0.99958,\n",
    "\t\tDev epoch 54, average loss 0.378678, average accuracy 0.92685,\n",
    "Train epoch 57, average loss 0.00153142, average accuracy 0.99968,\n",
    "Train epoch 60, average loss 0.00134926, average accuracy 0.99974,\n",
    "\t\tDev epoch 60, average loss 0.405928, average accuracy 0.929854,\n",
    "\t\t\t\t    Time taken for 60 epochs =  3704.6175475120544\n",
    "                    \n",
    "completed cnn creation\n",
    "#### added a filter for length 6. so filter sizes became (3,4,5,6). \n",
    "Train epoch 0, average loss 0.315134, average accuracy 0.868868,\n",
    "\t\tDev epoch 0, average loss 0.248855, average accuracy 0.89353,\n",
    "\t\t\t\t    Time taken for 0 epochs =  69.76286554336548\n",
    "Train epoch 3, average loss 0.149292, average accuracy 0.942482,\n",
    "Train epoch 6, average loss 0.072978, average accuracy 0.973211,\n",
    "\t\tDev epoch 6, average loss 0.220149, average accuracy 0.921908,\n",
    "Train epoch 9, average loss 0.0399216, average accuracy 0.985855,\n",
    "Train epoch 12, average loss 0.0274265, average accuracy 0.990367,\n",
    "\t\tDev epoch 12, average loss 0.321294, average accuracy 0.922342,\n",
    "\t\t\t\t    Time taken for 12 epochs =  666.9912831783295\n",
    "Train epoch 15, average loss 0.0199664, average accuracy 0.993398,\n",
    "Train epoch 18, average loss 0.0145588, average accuracy 0.995429,\n",
    "\t\tDev epoch 18, average loss 0.30958, average accuracy 0.921341,\n",
    "Train epoch 21, average loss 0.011635, average accuracy 0.996449,\n",
    "Train epoch 24, average loss 0.00927037, average accuracy 0.997119,\n",
    "\t\tDev epoch 24, average loss 0.352559, average accuracy 0.926449,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1264.2059795856476\n",
    "Train epoch 27, average loss 0.00758558, average accuracy 0.997789,\n",
    "Train epoch 30, average loss 0.0056179, average accuracy 0.998409,\n",
    "\t\tDev epoch 30, average loss 0.385125, average accuracy 0.926749,\n",
    "Train epoch 33, average loss 0.0049369, average accuracy 0.99856,\n",
    "Train epoch 36, average loss 0.00391196, average accuracy 0.99882,\n",
    "\t\tDev epoch 36, average loss 0.369655, average accuracy 0.926482,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1861.2735829353333\n",
    "Train epoch 39, average loss 0.00425983, average accuracy 0.99884,\n",
    "Train epoch 42, average loss 0.00378442, average accuracy 0.99898,\n",
    "\t\tDev epoch 42, average loss 0.386586, average accuracy 0.926883,\n",
    "Train epoch 45, average loss 0.00346757, average accuracy 0.99902,\n",
    "Train epoch 48, average loss 0.00338043, average accuracy 0.99902,\n",
    "\t\tDev epoch 48, average loss 0.395295, average accuracy 0.927784,\n",
    "\t\t\t\t    Time taken for 48 epochs =  2458.481989145279\n",
    "Train epoch 51, average loss 0.00368297, average accuracy 0.99901,\n",
    "Train epoch 54, average loss 0.00253086, average accuracy 0.99935,\n",
    "\t\tDev epoch 54, average loss 0.410479, average accuracy 0.92685,\n",
    "Train epoch 57, average loss 0.00307247, average accuracy 0.99915,\n",
    "Train epoch 60, average loss 0.00267205, average accuracy 0.99934,\n",
    "\t\tDev epoch 60, average loss 0.449313, average accuracy 0.926215,\n",
    "\t\t\t\t    Time taken for 60 epochs =  3055.6355838775635 \n",
    "                    \n",
    "                    \n",
    "#### With random shuffle added for batches.\n",
    "Train epoch 0, average loss 0.315134, average accuracy 0.868868,\n",
    "\t\tDev epoch 0, average loss 0.248855, average accuracy 0.89353,\n",
    "\t\t\t\t    Time taken for 0 epochs =  69.76286554336548\n",
    "Train epoch 3, average loss 0.149292, average accuracy 0.942482,\n",
    "Train epoch 6, average loss 0.072978, average accuracy 0.973211,\n",
    "\t\tDev epoch 6, average loss 0.220149, average accuracy 0.921908,\n",
    "Train epoch 9, average loss 0.0399216, average accuracy 0.985855,\n",
    "Train epoch 12, average loss 0.0274265, average accuracy 0.990367,\n",
    "\t\tDev epoch 12, average loss 0.321294, average accuracy 0.922342,\n",
    "\t\t\t\t    Time taken for 12 epochs =  666.9912831783295\n",
    "Train epoch 15, average loss 0.0199664, average accuracy 0.993398,\n",
    "Train epoch 18, average loss 0.0145588, average accuracy 0.995429,\n",
    "\t\tDev epoch 18, average loss 0.30958, average accuracy 0.921341,\n",
    "Train epoch 21, average loss 0.011635, average accuracy 0.996449,\n",
    "Train epoch 24, average loss 0.00927037, average accuracy 0.997119,\n",
    "\t\tDev epoch 24, average loss 0.352559, average accuracy 0.926449,\n",
    "\t\t\t\t    Time taken for 24 epochs =  1264.2059795856476\n",
    "Train epoch 27, average loss 0.00758558, average accuracy 0.997789,\n",
    "Train epoch 30, average loss 0.0056179, average accuracy 0.998409,\n",
    "\t\tDev epoch 30, average loss 0.385125, average accuracy 0.926749,\n",
    "Train epoch 33, average loss 0.0049369, average accuracy 0.99856,\n",
    "Train epoch 36, average loss 0.00391196, average accuracy 0.99882,\n",
    "\t\tDev epoch 36, average loss 0.369655, average accuracy 0.926482,\n",
    "\t\t\t\t    Time taken for 36 epochs =  1861.2735829353333\n",
    "Train epoch 39, average loss 0.00425983, average accuracy 0.99884,\n",
    "Train epoch 42, average loss 0.00378442, average accuracy 0.99898,\n",
    "\t\tDev epoch 42, average loss 0.386586, average accuracy 0.926883,\n",
    "Train epoch 45, average loss 0.00346757, average accuracy 0.99902,\n",
    "Train epoch 48, average loss 0.00338043, average accuracy 0.99902,\n",
    "\t\tDev epoch 48, average loss 0.395295, average accuracy 0.927784,\n",
    "\t\t\t\t    Time taken for 48 epochs =  2458.481989145279\n",
    "Train epoch 51, average loss 0.00368297, average accuracy 0.99901,\n",
    "Train epoch 54, average loss 0.00253086, average accuracy 0.99935,\n",
    "\t\tDev epoch 54, average loss 0.410479, average accuracy 0.92685,\n",
    "Train epoch 57, average loss 0.00307247, average accuracy 0.99915,\n",
    "Train epoch 60, average loss 0.00267205, average accuracy 0.99934,\n",
    "\t\tDev epoch 60, average loss 0.449313, average accuracy 0.926215,\n",
    "\t\t\t\t    Time taken for 60 epochs =  3055.6355838775635"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
